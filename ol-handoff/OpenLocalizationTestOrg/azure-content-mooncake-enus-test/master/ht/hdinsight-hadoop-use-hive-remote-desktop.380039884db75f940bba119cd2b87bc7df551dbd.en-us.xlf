<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="en-us">
    <header>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ht</xliffext:oltranslationpriority>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">fdf96c261c79c775d753b7c72d0aabbb5330c373</xliffext:olfilehash>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-02a95cf" tool-company="Microsoft" />
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>在 HDInsight 中将 Hadoop Hive 与远程桌面配合使用 | Azure</source>
          <target state="new">在 HDInsight 中将 Hadoop Hive 与远程桌面配合使用 | Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>学习如何通过使用远程桌面连接到 HDInsight 中的 Hadoop 群集，然后通过使用 Hive 命令行界面运行 Hive 查询。</source>
          <target state="new">学习如何通过使用远程桌面连接到 HDInsight 中的 Hadoop 群集，然后通过使用 Hive 命令行界面运行 Hive 查询。</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>通过远程桌面将 Hive 与 HDInsight 上的 Hadoop 配合使用</source>
          <target state="new">通过远程桌面将 Hive 与 HDInsight 上的 Hadoop 配合使用</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>在本文中，你将学习如何通过使用远程桌面连接到 HDInsight 群集，然后通过使用 Hive 命令行界面 (CLI) 运行 Hive 查询。</source>
          <target state="new">在本文中，你将学习如何通过使用远程桌面连接到 HDInsight 群集，然后通过使用 Hive 命令行界面 (CLI) 运行 Hive 查询。</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>本文档未详细描述示例中使用的 HiveQL 语句的作用。有关此示例中使用的 HiveQL 的详细信息，请参阅<bpt id="p1">[</bpt>将 Hive 与 HDInsight 上的 Hadoop 配合使用<ept id="p1">](/documentation/articles/hdinsight-use-hive)</ept>。</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>本文档未详细描述示例中使用的 HiveQL 语句的作用。有关此示例中使用的 HiveQL 的详细信息，请参阅<bpt id="p1">[</bpt>将 Hive 与 HDInsight 上的 Hadoop 配合使用<ept id="p1">](/documentation/articles/hdinsight-use-hive)</ept>。</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="prereq"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>先决条件</source>
          <target state="new"><ph id="ph1">&lt;a id="prereq"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>先决条件</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>若要完成本文中的步骤，你将需要：</source>
          <target state="new">若要完成本文中的步骤，你将需要：</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>基于 Windows 的 HDInsight（HDInsight 上的 Hadoop）群集</source>
          <target state="new">基于 Windows 的 HDInsight（HDInsight 上的 Hadoop）群集</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>运行 Windows 10、Window 8 或 Windows 7 的客户端计算机</source>
          <target state="new">运行 Windows 10、Window 8 或 Windows 7 的客户端计算机</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="connect"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>使用远程桌面进行连接</source>
          <target state="new"><ph id="ph1">&lt;a id="connect"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>使用远程桌面进行连接</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>为 HDInsight 群集启用远程桌面，然后根据<bpt id="p1">[</bpt>使用 RDP 连接到 HDInsight 群集<ept id="p1">](/documentation/articles/hdinsight-administer-use-management-portal-v1#rdp)</ept>中的说明连接到该群集。</source>
          <target state="new">为 HDInsight 群集启用远程桌面，然后根据<bpt id="p1">[</bpt>使用 RDP 连接到 HDInsight 群集<ept id="p1">](/documentation/articles/hdinsight-administer-use-management-portal-v1#rdp)</ept>中的说明连接到该群集。</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="hive"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>使用 Hive 命令</source>
          <target state="new"><ph id="ph1">&lt;a id="hive"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>使用 Hive 命令</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>连接到 HDInsight 群集的桌面之后，请执行以下步骤来使用 Hive：</source>
          <target state="new">连接到 HDInsight 群集的桌面之后，请执行以下步骤来使用 Hive：</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>从 HDInsight 桌面启动“Hadoop 命令行”。</source>
          <target state="new">从 HDInsight 桌面启动“Hadoop 命令行”。</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>输入以下命令启动 Hive CLI：</source>
          <target state="new">输入以下命令启动 Hive CLI：</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>在启动 CLI 后，你将会看到 Hive CLI 提示符：<ph id="ph1">`hive&gt;`</ph>。</source>
          <target state="new">在启动 CLI 后，你将会看到 Hive CLI 提示符：<ph id="ph1">`hive&gt;`</ph>。</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>在 CLI 中输入以下语句，以使用示例数据创建名为 <bpt id="p1">**</bpt>log4jLogs<ept id="p1">**</ept> 的新表：</source>
          <target state="new">在 CLI 中输入以下语句，以使用示例数据创建名为 <bpt id="p1">**</bpt>log4jLogs<ept id="p1">**</ept> 的新表：</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>这些语句将执行以下操作：</source>
          <target state="new">这些语句将执行以下操作：</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>DROP TABLE<ept id="p1">**</ept>：删除表和数据文件（如果该表已存在）。</source>
          <target state="new"><bpt id="p1">**</bpt>DROP TABLE<ept id="p1">**</ept>：删除表和数据文件（如果该表已存在）。</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>CREATE EXTERNAL TABLE<ept id="p1">**</ept>：在 Hive 中创建新的“外部”表。外部表仅在 Hive 中存储表定义；数据会保留在原始位置。</source>
          <target state="new"><bpt id="p1">**</bpt>CREATE EXTERNAL TABLE<ept id="p1">**</ept>：在 Hive 中创建新的“外部”表。外部表仅在 Hive 中存储表定义；数据会保留在原始位置。</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>当你预期以外部源更新基础数据（例如自动化数据上载过程），或以其他 MapReduce 操作更新基础数据，但希望 Hive 查询始终使用最新数据时，必须使用外部表。</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>当你预期以外部源更新基础数据（例如自动化数据上载过程），或以其他 MapReduce 操作更新基础数据，但希望 Hive 查询始终使用最新数据时，必须使用外部表。</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>删除外部表<bpt id="p1">**</bpt>不会<ept id="p1">**</ept>删除数据，只会删除表定义。</source>
          <target state="new">删除外部表<bpt id="p1">**</bpt>不会<ept id="p1">**</ept>删除数据，只会删除表定义。</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>ROW FORMAT<ept id="p1">**</ept>：告知 Hive 如何设置数据的格式。在此情况下，每个日志中的字段以空格分隔。</source>
          <target state="new"><bpt id="p1">**</bpt>ROW FORMAT<ept id="p1">**</ept>：告知 Hive 如何设置数据的格式。在此情况下，每个日志中的字段以空格分隔。</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>STORED AS TEXTFILE LOCATION<ept id="p1">**</ept>：让 Hive 知道数据的存储位置（example/data 目录），并且数据已存储为文本。</source>
          <target state="new"><bpt id="p1">**</bpt>STORED AS TEXTFILE LOCATION<ept id="p1">**</ept>：让 Hive 知道数据的存储位置（example/data 目录），并且数据已存储为文本。</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>SELECT<ept id="p1">**</ept> - 选择第 <bpt id="p2">**</bpt>t4<ept id="p2">**</ept> 列包含值 <bpt id="p3">**</bpt>[ERROR]<ept id="p3">**</ept> 的所有行的计数。这应会返回值 <bpt id="p4">**</bpt>3<ept id="p4">**</ept>，因为有三个行包含此值。</source>
          <target state="new"><bpt id="p1">**</bpt>SELECT<ept id="p1">**</ept> - 选择第 <bpt id="p2">**</bpt>t4<ept id="p2">**</ept> 列包含值 <bpt id="p3">**</bpt>[ERROR]<ept id="p3">**</ept> 的所有行的计数。这应会返回值 <bpt id="p4">**</bpt>3<ept id="p4">**</ept>，因为有三个行包含此值。</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>INPUT\_\_FILE\_\_NAME LIKE '%.log'<ept id="p1">**</ept> - 告诉 Hive，我们只应返回以 .log 结尾的文件中的数据。此项将搜索限定于包含数据的 sample.log 文件，使搜索不会返回与所定义架构不符的其他示例数据文件中的数据。</source>
          <target state="new"><bpt id="p1">**</bpt>INPUT\_\_FILE\_\_NAME LIKE '%.log'<ept id="p1">**</ept> - 告诉 Hive，我们只应返回以 .log 结尾的文件中的数据。此项将搜索限定于包含数据的 sample.log 文件，使搜索不会返回与所定义架构不符的其他示例数据文件中的数据。</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>使用以下语句创建名为 <bpt id="p1">**</bpt>errorLogs<ept id="p1">**</ept> 的新“内部”表：</source>
          <target state="new">使用以下语句创建名为 <bpt id="p1">**</bpt>errorLogs<ept id="p1">**</ept> 的新“内部”表：</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>这些语句将执行以下操作：</source>
          <target state="new">这些语句将执行以下操作：</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>CREATE TABLE IF NOT EXISTS<ept id="p1">**</ept>：创建表（如果该表尚不存在）。由于未使用 <bpt id="p2">**</bpt>EXTERNAL<ept id="p2">**</ept> 关键字，因此这是一个内部表，它存储在 Hive 数据仓库中并完全受 Hive 的管理。</source>
          <target state="new"><bpt id="p1">**</bpt>CREATE TABLE IF NOT EXISTS<ept id="p1">**</ept>：创建表（如果该表尚不存在）。由于未使用 <bpt id="p2">**</bpt>EXTERNAL<ept id="p2">**</ept> 关键字，因此这是一个内部表，它存储在 Hive 数据仓库中并完全受 Hive 的管理。</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>与 <bpt id="p1">**</bpt>EXTERNAL<ept id="p1">**</ept> 表不同，删除内部表会同时删除基础数据。</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>与 <bpt id="p1">**</bpt>EXTERNAL<ept id="p1">**</ept> 表不同，删除内部表会同时删除基础数据。</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>STORED AS ORC<ept id="p1">**</ept>：以优化行纵栏表 (ORC) 格式存储数据。这是高度优化且有效的 Hive 数据存储格式。</source>
          <target state="new"><bpt id="p1">**</bpt>STORED AS ORC<ept id="p1">**</ept>：以优化行纵栏表 (ORC) 格式存储数据。这是高度优化且有效的 Hive 数据存储格式。</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>INSERT OVERWRITE ...SELECT<ept id="p1">**</ept>：从包含 <bpt id="p2">**</bpt>[ERROR]<ept id="p2">**</ept> 的 <bpt id="p3">**</bpt>log4jLogs<ept id="p3">**</ept> 表中选择行，然后将数据插入 <bpt id="p4">**</bpt>errorLogs<ept id="p4">**</ept> 表中。</source>
          <target state="new"><bpt id="p1">**</bpt>INSERT OVERWRITE ...SELECT<ept id="p1">**</ept>：从包含 <bpt id="p2">**</bpt>[ERROR]<ept id="p2">**</ept> 的 <bpt id="p3">**</bpt>log4jLogs<ept id="p3">**</ept> 表中选择行，然后将数据插入 <bpt id="p4">**</bpt>errorLogs<ept id="p4">**</ept> 表中。</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>若要验证是否只将第 t4 列中包含 <bpt id="p1">**</bpt>[ERROR]<ept id="p1">**</ept> 的行存储到了 <bpt id="p2">**</bpt>errorLogs<ept id="p2">**</ept> 表，请使用以下语句从 <bpt id="p3">**</bpt>errorLogs<ept id="p3">**</ept> 返回所有行：</source>
          <target state="new">若要验证是否只将第 t4 列中包含 <bpt id="p1">**</bpt>[ERROR]<ept id="p1">**</ept> 的行存储到了 <bpt id="p2">**</bpt>errorLogs<ept id="p2">**</ept> 表，请使用以下语句从 <bpt id="p3">**</bpt>errorLogs<ept id="p3">**</ept> 返回所有行：</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>应返回三行数据，所有行都包含列 t4 中的 <bpt id="p1">**</bpt>[ERROR]<ept id="p1">**</ept>。</source>
          <target state="new">应返回三行数据，所有行都包含列 t4 中的 <bpt id="p1">**</bpt>[ERROR]<ept id="p1">**</ept>。</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="summary"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>摘要</source>
          <target state="new"><ph id="ph1">&lt;a id="summary"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>摘要</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>如你所见，Hive 命令提供了简单的方法让你以交互方式在 HDInsight 群集上运行 Hive 查询、监视作业状态，以及检索输出。</source>
          <target state="new">如你所见，Hive 命令提供了简单的方法让你以交互方式在 HDInsight 群集上运行 Hive 查询、监视作业状态，以及检索输出。</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>后续步骤</source>
          <target state="new"><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>后续步骤</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>有关 HDInsight 中的 Hive 的一般信息：</source>
          <target state="new">有关 HDInsight 中的 Hive 的一般信息：</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>将 Hive 与 HDInsight 上的 Hadoop 配合使用</source>
          <target state="new">将 Hive 与 HDInsight 上的 Hadoop 配合使用</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>有关 HDInsight 上的 Hadoop 的其他使用方法的信息：</source>
          <target state="new">有关 HDInsight 上的 Hadoop 的其他使用方法的信息：</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>将 Pig 与 HDInsight 上的 Hadoop 配合使用</source>
          <target state="new">将 Pig 与 HDInsight 上的 Hadoop 配合使用</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>将 MapReduce 与 HDInsight 上的 Hadoop 配合使用</source>
          <target state="new">将 MapReduce 与 HDInsight 上的 Hadoop 配合使用</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>