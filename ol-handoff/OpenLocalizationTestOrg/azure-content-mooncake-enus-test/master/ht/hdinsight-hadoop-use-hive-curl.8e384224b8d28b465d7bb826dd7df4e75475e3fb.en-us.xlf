<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="en-us">
    <header>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ht</xliffext:oltranslationpriority>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">e274f2d62d8799277cb937c585e3ef97fbcf49a7</xliffext:olfilehash>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-02a95cf" tool-company="Microsoft" />
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>在 HDInsight 中将 Hadoop Hive 与 Curl 配合使用 | Azure</source>
          <target state="new">在 HDInsight 中将 Hadoop Hive 与 Curl 配合使用 | Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>了解如何使用 Curl 向 HDInsight 远程提交 Pig 作业。</source>
          <target state="new">了解如何使用 Curl 向 HDInsight 远程提交 Pig 作业。</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>使用 Curl 在 HDInsight 中以 Hadoop 运行 Hive 查询</source>
          <target state="new">使用 Curl 在 HDInsight 中以 Hadoop 运行 Hive 查询</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>在本文档中，你将学习如何使用 Curl 在 Azure HDInsight 群集上对 Hadoop 运行 Hive 查询。</source>
          <target state="new">在本文档中，你将学习如何使用 Curl 在 Azure HDInsight 群集上对 Hadoop 运行 Hive 查询。</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>本文档使用 Curl 演示如何通过使用原始 HTTP 请求来与 HDInsight 交互，以便运行、监视和检索 Hive 查询的结果。若要执行这些操作，需要使用 HDInsight 群集提供的 WebHCat REST API（前称 Templeton）。</source>
          <target state="new">本文档使用 Curl 演示如何通过使用原始 HTTP 请求来与 HDInsight 交互，以便运行、监视和检索 Hive 查询的结果。若要执行这些操作，需要使用 HDInsight 群集提供的 WebHCat REST API（前称 Templeton）。</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="prereq"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>先决条件</source>
          <target state="new"><ph id="ph1">&lt;a id="prereq"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>先决条件</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>若要完成本文中的步骤，你将需要：</source>
          <target state="new">若要完成本文中的步骤，你将需要：</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>HDInsight 群集上的 Hadoop（基于 Windows）</source>
          <target state="new">HDInsight 群集上的 Hadoop（基于 Windows）</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>Curl</source>
          <target state="new">Curl</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>jq</source>
          <target state="new">jq</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="curl"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>通过使用 Curl 运行 Hive 查询</source>
          <target state="new"><ph id="ph1">&lt;a id="curl"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>通过使用 Curl 运行 Hive 查询</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>使用 Curl 或者与 WebHCat 进行任何其他形式的 REST 通信时，必须提供 HDInsight 群集管理员用户名和密码对请求进行身份验证。此外，还必须使用群集名称作为用来向服务器发送请求的统一资源标识符 (URI) 的一部分。</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>使用 Curl 或者与 WebHCat 进行任何其他形式的 REST 通信时，必须提供 HDInsight 群集管理员用户名和密码对请求进行身份验证。此外，还必须使用群集名称作为用来向服务器发送请求的统一资源标识符 (URI) 的一部分。</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>对本部分中的所有命令，请将 <bpt id="p1">**</bpt>USERNAME<ept id="p1">**</ept> 替换为在群集上进行身份验证的用户，并将 <bpt id="p2">**</bpt>PASSWORD<ept id="p2">**</ept> 替换为用户帐户的密码。将 <bpt id="p3">**</bpt>CLUSTERNAME<ept id="p3">**</ept> 替换为群集名称。</source>
          <target state="new">对本部分中的所有命令，请将 <bpt id="p1">**</bpt>USERNAME<ept id="p1">**</ept> 替换为在群集上进行身份验证的用户，并将 <bpt id="p2">**</bpt>PASSWORD<ept id="p2">**</ept> 替换为用户帐户的密码。将 <bpt id="p3">**</bpt>CLUSTERNAME<ept id="p3">**</ept> 替换为群集名称。</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>REST API 通过<bpt id="p1">[</bpt><ept id="p1">基本身份验证](http://en.wikipedia.org/wiki/Basic_access_authentication)</ept>进行保护。你始终应该使用安全 HTTP (HTTPS) 来发出请求，以确保安全地将凭据发送到服务器。</source>
          <target state="new">REST API 通过<bpt id="p1">[</bpt><ept id="p1">基本身份验证](http://en.wikipedia.org/wiki/Basic_access_authentication)</ept>进行保护。你始终应该使用安全 HTTP (HTTPS) 来发出请求，以确保安全地将凭据发送到服务器。</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>在命令行中，使用以下命令验证你是否可以连接到 HDInsight 群集。</source>
          <target state="new">在命令行中，使用以下命令验证你是否可以连接到 HDInsight 群集。</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>你应会收到类似于下面的响应：</source>
          <target state="new">你应会收到类似于下面的响应：</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>此命令中使用的参数如下：</source>
          <target state="new">此命令中使用的参数如下：</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>-u<ept id="p1">**</ept> - 用来对请求进行身份验证的用户名和密码。</source>
          <target state="new"><bpt id="p1">**</bpt>-u<ept id="p1">**</ept> - 用来对请求进行身份验证的用户名和密码。</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>-G<ept id="p1">**</ept> - 指出这是 GET 请求。</source>
          <target state="new"><bpt id="p1">**</bpt>-G<ept id="p1">**</ept> - 指出这是 GET 请求。</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>所有请求的 URL 开头 <bpt id="p1">**</bpt>https://CLUSTERNAME.azurehdinsight.cn/templeton/v1<ept id="p1">**</ept> 都是一样的。路径 <bpt id="p2">**</bpt>/status<ept id="p2">**</ept> 指示，请求是返回服务器的 WebHCat（也称为 Templeton）的状态。你还可以通过使用以下命令请求 Hive 的版本：</source>
          <target state="new">所有请求的 URL 开头 <bpt id="p1">**</bpt>https://CLUSTERNAME.azurehdinsight.cn/templeton/v1<ept id="p1">**</ept> 都是一样的。路径 <bpt id="p2">**</bpt>/status<ept id="p2">**</ept> 指示，请求是返回服务器的 WebHCat（也称为 Templeton）的状态。你还可以通过使用以下命令请求 Hive 的版本：</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>这应该会返回如下响应：</source>
          <target state="new">这应该会返回如下响应：</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>使用以下命令创建名为 <bpt id="p1">**</bpt>log4jLogs<ept id="p1">**</ept> 的新表：</source>
          <target state="new">使用以下命令创建名为 <bpt id="p1">**</bpt>log4jLogs<ept id="p1">**</ept> 的新表：</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>此命令中使用的参数如下：</source>
          <target state="new">此命令中使用的参数如下：</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>-d<ept id="p1">**</ept> - 由于未使用 <ph id="ph1">`-G`</ph>，请求默认为 POST 方法。<ph id="ph2">`-d`</ph> 指定与请求一起发送的数据值。</source>
          <target state="new"><bpt id="p1">**</bpt>-d<ept id="p1">**</ept> - 由于未使用 <ph id="ph1">`-G`</ph>，请求默认为 POST 方法。<ph id="ph2">`-d`</ph> 指定与请求一起发送的数据值。</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>user.name<ept id="p1">**</ept> - 正在运行命令的用户。</source>
          <target state="new"><bpt id="p1">**</bpt>user.name<ept id="p1">**</ept> - 正在运行命令的用户。</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>execute<ept id="p1">**</ept> - 要执行的 HiveQL 语句。</source>
          <target state="new"><bpt id="p1">**</bpt>execute<ept id="p1">**</ept> - 要执行的 HiveQL 语句。</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>statusdir<ept id="p1">**</ept> - 此作业的状态要写入到的目录。</source>
          <target state="new"><bpt id="p1">**</bpt>statusdir<ept id="p1">**</ept> - 此作业的状态要写入到的目录。</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>这些语句将执行以下操作：</source>
          <target state="new">这些语句将执行以下操作：</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>DROP TABLE<ept id="p1">**</ept> - 删除表和数据文件（如果该表已存在）。</source>
          <target state="new"><bpt id="p1">**</bpt>DROP TABLE<ept id="p1">**</ept> - 删除表和数据文件（如果该表已存在）。</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>CREATE EXTERNAL TABLE<ept id="p1">**</ept> - 在 Hive 中创建新的“外部”表。外部表仅在 Hive 中存储表定义。数据将保留在原始位置。</source>
          <target state="new"><bpt id="p1">**</bpt>CREATE EXTERNAL TABLE<ept id="p1">**</ept> - 在 Hive 中创建新的“外部”表。外部表仅在 Hive 中存储表定义。数据将保留在原始位置。</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>当你预期以外部源更新基础数据（例如自动化数据上载过程），或以其他 MapReduce 操作更新基础数据，但希望 Hive 查询始终使用最新数据时，必须使用外部表。</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>当你预期以外部源更新基础数据（例如自动化数据上载过程），或以其他 MapReduce 操作更新基础数据，但希望 Hive 查询始终使用最新数据时，必须使用外部表。</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>删除外部表<bpt id="p1">**</bpt>不会<ept id="p1">**</ept>删除数据，只会删除表定义。</source>
          <target state="new">删除外部表<bpt id="p1">**</bpt>不会<ept id="p1">**</ept>删除数据，只会删除表定义。</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>ROW FORMAT<ept id="p1">**</ept> - 告知 Hive 如何设置数据的格式。在此情况下，每个日志中的字段以空格分隔。</source>
          <target state="new"><bpt id="p1">**</bpt>ROW FORMAT<ept id="p1">**</ept> - 告知 Hive 如何设置数据的格式。在此情况下，每个日志中的字段以空格分隔。</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>STORED AS TEXTFILE LOCATION<ept id="p1">**</ept> - 让 Hive 知道数据的存储位置（example/data 目录），并且数据已存储为文本。</source>
          <target state="new"><bpt id="p1">**</bpt>STORED AS TEXTFILE LOCATION<ept id="p1">**</ept> - 让 Hive 知道数据的存储位置（example/data 目录），并且数据已存储为文本。</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>SELECT<ept id="p1">**</ept> - 选择第 <bpt id="p2">**</bpt>t4<ept id="p2">**</ept> 列包含值 <bpt id="p3">**</bpt>[ERROR]<ept id="p3">**</ept> 的所有行的计数。这应会返回值 <bpt id="p4">**</bpt>3<ept id="p4">**</ept>，因为有三个行包含此值。</source>
          <target state="new"><bpt id="p1">**</bpt>SELECT<ept id="p1">**</ept> - 选择第 <bpt id="p2">**</bpt>t4<ept id="p2">**</ept> 列包含值 <bpt id="p3">**</bpt>[ERROR]<ept id="p3">**</ept> 的所有行的计数。这应会返回值 <bpt id="p4">**</bpt>3<ept id="p4">**</ept>，因为有三个行包含此值。</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>请注意，在与 Curl 配合使用时，将用 <ph id="ph2">`+`</ph> 字符替换 HiveQL 语句之间的空格。如果带引号的值包含空格（例如分隔符），则不应替换为 <ph id="ph3">`+`</ph>。</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>请注意，在与 Curl 配合使用时，将用 <ph id="ph2">`+`</ph> 字符替换 HiveQL 语句之间的空格。如果带引号的值包含空格（例如分隔符），则不应替换为 <ph id="ph3">`+`</ph>。</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>INPUT\_\_FILE\_\_NAME LIKE '%25.log'<ept id="p1">**</ept> - 此项会对搜索进行限制，仅使用以 .log 结尾的文件。如果此项不存在，Hive 会尝试搜索此目录及其子目录中的所有文件，包括不符合为此表定义的列架构的文件。</source>
          <target state="new"><bpt id="p1">**</bpt>INPUT\_\_FILE\_\_NAME LIKE '%25.log'<ept id="p1">**</ept> - 此项会对搜索进行限制，仅使用以 .log 结尾的文件。如果此项不存在，Hive 会尝试搜索此目录及其子目录中的所有文件，包括不符合为此表定义的列架构的文件。</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>请注意，%25 是 % 的 URL 编码形式，因此实际条件是 <ph id="ph2">`like '%.log'`</ph>。% 必须是 URL 编码的，因为系统将其视为 URL 中的特殊字符。</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>请注意，%25 是 % 的 URL 编码形式，因此实际条件是 <ph id="ph2">`like '%.log'`</ph>。% 必须是 URL 编码的，因为系统将其视为 URL 中的特殊字符。</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>此命令应会返回可用来检查作业状态的作业 ID。</source>
          <target state="new">此命令应会返回可用来检查作业状态的作业 ID。</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>若要检查作业的状态，请使用以下命令。将 <bpt id="p1">**</bpt>JOBID<ept id="p1">**</ept> 替换为上一步骤返回的值。例如，如果返回值为 <ph id="ph1">`{"id":"job_1415651640909_0026"}`</ph>，则 <bpt id="p2">**</bpt>JOBID<ept id="p2">**</ept> 将是 <ph id="ph2">`job_1415651640909_0026`</ph>。</source>
          <target state="new">若要检查作业的状态，请使用以下命令。将 <bpt id="p1">**</bpt>JOBID<ept id="p1">**</ept> 替换为上一步骤返回的值。例如，如果返回值为 <ph id="ph1">`{"id":"job_1415651640909_0026"}`</ph>，则 <bpt id="p2">**</bpt>JOBID<ept id="p2">**</ept> 将是 <ph id="ph2">`job_1415651640909_0026`</ph>。</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>如果作业已完成，状态将是 <bpt id="p1">**</bpt>SUCCEEDED<ept id="p1">**</ept>。</source>
          <target state="new">如果作业已完成，状态将是 <bpt id="p1">**</bpt>SUCCEEDED<ept id="p1">**</ept>。</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>此 Curl 请求返回具有作业相关信息的 JavaScript 对象表示法 (JSON) 文档；使用 jq 可以仅检索状态值。</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>此 Curl 请求返回具有作业相关信息的 JavaScript 对象表示法 (JSON) 文档；使用 jq 可以仅检索状态值。</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>在作业的状态更改为 <bpt id="p1">**</bpt>SUCCEEDED<ept id="p1">**</ept> 后，你可以从 Azure Blob 存储中检索作业的结果。随查询一起传递的 <ph id="ph1">`statusdir`</ph> 参数包含输出文件的位置；在本例中为 <bpt id="p2">**</bpt>wasb:///example/curl<ept id="p2">**</ept>。此地址会将作业的输出存储在 HDInsight 群集所用的默认存储容器的 <bpt id="p3">**</bpt>example/curl<ept id="p3">**</ept> 目录中。</source>
          <target state="new">在作业的状态更改为 <bpt id="p1">**</bpt>SUCCEEDED<ept id="p1">**</ept> 后，你可以从 Azure Blob 存储中检索作业的结果。随查询一起传递的 <ph id="ph1">`statusdir`</ph> 参数包含输出文件的位置；在本例中为 <bpt id="p2">**</bpt>wasb:///example/curl<ept id="p2">**</ept>。此地址会将作业的输出存储在 HDInsight 群集所用的默认存储容器的 <bpt id="p3">**</bpt>example/curl<ept id="p3">**</ept> 目录中。</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>可以使用 <bpt id="p1">[</bpt>Azure CLI<ept id="p1">](/documentation/articles/xplat-cli-install)</ept> 列出并下载这些文件。例如，若要列出 <bpt id="p2">**</bpt>example/curl<ept id="p2">**</ept> 中的文件，请使用以下命令：</source>
          <target state="new">可以使用 <bpt id="p1">[</bpt>Azure CLI<ept id="p1">](/documentation/articles/xplat-cli-install)</ept> 列出并下载这些文件。例如，若要列出 <bpt id="p2">**</bpt>example/curl<ept id="p2">**</ept> 中的文件，请使用以下命令：</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>若要下载文件，请使用以下命令：</source>
          <target state="new">若要下载文件，请使用以下命令：</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>你必须使用 <ph id="ph2">`-a`</ph> 和 <ph id="ph3">`-k`</ph> 参数指定包含 Blob 的存储帐户名称，或者设置 <bpt id="p1">**</bpt>AZURE\_STORAGE\_ACCOUNT<ept id="p1">**</ept> 和 <bpt id="p2">**</bpt>AZURE\_STORAGE\_ACCESS\_KEY<ept id="p2">**</ept> 环境变量。请参阅 &lt;a href="/documentation/articles/hdinsight-upload-data" target="\_blank" 了解详细信息。</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>你必须使用 <ph id="ph2">`-a`</ph> 和 <ph id="ph3">`-k`</ph> 参数指定包含 Blob 的存储帐户名称，或者设置 <bpt id="p1">**</bpt>AZURE\_STORAGE\_ACCOUNT<ept id="p1">**</ept> 和 <bpt id="p2">**</bpt>AZURE\_STORAGE\_ACCESS\_KEY<ept id="p2">**</ept> 环境变量。请参阅 &lt;a href="/documentation/articles/hdinsight-upload-data" target="\_blank" 了解详细信息。</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>使用以下语句创建名为 <bpt id="p1">**</bpt>errorLogs<ept id="p1">**</ept> 的新“内部”表：</source>
          <target state="new">使用以下语句创建名为 <bpt id="p1">**</bpt>errorLogs<ept id="p1">**</ept> 的新“内部”表：</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>这些语句将执行以下操作：</source>
          <target state="new">这些语句将执行以下操作：</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>CREATE TABLE IF NOT EXISTS<ept id="p1">**</ept> - 创建表（如果该表尚不存在）。由于未使用 <bpt id="p2">**</bpt>EXTERNAL<ept id="p2">**</ept> 关键字，因此这是一个“内部”表，它存储在 Hive 数据仓库中并完全受 Hive 的管理。</source>
          <target state="new"><bpt id="p1">**</bpt>CREATE TABLE IF NOT EXISTS<ept id="p1">**</ept> - 创建表（如果该表尚不存在）。由于未使用 <bpt id="p2">**</bpt>EXTERNAL<ept id="p2">**</ept> 关键字，因此这是一个“内部”表，它存储在 Hive 数据仓库中并完全受 Hive 的管理。</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>与外部表不同，删除内部表会同时删除基础数据。</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>与外部表不同，删除内部表会同时删除基础数据。</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>STORED AS ORC<ept id="p1">**</ept> - 以优化行纵栏表 (ORC) 格式存储数据。这是高度优化且有效的 Hive 数据存储格式。</source>
          <target state="new"><bpt id="p1">**</bpt>STORED AS ORC<ept id="p1">**</ept> - 以优化行纵栏表 (ORC) 格式存储数据。这是高度优化且有效的 Hive 数据存储格式。</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>INSERT OVERWRITE ...SELECT<ept id="p1">**</ept> - 从包含 <bpt id="p2">**</bpt>[ERROR]<ept id="p2">**</ept> 的 <bpt id="p3">**</bpt>log4jLogs<ept id="p3">**</ept> 表中选择行，然后将数据插入 <bpt id="p4">**</bpt>errorLogs<ept id="p4">**</ept> 表中。</source>
          <target state="new"><bpt id="p1">**</bpt>INSERT OVERWRITE ...SELECT<ept id="p1">**</ept> - 从包含 <bpt id="p2">**</bpt>[ERROR]<ept id="p2">**</ept> 的 <bpt id="p3">**</bpt>log4jLogs<ept id="p3">**</ept> 表中选择行，然后将数据插入 <bpt id="p4">**</bpt>errorLogs<ept id="p4">**</ept> 表中。</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>SELECT<ept id="p1">**</ept> - 选择新 <bpt id="p2">**</bpt>errorLogs<ept id="p2">**</ept> 表中的所有行。</source>
          <target state="new"><bpt id="p1">**</bpt>SELECT<ept id="p1">**</ept> - 选择新 <bpt id="p2">**</bpt>errorLogs<ept id="p2">**</ept> 表中的所有行。</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>使用返回的作业 ID 检查作业的状态。成功后，如前面所述使用适用于 Windows 的 Azure CLI 下载并查看结果。输出应包含三行，其中所有行都包含 <bpt id="p1">**</bpt>[ERROR]<ept id="p1">**</ept>。</source>
          <target state="new">使用返回的作业 ID 检查作业的状态。成功后，如前面所述使用适用于 Windows 的 Azure CLI 下载并查看结果。输出应包含三行，其中所有行都包含 <bpt id="p1">**</bpt>[ERROR]<ept id="p1">**</ept>。</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="summary"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>摘要</source>
          <target state="new"><ph id="ph1">&lt;a id="summary"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>摘要</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>如本文档中所示，你可以使用原始 HTTP 请求来运行、监视和查看 HDInsight 群集上的 Hive 作业的结果。</source>
          <target state="new">如本文档中所示，你可以使用原始 HTTP 请求来运行、监视和查看 HDInsight 群集上的 Hive 作业的结果。</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>有关本文中使用的 REST 接口的详细信息，请参阅 <ph id="ph1">&lt;a href="https://cwiki.apache.org/confluence/display/Hive/WebHCat+Reference" target="_blank"&gt;</ph>WebHCat 参考<ph id="ph2">&lt;/a&gt;</ph>。</source>
          <target state="new">有关本文中使用的 REST 接口的详细信息，请参阅 <ph id="ph1">&lt;a href="https://cwiki.apache.org/confluence/display/Hive/WebHCat+Reference" target="_blank"&gt;</ph>WebHCat 参考<ph id="ph2">&lt;/a&gt;</ph>。</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>后续步骤</source>
          <target state="new"><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>后续步骤</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>有关将 Hive 与 HDInsight 配合使用的一般信息：</source>
          <target state="new">有关将 Hive 与 HDInsight 配合使用的一般信息：</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>将 Hive 与 HDInsight 上的 Hadoop 配合使用</source>
          <target state="new">将 Hive 与 HDInsight 上的 Hadoop 配合使用</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>有关 HDInsight 上的 Hadoop 的其他使用方法的信息：</source>
          <target state="new">有关 HDInsight 上的 Hadoop 的其他使用方法的信息：</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>将 Pig 与 HDInsight 上的 Hadoop 配合使用</source>
          <target state="new">将 Pig 与 HDInsight 上的 Hadoop 配合使用</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>将 MapReduce 与 HDInsight 上的 Hadoop 配合使用</source>
          <target state="new">将 MapReduce 与 HDInsight 上的 Hadoop 配合使用</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>