<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="en-us">
    <header>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ht</xliffext:oltranslationpriority>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">c7e2a181f220cae7e06d91b823e83381262d107e</xliffext:olfilehash>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-02a95cf" tool-company="Microsoft" />
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>将 MapReduce 与 HDInsight 上的 Hadoop 配合使用 | Azure</source>
          <target state="new">将 MapReduce 与 HDInsight 上的 Hadoop 配合使用 | Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>学习如何在 HDInsight 上的 Hadoop 群集中运行 MapReduce 作业。你将运行一个实现为 Java MapReduce 作业的基本单词计数操作。</source>
          <target state="new">学习如何在 HDInsight 上的 Hadoop 群集中运行 MapReduce 作业。你将运行一个实现为 Java MapReduce 作业的基本单词计数操作。</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>在 HDInsight 上的 Hadoop 中使用 MapReduce</source>
          <target state="new">在 HDInsight 上的 Hadoop 中使用 MapReduce</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>在本文中，你将学习如何在 HDInsight 上的 Hadoop 群集中运行 MapReduce 作业。我们将运行一个实现为 Java MapReduce 作业的基本单词计数操作。</source>
          <target state="new">在本文中，你将学习如何在 HDInsight 上的 Hadoop 群集中运行 MapReduce 作业。我们将运行一个实现为 Java MapReduce 作业的基本单词计数操作。</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="whatis"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>什么是 MapReduce？</source>
          <target state="new"><ph id="ph1">&lt;a id="whatis"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>什么是 MapReduce？</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>Hadoop MapReduce 是一个软件框架，用于编写处理海量数据的作业。输入数据已拆分成独立的区块，这些区块将在群集中的节点之间并行处理。MapReduce 作业包括两个函数：</source>
          <target state="new">Hadoop MapReduce 是一个软件框架，用于编写处理海量数据的作业。输入数据已拆分成独立的区块，这些区块将在群集中的节点之间并行处理。MapReduce 作业包括两个函数：</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>映射器<ept id="p1">**</ept>：使用输入数据，对数据进行分析（通常使用筛选器和排序操作），然后发出 Tuple（键/值对）</source>
          <target state="new"><bpt id="p1">**</bpt>映射器<ept id="p1">**</ept>：使用输入数据，对数据进行分析（通常使用筛选器和排序操作），然后发出 Tuple（键/值对）</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>化简器<ept id="p1">**</ept>：使用映射器发出的 Tuple，并执行汇总运算，以基于映射器数据创建更小的合并结果</source>
          <target state="new"><bpt id="p1">**</bpt>化简器<ept id="p1">**</ept>：使用映射器发出的 Tuple，并执行汇总运算，以基于映射器数据创建更小的合并结果</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>下图演示了一个基本的单词计数 MapReduce 作业示例：</source>
          <target state="new">下图演示了一个基本的单词计数 MapReduce 作业示例：</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>HDI.WordCountDiagram</source>
          <target state="new">HDI.WordCountDiagram</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>此作业的输出是某个单词在所分析的文本中出现的次数。</source>
          <target state="new">此作业的输出是某个单词在所分析的文本中出现的次数。</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>映射器将输入文本中的每行用作一个输入并将其拆分为多个单词。每当文本中的单词后跟一个 1 时，映射器将发出一个键/值对。输出在发送到化简器之前经过排序。</source>
          <target state="new">映射器将输入文本中的每行用作一个输入并将其拆分为多个单词。每当文本中的单词后跟一个 1 时，映射器将发出一个键/值对。输出在发送到化简器之前经过排序。</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>随后，化简器会计算每个单词的计数的和并发出一个键/值对（包含单词，后跟该单词的总出现次数）。</source>
          <target state="new">随后，化简器会计算每个单词的计数的和并发出一个键/值对（包含单词，后跟该单词的总出现次数）。</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>可以使用多种语言实现 MapReduce。Java 是最常见的实现，本文档中使用该语言进行演示。</source>
          <target state="new">可以使用多种语言实现 MapReduce。Java 是最常见的实现，本文档中使用该语言进行演示。</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Hadoop 流式处理</source>
          <target state="new">Hadoop 流式处理</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>与 Java 应用程序一样，基于 Java 和 Java 虚拟机（例如 Scalding 或 Cascading）的语言或框架可以直接作为 MapReduce 作业运行。其他实体（例如 C# 或 Python）或独立的可执行文件必须使用 Hadoop 流式处理。</source>
          <target state="new">与 Java 应用程序一样，基于 Java 和 Java 虚拟机（例如 Scalding 或 Cascading）的语言或框架可以直接作为 MapReduce 作业运行。其他实体（例如 C# 或 Python）或独立的可执行文件必须使用 Hadoop 流式处理。</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>Hadoop 流式处理通过 STDIN 和 STDOUT 与映射器和化简器通信 - 映射器和化简器每次从 STDIN 读取一行数据，并将输出写入到 STDOUT。读取的每行或者由映射器和化简器发出的每行必须采用制表符分隔的键/值对格式：</source>
          <target state="new">Hadoop 流式处理通过 STDIN 和 STDOUT 与映射器和化简器通信 - 映射器和化简器每次从 STDIN 读取一行数据，并将输出写入到 STDOUT。读取的每行或者由映射器和化简器发出的每行必须采用制表符分隔的键/值对格式：</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>有关详细信息，请参阅 <bpt id="p1">[</bpt>Hadoop 流式处理<ept id="p1">](http://hadoop.apache.org/docs/r1.2.1/streaming.html)</ept>。</source>
          <target state="new">有关详细信息，请参阅 <bpt id="p1">[</bpt>Hadoop 流式处理<ept id="p1">](http://hadoop.apache.org/docs/r1.2.1/streaming.html)</ept>。</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>有关将 Hadoop 流式处理与 hdinsight 配合使用的示例，请参阅：</source>
          <target state="new">有关将 Hadoop 流式处理与 hdinsight 配合使用的示例，请参阅：</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>开发 C# Hadoop 流式处理程序</source>
          <target state="new">开发 C# Hadoop 流式处理程序</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="data"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>关于示例数据</source>
          <target state="new"><ph id="ph1">&lt;a id="data"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>关于示例数据</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>对于本示例中的示例数据，你将使用 HDInsight 群集中作为文本文档提供的 Leonardo Da Vinci 笔记本。</source>
          <target state="new">对于本示例中的示例数据，你将使用 HDInsight 群集中作为文本文档提供的 Leonardo Da Vinci 笔记本。</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>示例数据存储在 Azure Blob 存储中，HDInsight 可以将该存储用作 Hadoop 群集的默认文件系统。HDInsight 可以使用 <bpt id="p1">**</bpt>wasb<ept id="p1">**</ept> 前缀访问 Blob 存储中存储的文件。例如，若要访问 sample.log 文件，可使用以下语法：</source>
          <target state="new">示例数据存储在 Azure Blob 存储中，HDInsight 可以将该存储用作 Hadoop 群集的默认文件系统。HDInsight 可以使用 <bpt id="p1">**</bpt>wasb<ept id="p1">**</ept> 前缀访问 Blob 存储中存储的文件。例如，若要访问 sample.log 文件，可使用以下语法：</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>由于 Azure Blob 存储是 HDInsight 的默认存储，因此你也可以使用 <bpt id="p1">**</bpt>/example/data/gutenberg/davinci.txt<ept id="p1">**</ept> 访问该文件。</source>
          <target state="new">由于 Azure Blob 存储是 HDInsight 的默认存储，因此你也可以使用 <bpt id="p1">**</bpt>/example/data/gutenberg/davinci.txt<ept id="p1">**</ept> 访问该文件。</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>在上述语法中，****wasb:///** 用于访问 HDInsight 群集的默认存储容器中存储的文件。如果你在设置群集时指定了其他存储帐户，并想要访问这些帐户中存储的文件，你可以指定容器名称和存储帐户地址来访问数据。例如 ****wasb://mycontainer@mystorage.blob.core.chinacloudapi.cn/example/data/gutenberg/davinci.txt**。</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>在上述语法中，****wasb:///** 用于访问 HDInsight 群集的默认存储容器中存储的文件。如果你在设置群集时指定了其他存储帐户，并想要访问这些帐户中存储的文件，你可以指定容器名称和存储帐户地址来访问数据。例如 ****wasb://mycontainer@mystorage.blob.core.chinacloudapi.cn/example/data/gutenberg/davinci.txt**。</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="job"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>关于示例 MapReduce</source>
          <target state="new"><ph id="ph1">&lt;a id="job"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>关于示例 MapReduce</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>本示例中使用的 MapReduce 作业位于 HDInsight 群集随附的 ****wasb://example/jars/hadoop-mapreduce-examples.jar** 中。其中包含一个你要针对 <bpt id="p1">**</bpt>davinci.txt<ept id="p1">**</ept> 运行的单词计数示例。</source>
          <target state="new">本示例中使用的 MapReduce 作业位于 HDInsight 群集随附的 ****wasb://example/jars/hadoop-mapreduce-examples.jar** 中。其中包含一个你要针对 <bpt id="p1">**</bpt>davinci.txt<ept id="p1">**</ept> 运行的单词计数示例。</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>在 HDInsight 2.1 群集上，该文件位置为 ****wasb:///example/jars/hadoop-examples.jar**。</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>在 HDInsight 2.1 群集上，该文件位置为 ****wasb:///example/jars/hadoop-examples.jar**。</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>下面提供了单词计数 MapReduce 作业的 Java 代码供你参考：</source>
          <target state="new">下面提供了单词计数 MapReduce 作业的 Java 代码供你参考：</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>有关编写自己的 MapReduce 作业的说明，请参阅<bpt id="p1">[</bpt>为 HDInsight 开发 Java MapReduce 程序<ept id="p1">](/documentation/articles/hdinsight-develop-deploy-java-mapreduce)</ept>。</source>
          <target state="new">有关编写自己的 MapReduce 作业的说明，请参阅<bpt id="p1">[</bpt>为 HDInsight 开发 Java MapReduce 程序<ept id="p1">](/documentation/articles/hdinsight-develop-deploy-java-mapreduce)</ept>。</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="run"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>运行 MapReduce</source>
          <target state="new"><ph id="ph1">&lt;a id="run"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>运行 MapReduce</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>HDInsight 可以使用各种方法运行 HiveQL 作业。使用下表来确定哪种方法最适合你，然后按链接进行演练。</source>
          <target state="new">HDInsight 可以使用各种方法运行 HiveQL 作业。使用下表来确定哪种方法最适合你，然后按链接进行演练。</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>使用此方法<ept id="p1">**</ept>...</source>
          <target state="new"><bpt id="p1">**</bpt>使用此方法<ept id="p1">**</ept>...</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>...实现此目的</source>
          <target state="new">...实现此目的</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>...使用此<bpt id="p1">**</bpt>群集操作系统<ept id="p1">**</ept></source>
          <target state="new">...使用此<bpt id="p1">**</bpt>群集操作系统<ept id="p1">**</ept></target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>...从此<bpt id="p1">**</bpt>客户端操作系统<ept id="p1">**</ept></source>
          <target state="new">...从此<bpt id="p1">**</bpt>客户端操作系统<ept id="p1">**</ept></target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>Curl</source>
          <target state="new">Curl</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>使用 <bpt id="p1">**</bpt>REST<ept id="p1">**</ept> 远程提交作业</source>
          <target state="new">使用 <bpt id="p1">**</bpt>REST<ept id="p1">**</ept> 远程提交作业</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>Windows</source>
          <target state="new">Windows</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>Windows</source>
          <target state="new">Windows</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>Windows PowerShell</source>
          <target state="new">Windows PowerShell</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>使用 <bpt id="p1">**</bpt>Windows PowerShell<ept id="p1">**</ept> 远程提交作业</source>
          <target state="new">使用 <bpt id="p1">**</bpt>Windows PowerShell<ept id="p1">**</ept> 远程提交作业</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>Windows</source>
          <target state="new">Windows</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>Windows</source>
          <target state="new">Windows</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>远程桌面</source>
          <target state="new">远程桌面</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>通过<bpt id="p1">**</bpt>远程桌面<ept id="p1">**</ept>使用 Hadoop 命令</source>
          <target state="new">通过<bpt id="p1">**</bpt>远程桌面<ept id="p1">**</ept>使用 Hadoop 命令</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>Windows</source>
          <target state="new">Windows</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>Windows</source>
          <target state="new">Windows</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>后续步骤</source>
          <target state="new"><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>后续步骤</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>虽然 MapReduce 提供了强大的诊断功能，但掌握起来可能会比较困难。有多个基于 Java 的框架可让你更轻松地定义 MapReduce 应用程序，还有一些技术（例如 Pig 和 Hive）可让你更方便地在 HDInsight 中处理数据。若要了解更多信息，请参阅下列文章：</source>
          <target state="new">虽然 MapReduce 提供了强大的诊断功能，但掌握起来可能会比较困难。有多个基于 Java 的框架可让你更轻松地定义 MapReduce 应用程序，还有一些技术（例如 Pig 和 Hive）可让你更方便地在 HDInsight 中处理数据。若要了解更多信息，请参阅下列文章：</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>为 HDInsight 开发 Java MapReduce 程序</source>
          <target state="new">为 HDInsight 开发 Java MapReduce 程序</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>将 Hive 与 HDInsight 配合使用</source>
          <target state="new">将 Hive 与 HDInsight 配合使用</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>将 Pig 与 HDInsight 配合使用</source>
          <target state="new">将 Pig 与 HDInsight 配合使用</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>运行 HDInsight 示例</source>
          <target state="new">运行 HDInsight 示例</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>