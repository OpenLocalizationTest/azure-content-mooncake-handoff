<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="en-us">
    <header>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ht</xliffext:oltranslationpriority>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">c2b9cb19b16be95b84004aa26e41b934b9ec7575</xliffext:olfilehash>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-02a95cf" tool-company="Microsoft" />
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>使用 HDInsight 中的 Hive 分析和处理 JSON 文档 | Azure</source>
          <target state="new">使用 HDInsight 中的 Hive 分析和处理 JSON 文档 | Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>了解如何使用 JSON 文档，以及如何使用 HDInsight 中的 Hive 来分析这些文档。</source>
          <target state="new">了解如何使用 JSON 文档，以及如何使用 HDInsight 中的 Hive 来分析这些文档。</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>使用 HDInsight 中的 Hive 处理和分析 JSON 文档</source>
          <target state="new">使用 HDInsight 中的 Hive 处理和分析 JSON 文档</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>了解如何使用 HDInsight 中的 Hive 处理和分析 JSON 文件。本教程将使用以下 JSON 文档</source>
          <target state="new">了解如何使用 HDInsight 中的 Hive 处理和分析 JSON 文件。本教程将使用以下 JSON 文档</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>可以在 wasb://processjson@hditutorialdata.blob.core.windows.net/ 上找到该文件。有关将 Azure Blob 存储与 HDInsight 配合使用的详细信息，请参阅<bpt id="p1">[</bpt>将 HDFS 兼容的 Azure Blob 存储与 HDInsight 中的 Hadoop 配合使用<ept id="p1">](/documentation/articles/hdinsight-hadoop-use-blob-storage)</ept>。如果需要，你可以将该文件复制到群集的默认容器。</source>
          <target state="new">可以在 wasb://processjson@hditutorialdata.blob.core.windows.net/ 上找到该文件。有关将 Azure Blob 存储与 HDInsight 配合使用的详细信息，请参阅<bpt id="p1">[</bpt>将 HDFS 兼容的 Azure Blob 存储与 HDInsight 中的 Hadoop 配合使用<ept id="p1">](/documentation/articles/hdinsight-hadoop-use-blob-storage)</ept>。如果需要，你可以将该文件复制到群集的默认容器。</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>在本教程中，你将使用 Hive 控制台。有关打开 Hive 控制台的说明，请参阅<bpt id="p1">[</bpt>通过远程桌面将 Hive 与 HDInsight 上的 Hadoop 配合使用<ept id="p1">](/documentation/articles/hdinsight-hadoop-use-hive-remote-desktop)</ept>。</source>
          <target state="new">在本教程中，你将使用 Hive 控制台。有关打开 Hive 控制台的说明，请参阅<bpt id="p1">[</bpt>通过远程桌面将 Hive 与 HDInsight 上的 Hadoop 配合使用<ept id="p1">](/documentation/articles/hdinsight-hadoop-use-hive-remote-desktop)</ept>。</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>平展 JSON 文档</source>
          <target state="new">平展 JSON 文档</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>下一部分中所列的方法需要 JSON 文档在单一行中。因此，你必须将 JSON 文档平展成字符串。如果 JSON 文档已平展，则你可以跳过此步骤，直接转到有关分析 JSON 数据的下一部分。</source>
          <target state="new">下一部分中所列的方法需要 JSON 文档在单一行中。因此，你必须将 JSON 文档平展成字符串。如果 JSON 文档已平展，则你可以跳过此步骤，直接转到有关分析 JSON 数据的下一部分。</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>原始 JSON 文件位于 <bpt id="p1">**</bpt>wasb://processjson@hditutorialdata.blob.core.windows.net/<ept id="p1">**</ept>。 <bpt id="p2">*</bpt>StudentsRaw<ept id="p2">*</ept> Hive 表指向原始的未平展 JSON 文档。</source>
          <target state="new">原始 JSON 文件位于 <bpt id="p1">**</bpt>wasb://processjson@hditutorialdata.blob.core.windows.net/<ept id="p1">**</ept>。 <bpt id="p2">*</bpt>StudentsRaw<ept id="p2">*</ept> Hive 表指向原始的未平展 JSON 文档。</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source><bpt id="p1">*</bpt>StudentsOneLine<ept id="p1">*</ept> Hive 表将数据存储在 HDInsight 默认文件系统中的 <bpt id="p2">*</bpt>/json/students/<ept id="p2">*</ept> 路径下。</source>
          <target state="new"><bpt id="p1">*</bpt>StudentsOneLine<ept id="p1">*</ept> Hive 表将数据存储在 HDInsight 默认文件系统中的 <bpt id="p2">*</bpt>/json/students/<ept id="p2">*</ept> 路径下。</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>INSERT 语句在 StudentOneLine 表中填充平展的 JSON 数据。</source>
          <target state="new">INSERT 语句在 StudentOneLine 表中填充平展的 JSON 数据。</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>SELECT 语句应只返回 1 行。</source>
          <target state="new">SELECT 语句应只返回 1 行。</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>下面是 SELECT 语句的输出：</source>
          <target state="new">下面是 SELECT 语句的输出：</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>平展 JSON 文档。</source>
          <target state="new">平展 JSON 文档。</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>在 Hive 中分析 JSON 文档</source>
          <target state="new">在 Hive 中分析 JSON 文档</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>Hive 提供了三种不同的机制用于对 JSON 文档运行查询：</source>
          <target state="new">Hive 提供了三种不同的机制用于对 JSON 文档运行查询：</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>使用 GET\_JSON\_OBJECT UDF（用户定义的函数）</source>
          <target state="new">使用 GET\_JSON\_OBJECT UDF（用户定义的函数）</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>使用 JSON\_TUPLE UDF</source>
          <target state="new">使用 JSON\_TUPLE UDF</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>使用自定义 SerDe</source>
          <target state="new">使用自定义 SerDe</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>使用 Python 或其他语言编写你自己的 UDF。请参阅<bpt id="p1">[</bpt>此文<ept id="p1">][hdinsight-python]</ept>，了解如何使用 Hive 运行自己的 Python 代码。</source>
          <target state="new">使用 Python 或其他语言编写你自己的 UDF。请参阅<bpt id="p1">[</bpt>此文<ept id="p1">][hdinsight-python]</ept>，了解如何使用 Hive 运行自己的 Python 代码。</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>使用 GET\_JSON\_OBJECT UDF</source>
          <target state="new">使用 GET\_JSON\_OBJECT UDF</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>Hive 提供了名为 <bpt id="p1">[</bpt>get\_json\_object<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object)</ept> 的内置 UDF，它可以在运行时执行 JSON 查询。此方法采用两个参数 – 表名称和方法名称，具有平展的 JSON 文档和需要进行分析的 JSON 字段。让我们来探讨一个示例，以了解此 UDF 的工作原理。</source>
          <target state="new">Hive 提供了名为 <bpt id="p1">[</bpt>get\_json\_object<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object)</ept> 的内置 UDF，它可以在运行时执行 JSON 查询。此方法采用两个参数 – 表名称和方法名称，具有平展的 JSON 文档和需要进行分析的 JSON 字段。让我们来探讨一个示例，以了解此 UDF 的工作原理。</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>获取每个学生的名字和姓氏</source>
          <target state="new">获取每个学生的名字和姓氏</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>这是在控制台窗口中运行此查询时的输出。</source>
          <target state="new">这是在控制台窗口中运行此查询时的输出。</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>get\_json\_object UDF</source>
          <target state="new">get\_json\_object UDF</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>get-json\_object UDF 有一些限制。</source>
          <target state="new">get-json\_object UDF 有一些限制。</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>由于查询中的每个字段都需要重新分析查询，因此会影响性能。</source>
          <target state="new">由于查询中的每个字段都需要重新分析查询，因此会影响性能。</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>GET\_JSON\_OBJECT() 返回数组的字符串表示形式。若要将其转换为 Hive 数组，你必须使用正则表达式来替换方括号“[”和“]”，然后调用拆分来获取数组。</source>
          <target state="new">GET\_JSON\_OBJECT() 返回数组的字符串表示形式。若要将其转换为 Hive 数组，你必须使用正则表达式来替换方括号“[”和“]”，然后调用拆分来获取数组。</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>正因如此，Hive wiki 建议使用 json\_tuple。</source>
          <target state="new">正因如此，Hive wiki 建议使用 json\_tuple。</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>使用 JSON\_TUPLE UDF</source>
          <target state="new">使用 JSON\_TUPLE UDF</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>Hive 提供的另一个 UDF 称为 <bpt id="p1">[</bpt>json\_tuple<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-json_tuple)</ept>，其性能比 <bpt id="p2">[</bpt>get\_ json \_object<ept id="p2">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object)</ept> 要高。此方法采用一组键和一个 JSON 字符串，并使用一个函数返回值的元组。以下查询将从 JSON 文档返回学生 ID 和年级：</source>
          <target state="new">Hive 提供的另一个 UDF 称为 <bpt id="p1">[</bpt>json\_tuple<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-json_tuple)</ept>，其性能比 <bpt id="p2">[</bpt>get\_ json \_object<ept id="p2">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object)</ept> 要高。此方法采用一组键和一个 JSON 字符串，并使用一个函数返回值的元组。以下查询将从 JSON 文档返回学生 ID 和年级：</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>此脚本在 Hive 控制台中的输出：</source>
          <target state="new">此脚本在 Hive 控制台中的输出：</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>json\_tuple UDF</source>
          <target state="new">json\_tuple UDF</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>JSON\_TUPLE 在 Hive 中使用了<bpt id="p1">[</bpt>横向视图<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView)</ept>语法，使 json\_tuple 能够通过将 UDT 函数应用于原始表的每一行来创建虚拟表。由于重复使用横向视图，复杂的 JSON 会变得过于庞大。此外，JSON_TUPLE 无法处理嵌套的 JSONs。</source>
          <target state="new">JSON\_TUPLE 在 Hive 中使用了<bpt id="p1">[</bpt>横向视图<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView)</ept>语法，使 json\_tuple 能够通过将 UDT 函数应用于原始表的每一行来创建虚拟表。由于重复使用横向视图，复杂的 JSON 会变得过于庞大。此外，JSON_TUPLE 无法处理嵌套的 JSONs。</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>使用自定义 SerDe</source>
          <target state="new">使用自定义 SerDe</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>SerDe 是用于分析嵌套 JSON 文档的最佳选择，它可让你定义 JSON 架构，并使用该架构来分析文档。在本教程中，你将使用其中 <bpt id="p1">[</bpt>rcongiu<ept id="p1">](https://github.com/rcongiu)</ept> 开发的热门 SerDe 之一。</source>
          <target state="new">SerDe 是用于分析嵌套 JSON 文档的最佳选择，它可让你定义 JSON 架构，并使用该架构来分析文档。在本教程中，你将使用其中 <bpt id="p1">[</bpt>rcongiu<ept id="p1">](https://github.com/rcongiu)</ept> 开发的热门 SerDe 之一。</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>使用自定义 SerDe：</source>
          <target state="new">使用自定义 SerDe：</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>安装 <bpt id="p1">[</bpt>Java SE 开发工具包 7u55 JDK 1.7.0_55<ept id="p1">](http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html#jdk-7u55-oth-JPR)</ept>。如果你要使用 HDInsight 的 Windows 部署，请选择 Windows X64 版本的 JDK。</source>
          <target state="new">安装 <bpt id="p1">[</bpt>Java SE 开发工具包 7u55 JDK 1.7.0_55<ept id="p1">](http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html#jdk-7u55-oth-JPR)</ept>。如果你要使用 HDInsight 的 Windows 部署，请选择 Windows X64 版本的 JDK。</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.WARNING]</ph>JDK 1.8 不适用于此 SerDe。</source>
          <target state="new"><ph id="ph1">[AZURE.WARNING]</ph>JDK 1.8 不适用于此 SerDe。</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>安装完成之后，请添加新的用户环境变量：</source>
          <target state="new">安装完成之后，请添加新的用户环境变量：</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>从 Windows 屏幕打开“查看高级系统设置”。</source>
          <target state="new">从 Windows 屏幕打开“查看高级系统设置”。</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>单击“环境变量”。</source>
          <target state="new">单击“环境变量”。</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>添加指向 <bpt id="p1">**</bpt>C:\\Program Files\\Java\\jdk1.7.0\_55<ept id="p1">**</ept> 或任何 JDK 安装位置的新 <bpt id="p2">**</bpt>JAVA_HOME<ept id="p2">**</ept> 环境变量。</source>
          <target state="new">添加指向 <bpt id="p1">**</bpt>C:\\Program Files\\Java\\jdk1.7.0\_55<ept id="p1">**</ept> 或任何 JDK 安装位置的新 <bpt id="p2">**</bpt>JAVA_HOME<ept id="p2">**</ept> 环境变量。</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>为 JDK 设置正确的配置值</source>
          <target state="new">为 JDK 设置正确的配置值</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>安装 <bpt id="p1">[</bpt>Maven 3.3.1<ept id="p1">](http://mirror.olnevhost.net/pub/apache/maven/maven-3/3.3.1/binaries/apache-maven-3.3.1-bin.zip)</ept></source>
          <target state="new">安装 <bpt id="p1">[</bpt>Maven 3.3.1<ept id="p1">](http://mirror.olnevhost.net/pub/apache/maven/maven-3/3.3.1/binaries/apache-maven-3.3.1-bin.zip)</ept></target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>转到“控件面板”-&gt;“编辑系统变量”（对应于你帐户的环境变量），将 bin 文件夹添加到你的路径。以下屏幕截图显示了如何执行此操作。</source>
          <target state="new">转到“控件面板”-&gt;“编辑系统变量”（对应于你帐户的环境变量），将 bin 文件夹添加到你的路径。以下屏幕截图显示了如何执行此操作。</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>设置 Maven</source>
          <target state="new">设置 Maven</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>从 <bpt id="p1">[</bpt>Hive-JSON-SerDe<ept id="p1">](https://github.com/sheetaldolas/Hive-JSON-Serde/tree/master)</ept> github 站点克隆项目。可以通过按以下屏幕截图中所示单击“下载 Zip”按钮来实现此目的。</source>
          <target state="new">从 <bpt id="p1">[</bpt>Hive-JSON-SerDe<ept id="p1">](https://github.com/sheetaldolas/Hive-JSON-Serde/tree/master)</ept> github 站点克隆项目。可以通过按以下屏幕截图中所示单击“下载 Zip”按钮来实现此目的。</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>克隆项目</source>
          <target state="new">克隆项目</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>4：转到此包下载到的文件夹，然后键入“mvn package”。这应会创建必要的 jar 文件，然后你可以将其复制到群集。</source>
          <target state="new">4：转到此包下载到的文件夹，然后键入“mvn package”。这应会创建必要的 jar 文件，然后你可以将其复制到群集。</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>5：转到根文件夹下存放所下载包的目标文件夹。将 json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar 文件上载到群集的头节点。我通常会将它放在 hive bin 文件夹下：C:\\apps\\dist\\hive-0.13.0.2.1.11.0-2316\\bin 或类似的文件夹。</source>
          <target state="new">5：转到根文件夹下存放所下载包的目标文件夹。将 json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar 文件上载到群集的头节点。我通常会将它放在 hive bin 文件夹下：C:\\apps\\dist\\hive-0.13.0.2.1.11.0-2316\\bin 或类似的文件夹。</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>6：在 hive 提示符下，键入“add jar /path/to/json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar”。由于在我的示例中，jar 在 C:\\apps\\dist\\hive-0.13.x\\bin 文件夹中，因此我可以直接添加名称如下的 jar：</source>
          <target state="new">6：在 hive 提示符下，键入“add jar /path/to/json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar”。由于在我的示例中，jar 在 C:\\apps\\dist\\hive-0.13.x\\bin 文件夹中，因此我可以直接添加名称如下的 jar：</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>现在，你可以使用 SerDe 对 JSON 文档运行查询。</source>
          <target state="new">现在，你可以使用 SerDe 对 JSON 文档运行查询。</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>以下语句将创建使用所定义架构的表</source>
          <target state="new">以下语句将创建使用所定义架构的表</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>列出学生的名字和姓氏</source>
          <target state="new">列出学生的名字和姓氏</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>下面是 Hive 控制台输出的结果。</source>
          <target state="new">下面是 Hive 控制台输出的结果。</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>SerDe 查询 1</source>
          <target state="new">SerDe 查询 1</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>计算 JSON 文档的总分</source>
          <target state="new">计算 JSON 文档的总分</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>以上查询使用 <bpt id="p1">[</bpt>lateral view explode<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView)</ept> UDF 展开分数数组，以便可以求和。</source>
          <target state="new">以上查询使用 <bpt id="p1">[</bpt>lateral view explode<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView)</ept> UDF 展开分数数组，以便可以求和。</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>下面是 Hive 控制台的输出。</source>
          <target state="new">下面是 Hive 控制台的输出。</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>SerDe 查询 2</source>
          <target state="new">SerDe 查询 2</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>查找给定的学生在哪些科目取得了 80 以上的分数 SELECT jt.StudentClassCollection.ClassId FROM json\_table jt lateral view explode(jt.StudentClassCollection.Score) collection as score where score &gt; 80;</source>
          <target state="new">查找给定的学生在哪些科目取得了 80 以上的分数 SELECT jt.StudentClassCollection.ClassId FROM json\_table jt lateral view explode(jt.StudentClassCollection.Score) collection as score where score &gt; 80;</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>上面的查询将返回一个 Hive 数组，这与 get\_json\_object 不同，后者返回一个字符串。</source>
          <target state="new">上面的查询将返回一个 Hive 数组，这与 get\_json\_object 不同，后者返回一个字符串。</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>SerDe 查询 3</source>
          <target state="new">SerDe 查询 3</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>如果你想要跳过格式不正确的 JSON，可以根据此 SerDe 的 <bpt id="p1">[</bpt>wiki 页面<ept id="p1">](https://github.com/sheetaldolas/Hive-JSON-Serde/tree/master)</ept>中所述，通过键入以下代码实现此目的：</source>
          <target state="new">如果你想要跳过格式不正确的 JSON，可以根据此 SerDe 的 <bpt id="p1">[</bpt>wiki 页面<ept id="p1">](https://github.com/sheetaldolas/Hive-JSON-Serde/tree/master)</ept>中所述，通过键入以下代码实现此目的：</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>摘要</source>
          <target state="new">摘要</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>总之，在 Hive 中选择的 JSON 运算符类型取决于你的方案。如果你有一个简单的 JSON 文档，并只有一个要查找的字段，则你可以选择使用 Hive UDF get\_json\_object。如果你有多个键用于查找，则可以使用 json\_tuple。如果你有嵌套的文档，则应使用 JSON SerDe。</source>
          <target state="new">总之，在 Hive 中选择的 JSON 运算符类型取决于你的方案。如果你有一个简单的 JSON 文档，并只有一个要查找的字段，则你可以选择使用 Hive UDF get\_json\_object。如果你有多个键用于查找，则可以使用 json\_tuple。如果你有嵌套的文档，则应使用 JSON SerDe。</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>如需其他相关文章，请参阅</source>
          <target state="new">如需其他相关文章，请参阅</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>将 Hive 和 HiveQL 与 HDInsight 中的 Hadoop 配合使用以分析示例 Apache log4j 文件</source>
          <target state="new">将 Hive 和 HiveQL 与 HDInsight 中的 Hadoop 配合使用以分析示例 Apache log4j 文件</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>使用 HDInsight 中的 Hive 分析航班延误数据</source>
          <target state="new">使用 HDInsight 中的 Hive 分析航班延误数据</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>