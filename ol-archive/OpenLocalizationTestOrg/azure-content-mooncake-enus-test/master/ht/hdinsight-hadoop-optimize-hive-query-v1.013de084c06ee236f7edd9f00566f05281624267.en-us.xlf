<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="en-us">
    <header>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ht</xliffext:oltranslationpriority>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">3e47ce5f6a458018cdfd83305ad9bf285614aeea</xliffext:olfilehash>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-02a95cf" tool-company="Microsoft" />
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>优化 Hive 查询以便在 HDInsight 中更快地执行 | Azure</source>
          <target state="new">优化 Hive 查询以便在 HDInsight 中更快地执行 | Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>了解如何在 HDInsight 中优化 Hive 查询</source>
          <target state="new">了解如何在 HDInsight 中优化 Hive 查询</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>在 Hdinsight 中优化 Hadoop 的 Hive 查询</source>
          <target state="new">在 Hdinsight 中优化 Hadoop 的 Hive 查询</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>默认情况下，不会为了性能而优化 Hadoop 群集。本文介绍可对查询应用的几种最常见 Hive 性能优化方法。</source>
          <target state="new">默认情况下，不会为了性能而优化 Hadoop 群集。本文介绍可对查询应用的几种最常见 Hive 性能优化方法。</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>向外缩放辅助节点</source>
          <target state="new">向外缩放辅助节点</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>增加群集中的辅助节点数目，即可利用更多并行运行的映射器和化简器。在 HDInsight 中，可通过两种方式增加扩大的数目：</source>
          <target state="new">增加群集中的辅助节点数目，即可利用更多并行运行的映射器和化简器。在 HDInsight 中，可通过两种方式增加扩大的数目：</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>在预配时，可以使用 Azure 门户、Azure PowerShell 或跨平台命令行界面指定辅助节点的数目。有关详细信息，请参阅<bpt id="p1">[</bpt>设置 HDInsight 群集<ept id="p1">](/documentation/articles/hdinsight-provision-clusters-v1)</ept>。以下屏幕显示了 Azure 门户上的辅助节点配置：</source>
          <target state="new">在预配时，可以使用 Azure 门户、Azure PowerShell 或跨平台命令行界面指定辅助节点的数目。有关详细信息，请参阅<bpt id="p1">[</bpt>设置 HDInsight 群集<ept id="p1">](/documentation/articles/hdinsight-provision-clusters-v1)</ept>。以下屏幕显示了 Azure 门户上的辅助节点配置：</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>scaleout\_1</source>
          <target state="new">scaleout\_1</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>在运行时，你也可以向外缩放群集，而无需重建群集。如下所示。</source>
          <target state="new">在运行时，你也可以向外缩放群集，而无需重建群集。如下所示。</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>scaleout\_1</source>
          <target state="new">scaleout\_1</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>有关 HDInsight 支持的不同虚拟机的详细信息，请参阅 <bpt id="p1">[</bpt>HDInsight 定价<ept id="p1">](/home/features/hdinsight/#price)</ept>。</source>
          <target state="new">有关 HDInsight 支持的不同虚拟机的详细信息，请参阅 <bpt id="p1">[</bpt>HDInsight 定价<ept id="p1">](/home/features/hdinsight/#price)</ept>。</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>启用 Tez</source>
          <target state="new">启用 Tez</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt>Apache Tez<ept id="p1">](http://hortonworks.com/hadoop/tez/)</ept> 是 MapReduce 引擎的替代执行引擎：</source>
          <target state="new"><bpt id="p1">[</bpt>Apache Tez<ept id="p1">](http://hortonworks.com/hadoop/tez/)</ept> 是 MapReduce 引擎的替代执行引擎：</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>tez_1</source>
          <target state="new">tez_1</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>Tez 速度更快，因为：</source>
          <target state="new">Tez 速度更快，因为：</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>在 MapReduce 引擎中以单个作业执行定向无圈图 (DAG)，表达的 DAG 要求每组映射器后接一组化简器。这会导致针对每个 Hive 查询运行多个 MapReduce 作业。Tez 没有这种局限性，它可以将复杂的 DAG 作为一个作业进行处理，因此将作业启动开销降到最低。</source>
          <target state="new">在 MapReduce 引擎中以单个作业执行定向无圈图 (DAG)，表达的 DAG 要求每组映射器后接一组化简器。这会导致针对每个 Hive 查询运行多个 MapReduce 作业。Tez 没有这种局限性，它可以将复杂的 DAG 作为一个作业进行处理，因此将作业启动开销降到最低。</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>避免不必要的写入<ept id="p1">**</ept>。由于要为 MapReduce 引擎的同一 Hive 查询运行多个作业，每个作业的输出将写入 HDFS 以用作暂存数据。而 Tez 最大程度地减少了对每个 Hive 查询运行的作业数，因此能够避免不必要的写入。</source>
          <target state="new"><bpt id="p1">**</bpt>避免不必要的写入<ept id="p1">**</ept>。由于要为 MapReduce 引擎的同一 Hive 查询运行多个作业，每个作业的输出将写入 HDFS 以用作暂存数据。而 Tez 最大程度地减少了对每个 Hive 查询运行的作业数，因此能够避免不必要的写入。</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>最大程度地降低启动延迟<ept id="p1">**</ept>。Tez 可以减少需要启动的映射器数目，同时还能提高优化吞吐量，因此，更有利于最小化启动延迟。</source>
          <target state="new"><bpt id="p1">**</bpt>最大程度地降低启动延迟<ept id="p1">**</ept>。Tez 可以减少需要启动的映射器数目，同时还能提高优化吞吐量，因此，更有利于最小化启动延迟。</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>重复使用容器<ept id="p1">**</ept>。Tez 会尽可能地重复使用容器，以确保降低由于启动容器而产生的延迟。</source>
          <target state="new"><bpt id="p1">**</bpt>重复使用容器<ept id="p1">**</ept>。Tez 会尽可能地重复使用容器，以确保降低由于启动容器而产生的延迟。</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>连续优化技术<ept id="p1">**</ept>。传统上，优化是在编译阶段完成的。但是，这可以提供有关输入的详细信息，以便在运行时更好地进行优化。Tez 使用连续优化技术，从而可以在运行时阶段进一步优化计划。</source>
          <target state="new"><bpt id="p1">**</bpt>连续优化技术<ept id="p1">**</ept>。传统上，优化是在编译阶段完成的。但是，这可以提供有关输入的详细信息，以便在运行时更好地进行优化。Tez 使用连续优化技术，从而可以在运行时阶段进一步优化计划。</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>有关这些概念的详细信息，请单击<bpt id="p1">[</bpt>此处<ept id="p1">](http://hortonworks.com/hadoop/tez/)</ept></source>
          <target state="new">有关这些概念的详细信息，请单击<bpt id="p1">[</bpt>此处<ept id="p1">](http://hortonworks.com/hadoop/tez/)</ept></target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>你可以通过在查询的前面加上以下设置作为前缀，来执行 Tez 支持的任何 Hive 查询：</source>
          <target state="new">你可以通过在查询的前面加上以下设置作为前缀，来执行 Tez 支持的任何 Hive 查询：</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>必须在预配时启用 Tez。以下 Azure PowerShell 脚本示例用于预配已启用 Tez 的 Hadoop 群集：</source>
          <target state="new">必须在预配时启用 Tez。以下 Azure PowerShell 脚本示例用于预配已启用 Tez 的 Hadoop 群集：</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Hive 分区</source>
          <target state="new">Hive 分区</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>I/O 操作是运行 Hive 查询的主要性能瓶颈。如果可以减少需要读取的数据量，即可改善性能。默认情况下，Hive 查询扫描整个 Hive 表。对于表扫描之类的查询，这非常有利；但是，对于只需扫描少量数据的查询（例如，使用筛选进行查询），这会产生不必要的开销。使用 Hive 分区，Hive 查询只需访问 Hive 表中必要的数据量。</source>
          <target state="new">I/O 操作是运行 Hive 查询的主要性能瓶颈。如果可以减少需要读取的数据量，即可改善性能。默认情况下，Hive 查询扫描整个 Hive 表。对于表扫描之类的查询，这非常有利；但是，对于只需扫描少量数据的查询（例如，使用筛选进行查询），这会产生不必要的开销。使用 Hive 分区，Hive 查询只需访问 Hive 表中必要的数据量。</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>Hive 分区的实现方法是将未经处理的数据刷新成新的目录，而每个分区区都有自己的目录 - 其中的分区由用户定义。下图说明如何根据<bpt id="p1">*</bpt>年<ept id="p1">*</ept>列来分区 Hive 表。每年都会创建新的目录。</source>
          <target state="new">Hive 分区的实现方法是将未经处理的数据刷新成新的目录，而每个分区区都有自己的目录 - 其中的分区由用户定义。下图说明如何根据<bpt id="p1">*</bpt>年<ept id="p1">*</ept>列来分区 Hive 表。每年都会创建新的目录。</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>partitioning</source>
          <target state="new">partitioning</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>一些分区注意事项：</source>
          <target state="new">一些分区注意事项：</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>不要分区不足<ept id="p1">**</ept> - 根据包含少量值的列进行分区可能会导致创建很少的分区。例如，根据性别（男性和女性）分区只会创建两个分区，最多只会将延迟降低一半。</source>
          <target state="new"><bpt id="p1">**</bpt>不要分区不足<ept id="p1">**</ept> - 根据包含少量值的列进行分区可能会导致创建很少的分区。例如，根据性别（男性和女性）分区只会创建两个分区，最多只会将延迟降低一半。</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>不要过度分区<ept id="p1">**</ept> - 另一种极端是，根据包含唯一值（例如 userid）的列进行分区会导致创建多个分区，从而给群集命名节点带来很大的压力，因为它必须处理大量的目录。这是另一种极端做法。</source>
          <target state="new"><bpt id="p1">**</bpt>不要过度分区<ept id="p1">**</ept> - 另一种极端是，根据包含唯一值（例如 userid）的列进行分区会导致创建多个分区，从而给群集命名节点带来很大的压力，因为它必须处理大量的目录。这是另一种极端做法。</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>避免数据偏斜<ept id="p1">**</ept> - 明智选择分区键，以便所有分区的大小均等。例如，根据<bpt id="p2">*</bpt>州<ept id="p2">*</ept>分区可能会导致“加利福尼亚州”的记录数几乎是“佛蒙特州”的 30 倍，因为两个州的人口有差异。</source>
          <target state="new"><bpt id="p1">**</bpt>避免数据偏斜<ept id="p1">**</ept> - 明智选择分区键，以便所有分区的大小均等。例如，根据<bpt id="p2">*</bpt>州<ept id="p2">*</ept>分区可能会导致“加利福尼亚州”的记录数几乎是“佛蒙特州”的 30 倍，因为两个州的人口有差异。</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>若要创建分区表，请使用 <bpt id="p1">*</bpt>Partitioned By<ept id="p1">*</ept> 子句：</source>
          <target state="new">若要创建分区表，请使用 <bpt id="p1">*</bpt>Partitioned By<ept id="p1">*</ept> 子句：</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>创建分区表后，可以创建静态分区或动态分区。</source>
          <target state="new">创建分区表后，可以创建静态分区或动态分区。</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>静态分区<ept id="p1">**</ept>表示已在相应目录中创建了分片数据，你可以请求根据目录位置在 Hive 中手动分区。以下代码段对此做了演示。</source>
          <target state="new"><bpt id="p1">**</bpt>静态分区<ept id="p1">**</ept>表示已在相应目录中创建了分片数据，你可以请求根据目录位置在 Hive 中手动分区。以下代码段对此做了演示。</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>动态分区<ept id="p1">**</ept>表示你希望 Hive 自动为你创建分区。由于我们已经基于暂存表创建了分区表，我们需要做的就是将数据插入分区表，如下所示：</source>
          <target state="new"><bpt id="p1">**</bpt>动态分区<ept id="p1">**</ept>表示你希望 Hive 自动为你创建分区。由于我们已经基于暂存表创建了分区表，我们需要做的就是将数据插入分区表，如下所示：</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>有关更多详细信息，请参阅<bpt id="p1">[</bpt>分区表<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-PartitionedTables)</ept>。</source>
          <target state="new">有关更多详细信息，请参阅<bpt id="p1">[</bpt>分区表<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-PartitionedTables)</ept>。</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>使用 ORCFile 格式</source>
          <target state="new">使用 ORCFile 格式</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>Hive 支持不同的文件格式。例如：</source>
          <target state="new">Hive 支持不同的文件格式。例如：</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>文本<ept id="p1">**</ept>：这是默认的文件格式，适用于大多数情况</source>
          <target state="new"><bpt id="p1">**</bpt>文本<ept id="p1">**</ept>：这是默认的文件格式，适用于大多数情况</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Avro<ept id="p1">**</ept>：非常适合互操作方案</source>
          <target state="new"><bpt id="p1">**</bpt>Avro<ept id="p1">**</ept>：非常适合互操作方案</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>ORC/Parquet<ept id="p1">**</ept>：最适合用于提高性能</source>
          <target state="new"><bpt id="p1">**</bpt>ORC/Parquet<ept id="p1">**</ept>：最适合用于提高性能</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>ORC（优化行纵栏式）格式是存储 Hive 数据的高效方式。与其他格式相比，ORC 具有以下优点：</source>
          <target state="new">ORC（优化行纵栏式）格式是存储 Hive 数据的高效方式。与其他格式相比，ORC 具有以下优点：</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>支持复杂类型（包括 DateTime）和复杂的半结构化类型</source>
          <target state="new">支持复杂类型（包括 DateTime）和复杂的半结构化类型</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>高达 70% 的压缩率</source>
          <target state="new">高达 70% 的压缩率</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>每隔 10,000 行编制索引一次并允许跳过行</source>
          <target state="new">每隔 10,000 行编制索引一次并允许跳过行</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>大幅减少运行时执行时间</source>
          <target state="new">大幅减少运行时执行时间</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>若要启用 ORC 格式，请先使用 <bpt id="p1">*</bpt>Stored as ORC<ept id="p1">*</ept> 子句创建一个表：</source>
          <target state="new">若要启用 ORC 格式，请先使用 <bpt id="p1">*</bpt>Stored as ORC<ept id="p1">*</ept> 子句创建一个表：</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>接下来，从暂存表向 ORC 表插入数据。例如：</source>
          <target state="new">接下来，从暂存表向 ORC 表插入数据。例如：</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>可在<bpt id="p1">[</bpt>此处<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC)</ept>阅读有关 ORC 格式的详细信息。</source>
          <target state="new">可在<bpt id="p1">[</bpt>此处<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC)</ept>阅读有关 ORC 格式的详细信息。</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>向量化</source>
          <target state="new">向量化</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>向量化可让 Hive 以批的形式同时处理 1024 行，而不是一次处理一行。这意味着，简单的操作可以更快地完成，因为需要运行的内部代码更少。</source>
          <target state="new">向量化可让 Hive 以批的形式同时处理 1024 行，而不是一次处理一行。这意味着，简单的操作可以更快地完成，因为需要运行的内部代码更少。</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>若要启用向量化，请在 Hive 查询的前面加上以下设置作为前缀：</source>
          <target state="new">若要启用向量化，请在 Hive 查询的前面加上以下设置作为前缀：</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>有关详细信息，请参阅<bpt id="p1">[</bpt>向量化查询执行<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/Vectorized+Query+Execution)</ept>。</source>
          <target state="new">有关详细信息，请参阅<bpt id="p1">[</bpt>向量化查询执行<ept id="p1">](https://cwiki.apache.org/confluence/display/Hive/Vectorized+Query+Execution)</ept>。</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>其他优化方法</source>
          <target state="new">其他优化方法</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>你还可以考虑使用其他一些高级优化方法，例如：</source>
          <target state="new">你还可以考虑使用其他一些高级优化方法，例如：</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>Hive 装桶：<ept id="p1">**</ept>将大型数据集群集化或分段以优化查询性能的技术。</source>
          <target state="new"><bpt id="p1">**</bpt>Hive 装桶：<ept id="p1">**</ept>将大型数据集群集化或分段以优化查询性能的技术。</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>联接优化：<ept id="p1">**</ept>Hive 的查询执行计划优化，可改善联接的效率并减少用户提示的需要。有关详细信息，请参阅<bpt id="p2">[</bpt>联接优化<ept id="p2">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+JoinOptimization#LanguageManualJoinOptimization-JoinOptimization)</ept>。</source>
          <target state="new"><bpt id="p1">**</bpt>联接优化：<ept id="p1">**</ept>Hive 的查询执行计划优化，可改善联接的效率并减少用户提示的需要。有关详细信息，请参阅<bpt id="p2">[</bpt>联接优化<ept id="p2">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+JoinOptimization#LanguageManualJoinOptimization-JoinOptimization)</ept>。</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>增加化简器</source>
          <target state="new">增加化简器</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>后续步骤</source>
          <target state="new"><ph id="ph1">&lt;a id="nextsteps"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph>后续步骤</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>在本文中，你已学习了几种常见的 Hive 查询优化方法。若要了解更多信息，请参阅下列文章：</source>
          <target state="new">在本文中，你已学习了几种常见的 Hive 查询优化方法。若要了解更多信息，请参阅下列文章：</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>使用 HDInsight 中的 Hive 分析航班延误数据</source>
          <target state="new">使用 HDInsight 中的 Hive 分析航班延误数据</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>使用 HDInsight 中 Hadoop上的 Hive 查询控制台分析传感器数据</source>
          <target state="new">使用 HDInsight 中 Hadoop上的 Hive 查询控制台分析传感器数据</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>