<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="en-us">
    <header>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ht</xliffext:oltranslationpriority>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">3596c4a2bf5dfc42fc217c3dedfd484d73fee61c</xliffext:olfilehash>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-02a95cf" tool-company="Microsoft" />
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>在 HDInsight 中运行 Hadoop 示例 | Azure</source>
          <target state="new">在 HDInsight 中运行 Hadoop 示例 | Azure</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>使用所提供的示例开始使用 Azure HDInsight 服务。在数据群集中使用运行 MapReduce 程序的 PowerShell 脚本。</source>
          <target state="new">使用所提供的示例开始使用 Azure HDInsight 服务。在数据群集中使用运行 MapReduce 程序的 PowerShell 脚本。</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>在基于 Windows 的 HDInsight 中运行 Hadoop MapReduce 示例</source>
          <target state="new">在基于 Windows 的 HDInsight 中运行 Hadoop MapReduce 示例</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>为帮助你开始使用 Azure HDInsight 在 Hadoop 群集上运行 MapReduce 作业，我们提供了一组示例。在你创建的每一个 HDInsight 托管群集上都可以使用这些示例。运行这些示例会让你熟悉使用 Azure PowerShell cmdlet 在 Hadoop 群集上运行作业。</source>
          <target state="new">为帮助你开始使用 Azure HDInsight 在 Hadoop 群集上运行 MapReduce 作业，我们提供了一组示例。在你创建的每一个 HDInsight 托管群集上都可以使用这些示例。运行这些示例会让你熟悉使用 Azure PowerShell cmdlet 在 Hadoop 群集上运行作业。</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>字数统计<ept id="p2">**</ept><ept id="p1">](#hdinsight-sample-wordcount)</ept>：计算单词在文本文件中出现的次数。</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>字数统计<ept id="p2">**</ept><ept id="p1">](#hdinsight-sample-wordcount)</ept>：计算单词在文本文件中出现的次数。</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>C# 流式处理字数统计<ept id="p2">**</ept><ept id="p1">](#hdinsight-sample-csharp-streaming)</ept>：使用 Hadoop 流式处理接口计算单词在文本文件中出现的次数。</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>C# 流式处理字数统计<ept id="p2">**</ept><ept id="p1">](#hdinsight-sample-csharp-streaming)</ept>：使用 Hadoop 流式处理接口计算单词在文本文件中出现的次数。</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>Pi 估计器<ept id="p2">**</ept><ept id="p1">](#hdinsight-sample-pi-estimator)</ept>：使用统计学方法（拟蒙特卡罗法）来估算 pi 值。</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>Pi 估计器<ept id="p2">**</ept><ept id="p1">](#hdinsight-sample-pi-estimator)</ept>：使用统计学方法（拟蒙特卡罗法）来估算 pi 值。</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source><bpt id="p1">[</bpt><bpt id="p2">**</bpt>10-GB Graysort<ept id="p2">**</ept><ept id="p1">](#hdinsight-sample-10gb-graysort)</ept>：使用 HDInsight 对 10 GB 文件运行常规用途的 GraySort。有三个作业要运行：Teragen 生成数据，Terasort 对数据排序，而 Teravalidate 确认数据已正确排序。</source>
          <target state="new"><bpt id="p1">[</bpt><bpt id="p2">**</bpt>10-GB Graysort<ept id="p2">**</ept><ept id="p1">](#hdinsight-sample-10gb-graysort)</ept>：使用 HDInsight 对 10 GB 文件运行常规用途的 GraySort。有三个作业要运行：Teragen 生成数据，Terasort 对数据排序，而 Teravalidate 确认数据已正确排序。</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source><ph id="ph1">[AZURE.NOTE]</ph>可以在附录中找到源代码。</source>
          <target state="new"><ph id="ph1">[AZURE.NOTE]</ph>可以在附录中找到源代码。</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>Web 上有许多介绍 Hadoop 相关技术（例如基于 Java 的 MapReduce 编程和流式处理）的其他文档，以及有关 Windows PowerShell 脚本中使用的 cmdlet 的文档。有关这些资源的详细信息，请参阅：</source>
          <target state="new">Web 上有许多介绍 Hadoop 相关技术（例如基于 Java 的 MapReduce 编程和流式处理）的其他文档，以及有关 Windows PowerShell 脚本中使用的 cmdlet 的文档。有关这些资源的详细信息，请参阅：</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>为 HDInsight 中的 Hadoop 开发 Java MapReduce 程序</source>
          <target state="new">为 HDInsight 中的 Hadoop 开发 Java MapReduce 程序</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>为 HDInsight 开发 C# Hadoop 流式处理程序</source>
          <target state="new">为 HDInsight 开发 C# Hadoop 流式处理程序</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>在 HDInsight 中提交 Hadoop 作业</source>
          <target state="new">在 HDInsight 中提交 Hadoop 作业</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>Azure HDInsight 简介</source>
          <target state="new">Azure HDInsight 简介</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>现今，许多人选择 Hive 和 Pig，而不是 MapReduce。有关详细信息，请参阅：</source>
          <target state="new">现今，许多人选择 Hive 和 Pig，而不是 MapReduce。有关详细信息，请参阅：</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>在 HDInsight 中使用 Hive</source>
          <target state="new">在 HDInsight 中使用 Hive</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>在 HDInsight 中使用 Pig</source>
          <target state="new">在 HDInsight 中使用 Pig</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>先决条件<ept id="p1">**</ept>：</source>
          <target state="new"><bpt id="p1">**</bpt>先决条件<ept id="p1">**</ept>：</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>一个 Azure 订阅<ept id="p1">**</ept>。请参阅<bpt id="p2">[</bpt>获取 Azure 试用版<ept id="p2">](/pricing/1rmb-trial/)</ept>。</source>
          <target state="new"><bpt id="p1">**</bpt>一个 Azure 订阅<ept id="p1">**</ept>。请参阅<bpt id="p2">[</bpt>获取 Azure 试用版<ept id="p2">](/pricing/1rmb-trial/)</ept>。</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>一个 HDInsight 群集<ept id="p1">**</ept>。有关可用于创建这类群集的不同方法的说明，请参阅<bpt id="p2">[</bpt>在 HDInsight 中创建 Hadoop 群集<ept id="p2">](/documentation/articles/hdinsight-provision-clusters-v1)</ept>。</source>
          <target state="new"><bpt id="p1">**</bpt>一个 HDInsight 群集<ept id="p1">**</ept>。有关可用于创建这类群集的不同方法的说明，请参阅<bpt id="p2">[</bpt>在 HDInsight 中创建 Hadoop 群集<ept id="p2">](/documentation/articles/hdinsight-provision-clusters-v1)</ept>。</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>配备 Azure PowerShell 的工作站<ept id="p1">**</ept>。请参阅<bpt id="p2">[</bpt>安装和使用 Azure PowerShell<ept id="p2">](/documentation/articles/powershell-install-configure)</ept>。</source>
          <target state="new"><bpt id="p1">**</bpt>配备 Azure PowerShell 的工作站<ept id="p1">**</ept>。请参阅<bpt id="p2">[</bpt>安装和使用 Azure PowerShell<ept id="p2">](/documentation/articles/powershell-install-configure)</ept>。</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="hdinsight-sample-wordcount"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> 字数统计 - Java</source>
          <target state="new"><ph id="ph1">&lt;a name="hdinsight-sample-wordcount"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> 字数统计 - Java</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>若要提交 MapReduce 项目，请先创建 MapReduce 作业定义。在作业定义中，指定 MapReduce 程序 jar 文件和 jar 文件的位置（即，* *<bpt id="p1">**</bpt>wasb:///example/jars/hadoop-mapreduce-examples.jar<ept id="p1">**</ept>）、类名和参数。Wordcount MapReduce 程序采用两个参数：用于计算单词数的源文件和输出位置。</source>
          <target state="new">若要提交 MapReduce 项目，请先创建 MapReduce 作业定义。在作业定义中，指定 MapReduce 程序 jar 文件和 jar 文件的位置（即，* *<bpt id="p1">**</bpt>wasb:///example/jars/hadoop-mapreduce-examples.jar<ept id="p1">**</ept>）、类名和参数。Wordcount MapReduce 程序采用两个参数：用于计算单词数的源文件和输出位置。</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>可以在<bpt id="p1">[</bpt>附录 A<ept id="p1">](#apendix-a---the-word-count-MapReduce-program-in-java)</ept> 中找到源代码。</source>
          <target state="new">可以在<bpt id="p1">[</bpt>附录 A<ept id="p1">](#apendix-a---the-word-count-MapReduce-program-in-java)</ept> 中找到源代码。</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>有关开发 Java MapReduce 程序的过程，请参阅<bpt id="p1">[</bpt>开发适用于 HDInsight 中的 Hadoop 的 Java MapReduce 程序<ept id="p1">](/documentation/articles/hdinsight-develop-deploy-java-mapreduce)</ept></source>
          <target state="new">有关开发 Java MapReduce 程序的过程，请参阅<bpt id="p1">[</bpt>开发适用于 HDInsight 中的 Hadoop 的 Java MapReduce 程序<ept id="p1">](/documentation/articles/hdinsight-develop-deploy-java-mapreduce)</ept></target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>提交字数统计 MapReduce 作业</source>
          <target state="new">提交字数统计 MapReduce 作业</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>打开 <bpt id="p1">**</bpt>Windows PowerShell ISE<ept id="p1">**</ept>。有关说明，请参阅<bpt id="p2">[</bpt>安装和配置 Azure PowerShell<ept id="p2">][powershell-install-configure]</ept>。</source>
          <target state="new">打开 <bpt id="p1">**</bpt>Windows PowerShell ISE<ept id="p1">**</ept>。有关说明，请参阅<bpt id="p2">[</bpt>安装和配置 Azure PowerShell<ept id="p2">][powershell-install-configure]</ept>。</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>粘贴以下 PowerShell 脚本：</source>
          <target state="new">粘贴以下 PowerShell 脚本：</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>MapReduce 作业将生成一个名为 <bpt id="p1">*</bpt>part-r-00000<ept id="p1">*</ept> 的文件，其中包含单词和计数。该脚本使用 <bpt id="p2">**</bpt>findstr<ept id="p2">**</ept> 命令来列出包含“there”的所有单词。</source>
          <target state="new">MapReduce 作业将生成一个名为 <bpt id="p1">*</bpt>part-r-00000<ept id="p1">*</ept> 的文件，其中包含单词和计数。该脚本使用 <bpt id="p2">**</bpt>findstr<ept id="p2">**</ept> 命令来列出包含“there”的所有单词。</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>设置前 3 个变量，然后运行脚本。</source>
          <target state="new">设置前 3 个变量，然后运行脚本。</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="hdinsight-sample-csharp-streaming"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> 字数统计 - C# 流式处理</source>
          <target state="new"><ph id="ph1">&lt;a name="hdinsight-sample-csharp-streaming"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> 字数统计 - C# 流式处理</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>Hadoop 向 MapReduce 提供了一个流式处理 API，利用它，你可以采用 Java 之外的其他语言来编写映射函数和化简函数。</source>
          <target state="new">Hadoop 向 MapReduce 提供了一个流式处理 API，利用它，你可以采用 Java 之外的其他语言来编写映射函数和化简函数。</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>在示例中，映射器和化简器都是可执行程序，它们从 [stdin][stdin-stdout-stderr] 读取输入（逐行）并将输出结果发送到 [stdout][stdin-stdout-stderr]。程序计算文本中所有单词的数量。</source>
          <target state="new">在示例中，映射器和化简器都是可执行程序，它们从 [stdin][stdin-stdout-stderr] 读取输入（逐行）并将输出结果发送到 [stdout][stdin-stdout-stderr]。程序计算文本中所有单词的数量。</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>如果为<bpt id="p1">**</bpt>映射器<ept id="p1">**</ept>指定可执行文件，则当初始化映射器时，每个映射器任务都将启动此可执行文件作为一个单独的进程。当映射器任务运行时，它将其输入转换为行，并将这些行馈送到进程的 [stdin][stdin-stdout-stderr]。</source>
          <target state="new">如果为<bpt id="p1">**</bpt>映射器<ept id="p1">**</ept>指定可执行文件，则当初始化映射器时，每个映射器任务都将启动此可执行文件作为一个单独的进程。当映射器任务运行时，它将其输入转换为行，并将这些行馈送到进程的 [stdin][stdin-stdout-stderr]。</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>同时，映射器从进程的 stdout 中收集面向行的输出。然后将每行转换为一个键/值对（作为映射器的输出收集）。默认情况下，一行的前缀直至第一个制表符是键，而该行的剩余部分（不包括制表符）是值。如果行中没有制表符，则整行被视为键，而值为 Null。</source>
          <target state="new">同时，映射器从进程的 stdout 中收集面向行的输出。然后将每行转换为一个键/值对（作为映射器的输出收集）。默认情况下，一行的前缀直至第一个制表符是键，而该行的剩余部分（不包括制表符）是值。如果行中没有制表符，则整行被视为键，而值为 Null。</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>如果为<bpt id="p1">**</bpt>化简器<ept id="p1">**</ept>指定可执行文件，则当初始化化简器时，每个化简器任务都将启动此可执行文件作为一个单独的进程。当化简器任务运行时，它将其输入键/值对转换为行，并将这些行馈送到进程的 [stdin][stdin-stdout-stderr]。</source>
          <target state="new">如果为<bpt id="p1">**</bpt>化简器<ept id="p1">**</ept>指定可执行文件，则当初始化化简器时，每个化简器任务都将启动此可执行文件作为一个单独的进程。当化简器任务运行时，它将其输入键/值对转换为行，并将这些行馈送到进程的 [stdin][stdin-stdout-stderr]。</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>同时，化简器从进程的 [stdout][stdin-stdout-stderr] 中收集面向行的输出。然后将每行转换为一个键/值对（作为化简器的输出收集）。默认情况下，一行的前缀直至第一个制表符是键，而该行的剩余部分（不包括制表符）是值。</source>
          <target state="new">同时，化简器从进程的 [stdout][stdin-stdout-stderr] 中收集面向行的输出。然后将每行转换为一个键/值对（作为化简器的输出收集）。默认情况下，一行的前缀直至第一个制表符是键，而该行的剩余部分（不包括制表符）是值。</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source>有关 Hadoop 流式处理接口的详细信息，请参阅 [Hadoop 流式处理][hadoop-streaming]。</source>
          <target state="new">有关 Hadoop 流式处理接口的详细信息，请参阅 [Hadoop 流式处理][hadoop-streaming]。</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>提交 C# 流式处理字数统计作业</source>
          <target state="new">提交 C# 流式处理字数统计作业</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>按照<bpt id="p1">[</bpt>字数统计 - Java<ept id="p1">](#word-count-java)</ept> 中的过程操作，并将作业定义替换为以下内容：</source>
          <target state="new">按照<bpt id="p1">[</bpt>字数统计 - Java<ept id="p1">](#word-count-java)</ept> 中的过程操作，并将作业定义替换为以下内容：</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>输出文件应该是：</source>
          <target state="new">输出文件应该是：</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="hdinsight-sample-pi-estimator"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> PI 估计器</source>
          <target state="new"><ph id="ph1">&lt;a name="hdinsight-sample-pi-estimator"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> PI 估计器</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>pi 估计器使用统计学方法（拟蒙特卡罗法）来估算 pi 值。单位平方形内部随机放置的点也落入该平方形内嵌的圆圈内，其概率等于圆圈面积 pi/4。可以从 4R 的值来估算 pi 的值，其中 R 是落入圆圈内的点数与平方形内总点数的比率。所使用的取样点越多，估算值越准确。</source>
          <target state="new">pi 估计器使用统计学方法（拟蒙特卡罗法）来估算 pi 值。单位平方形内部随机放置的点也落入该平方形内嵌的圆圈内，其概率等于圆圈面积 pi/4。可以从 4R 的值来估算 pi 的值，其中 R 是落入圆圈内的点数与平方形内总点数的比率。所使用的取样点越多，估算值越准确。</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>为此示例提供的脚本提交了一个 Hadoop jar 作业，设置为使用特定的值（16 个映射）运行，其中每个映射都必须通过参数值计算 1 千万个取样点。可以更改这些参数值以改进 pi 的估算值。例如，pi 采用前 10 位小数时为 3.1415926535。</source>
          <target state="new">为此示例提供的脚本提交了一个 Hadoop jar 作业，设置为使用特定的值（16 个映射）运行，其中每个映射都必须通过参数值计算 1 千万个取样点。可以更改这些参数值以改进 pi 的估算值。例如，pi 采用前 10 位小数时为 3.1415926535。</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>提交 pi 估计器作业</source>
          <target state="new">提交 pi 估计器作业</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>按照<bpt id="p1">[</bpt>字数统计 - Java<ept id="p1">](#word-count-java)</ept> 中的过程操作，并将作业定义替换为以下内容：</source>
          <target state="new">按照<bpt id="p1">[</bpt>字数统计 - Java<ept id="p1">](#word-count-java)</ept> 中的过程操作，并将作业定义替换为以下内容：</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="hdinsight-sample-10gb-graysort"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> 10-GB Graysort</source>
          <target state="new"><ph id="ph1">&lt;a name="hdinsight-sample-10gb-graysort"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> 10-GB Graysort</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>此示例使用适中的 10GB 数据，这样它运行时能相对快一点。它使用由 Owen O'Malley 和 Arun Murthy 开发的 MapReduce 应用程序，此应用程序以 0.578TB/分钟（100TB 用时 173 分钟）的速率赢得了 2009 年年度常用（“daytona”）TB 级排序基准。有关这一排序基准和其他排序基准的详细信息，请参阅 <bpt id="p1">[</bpt>Sortbenchmark<ept id="p1">](http://sortbenchmark.org/)</ept> Web 应用。</source>
          <target state="new">此示例使用适中的 10GB 数据，这样它运行时能相对快一点。它使用由 Owen O'Malley 和 Arun Murthy 开发的 MapReduce 应用程序，此应用程序以 0.578TB/分钟（100TB 用时 173 分钟）的速率赢得了 2009 年年度常用（“daytona”）TB 级排序基准。有关这一排序基准和其他排序基准的详细信息，请参阅 <bpt id="p1">[</bpt>Sortbenchmark<ept id="p1">](http://sortbenchmark.org/)</ept> Web 应用。</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>本示例使用三组 MapReduce 程序：</source>
          <target state="new">本示例使用三组 MapReduce 程序：</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>TeraGen<ept id="p1">**</ept> 是一个 MapReduce 程序，你可用它来生成要排序的数据行。</source>
          <target state="new"><bpt id="p1">**</bpt>TeraGen<ept id="p1">**</ept> 是一个 MapReduce 程序，你可用它来生成要排序的数据行。</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>TeraSort<ept id="p1">**</ept> 以输入数据为例，使用 MapReduce 将数据排序到总序中。TeraSort 是 MapReduce 函数的一种标准排序，但自定义的分区程序除外，此分区程序使用 N-1 个抽样键（用于定义每次简化的键范围）的已排序列表。具体说来，sample[i-1] &lt;= key &lt; sample[i] 的所有键都将会发送到化简变量 i。这样可确保化简变量 i 的输出全都小于化简变量 i+1 的输出。</source>
          <target state="new"><bpt id="p1">**</bpt>TeraSort<ept id="p1">**</ept> 以输入数据为例，使用 MapReduce 将数据排序到总序中。TeraSort 是 MapReduce 函数的一种标准排序，但自定义的分区程序除外，此分区程序使用 N-1 个抽样键（用于定义每次简化的键范围）的已排序列表。具体说来，sample[i-1] &lt;= key &lt; sample[i] 的所有键都将会发送到化简变量 i。这样可确保化简变量 i 的输出全都小于化简变量 i+1 的输出。</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>TeraValidate<ept id="p1">**</ept> 是一个 MapReduce 程序，用于验证输出是否已全局排序。它在输出目录中对于每个文件创建一个映射，每个映射都确保每个键均小于或等于前一个键。映射函数也会生成每个文件的第一个和最后一个键的记录，而化简函数会确保文件 i 的第一个键大于文件 i-1 的最后一个键。任何问题都会报告为包含故障键的化简的输出结果。</source>
          <target state="new"><bpt id="p1">**</bpt>TeraValidate<ept id="p1">**</ept> 是一个 MapReduce 程序，用于验证输出是否已全局排序。它在输出目录中对于每个文件创建一个映射，每个映射都确保每个键均小于或等于前一个键。映射函数也会生成每个文件的第一个和最后一个键的记录，而化简函数会确保文件 i 的第一个键大于文件 i-1 的最后一个键。任何问题都会报告为包含故障键的化简的输出结果。</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>所有三个应用程序所使用的输入和输出格式都以正确格式读写文本文件。化简的输出结果的复制设置为 1，而不是默认值 3，因为基准比赛不要求输出结果数据复制到多个节点上。</source>
          <target state="new">所有三个应用程序所使用的输入和输出格式都以正确格式读写文本文件。化简的输出结果的复制设置为 1，而不是默认值 3，因为基准比赛不要求输出结果数据复制到多个节点上。</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>此示例要求三个任务，每个任务对应于简介部分介绍的一个 MapReduce 程序：</source>
          <target state="new">此示例要求三个任务，每个任务对应于简介部分介绍的一个 MapReduce 程序：</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source>通过运行 <bpt id="p1">**</bpt>TeraGen<ept id="p1">**</ept> MapReduce 作业生成要排序的数据。</source>
          <target state="new">通过运行 <bpt id="p1">**</bpt>TeraGen<ept id="p1">**</ept> MapReduce 作业生成要排序的数据。</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>通过运行 <bpt id="p1">**</bpt>TeraSort<ept id="p1">**</ept> MapReduce 作业对数据进行排序。</source>
          <target state="new">通过运行 <bpt id="p1">**</bpt>TeraSort<ept id="p1">**</ept> MapReduce 作业对数据进行排序。</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>通过运行 <bpt id="p1">**</bpt>TeraValidate<ept id="p1">**</ept> MapReduce 作业确认数据已正确排序。</source>
          <target state="new">通过运行 <bpt id="p1">**</bpt>TeraValidate<ept id="p1">**</ept> MapReduce 作业确认数据已正确排序。</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>提交作业</source>
          <target state="new">提交作业</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>按照<bpt id="p1">[</bpt>字数统计 - Java<ept id="p1">](#word-count-java)</ept> 中的过程操作，并使用以下作业定义：</source>
          <target state="new">按照<bpt id="p1">[</bpt>字数统计 - Java<ept id="p1">](#word-count-java)</ept> 中的过程操作，并使用以下作业定义：</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>$teragen = New-AzureHDInsightMapReduceJobDefinition <ph id="ph1">`
                              -JarFile "/example/jars/hadoop-mapreduce-examples.jar" `</ph></source>
          <target state="new">$teragen = New-AzureHDInsightMapReduceJobDefinition <ph id="ph1">`
                              -JarFile "/example/jars/hadoop-mapreduce-examples.jar" `</ph></target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>-ClassName "teragen" `</source>
          <target state="new">-ClassName "teragen" `</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>-Arguments "-Dmapred.map.tasks=50", "100000000", "/example/data/10GB-sort-input"</source>
          <target state="new">-Arguments "-Dmapred.map.tasks=50", "100000000", "/example/data/10GB-sort-input"</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>$terasort = New-AzureHDInsightMapReduceJobDefinition <ph id="ph1">`
                              -JarFile "/example/jars/hadoop-mapreduce-examples.jar" `</ph></source>
          <target state="new">$terasort = New-AzureHDInsightMapReduceJobDefinition <ph id="ph1">`
                              -JarFile "/example/jars/hadoop-mapreduce-examples.jar" `</ph></target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>-ClassName "terasort" `</source>
          <target state="new">-ClassName "terasort" `</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>-Arguments "-Dmapred.map.tasks=50", "-Dmapred.reduce.tasks=25", "/example/data/10GB-sort-input", "/example/data/10GB-sort-output"</source>
          <target state="new">-Arguments "-Dmapred.map.tasks=50", "-Dmapred.reduce.tasks=25", "/example/data/10GB-sort-input", "/example/data/10GB-sort-output"</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>$teravalidate = New-AzureHDInsightMapReduceJobDefinition <ph id="ph1">`
                              -JarFile "/example/jars/hadoop-mapreduce-examples.jar" `</ph></source>
          <target state="new">$teravalidate = New-AzureHDInsightMapReduceJobDefinition <ph id="ph1">`
                              -JarFile "/example/jars/hadoop-mapreduce-examples.jar" `</ph></target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>-ClassName "teravalidate" `</source>
          <target state="new">-ClassName "teravalidate" `</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>-Arguments "-Dmapred.map.tasks=50", "-Dmapred.reduce.tasks=25", "/example/data/10GB-sort-output", "/example/data/10GB-sort-validate"</source>
          <target state="new">-Arguments "-Dmapred.map.tasks=50", "-Dmapred.reduce.tasks=25", "/example/data/10GB-sort-output", "/example/data/10GB-sort-validate"</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>后续步骤</source>
          <target state="new">后续步骤</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>从本文和每个示例的相关文章中，你了解到如何使用 Azure PowerShell 运行 HDInsight 群集附带的示例。有关 Pig、Hive 和 MapReduce 如何与 HDInsight 配合使用的教程，请参阅以下主题：</source>
          <target state="new">从本文和每个示例的相关文章中，你了解到如何使用 Azure PowerShell 运行 HDInsight 群集附带的示例。有关 Pig、Hive 和 MapReduce 如何与 HDInsight 配合使用的教程，请参阅以下主题：</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>将 Hadoop 与 HDInsight 中的 Hive 配合使用以分析手机使用情况</source>
          <target state="new">将 Hadoop 与 HDInsight 中的 Hive 配合使用以分析手机使用情况</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source>将 Pig 与 HDInsight 上的 Hadoop 配合使用</source>
          <target state="new">将 Pig 与 HDInsight 上的 Hadoop 配合使用</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>将 Hive 与 HDInsight 上的 Hadoop 配合使用</source>
          <target state="new">将 Hive 与 HDInsight 上的 Hadoop 配合使用</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>在 HDInsight 中提交 Hadoop 作业</source>
          <target state="new">在 HDInsight 中提交 Hadoop 作业</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>Azure HDInsight SDK 文档</source>
          <target state="new">Azure HDInsight SDK 文档</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>在 HDInsight 中调试 Hadoop：错误消息</source>
          <target state="new">在 HDInsight 中调试 Hadoop：错误消息</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source><ph id="ph1">&lt;a name="word-count-java" id="apendix-a---the-word-count-MapReduce-program-in-java"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> 附录 A - 字数统计源代码</source>
          <target state="new"><ph id="ph1">&lt;a name="word-count-java" id="apendix-a---the-word-count-MapReduce-program-in-java"&gt;</ph><ph id="ph2">&lt;/a&gt;</ph> 附录 A - 字数统计源代码</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>附录 B - 字数统计流式处理源代码</source>
          <target state="new">附录 B - 字数统计流式处理源代码</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>MapReduce 程序使用 cat.exe 应用程序作为映射接口将文本流式传输到控制台，并使用 wc.exe 应用程序作为化简接口来统计从文档中流式传输的字数。映射器和化简器都从标准输入流 (stdin) 逐行读取字符，并写入到标准输出流 (stdout)。</source>
          <target state="new">MapReduce 程序使用 cat.exe 应用程序作为映射接口将文本流式传输到控制台，并使用 wc.exe 应用程序作为化简接口来统计从文档中流式传输的字数。映射器和化简器都从标准输入流 (stdin) 逐行读取字符，并写入到标准输出流 (stdout)。</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>cat.cs 文件中的映射器代码使用 <bpt id="p1">[</bpt>StreamReader<ept id="p1">][streamreader]</ept> 对象将传入流的字符读入到控制台，然后控制台使用静态 <bpt id="p2">[</bpt>Console.Writeline<ept id="p2">][console-writeline]</ept> 方法将流写入标准输出流。</source>
          <target state="new">cat.cs 文件中的映射器代码使用 <bpt id="p1">[</bpt>StreamReader<ept id="p1">][streamreader]</ept> 对象将传入流的字符读入到控制台，然后控制台使用静态 <bpt id="p2">[</bpt>Console.Writeline<ept id="p2">][console-writeline]</ept> 方法将流写入标准输出流。</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>wc.cs 文件中的化简器代码使用 <bpt id="p1">[</bpt>StreamReader<ept id="p1">][streamreader]</ept> 对象从 cat.exe 映射器输出的标准输入流读取字符。当它使用 <bpt id="p2">[</bpt>Console.Writeline<ept id="p2">][console-writeline]</ept> 方法读取字符时，它将通过统计每个单词末尾的空格和行结束字符的数目来计算单词数量。然后使用 <bpt id="p3">[</bpt>Console.Writeline<ept id="p3">][console-writeline]</ept> 方法将总数写入标准输出流中。</source>
          <target state="new">wc.cs 文件中的化简器代码使用 <bpt id="p1">[</bpt>StreamReader<ept id="p1">][streamreader]</ept> 对象从 cat.exe 映射器输出的标准输入流读取字符。当它使用 <bpt id="p2">[</bpt>Console.Writeline<ept id="p2">][console-writeline]</ept> 方法读取字符时，它将通过统计每个单词末尾的空格和行结束字符的数目来计算单词数量。然后使用 <bpt id="p3">[</bpt>Console.Writeline<ept id="p3">][console-writeline]</ept> 方法将总数写入标准输出流中。</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>附录 C - PI 估计器源代码</source>
          <target state="new">附录 C - PI 估计器源代码</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>在下面可以检查包含映射器函数和化简器函数的 pi estimator Java 代码。映射器程序生成在单位平方形内部随机放置的指定点数，然后计算位于圆圈内部的这些点的数目。化简器程序累计由映射器统计的点数，然后根据公式 4R 估算 pi 的值，其中 R 是圆圈内统计的点数与方形内总点数的比率。</source>
          <target state="new">在下面可以检查包含映射器函数和化简器函数的 pi estimator Java 代码。映射器程序生成在单位平方形内部随机放置的指定点数，然后计算位于圆圈内部的这些点的数目。化简器程序累计由映射器统计的点数，然后根据公式 4R 估算 pi 的值，其中 R 是圆圈内统计的点数与方形内总点数的比率。</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>附录 D - 10gb graysort 源代码</source>
          <target state="new">附录 D - 10gb graysort 源代码</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>这一部分提供了 TeraSort MapReduce 程序的代码以供检查。</source>
          <target state="new">这一部分提供了 TeraSort MapReduce 程序的代码以供检查。</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>