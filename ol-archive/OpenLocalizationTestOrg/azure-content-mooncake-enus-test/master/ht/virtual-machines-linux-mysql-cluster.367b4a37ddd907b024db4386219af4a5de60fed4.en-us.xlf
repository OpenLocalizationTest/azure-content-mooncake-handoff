<?xml version="1.0"?>
<xliff version="1.2" xmlns="urn:oasis:names:tc:xliff:document:1.2" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="urn:oasis:names:tc:xliff:document:1.2 xliff-core-1.2-transitional.xsd">
  <file datatype="xml" original="md" source-language="en-US" target-language="en-us">
    <header>
      <xliffext:oltranslationpriority xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">ht</xliffext:oltranslationpriority>
      <xliffext:olfilehash xmlns:xliffext="urn:microsoft:content:schema:xliffextensions">509b60a6a1ab41137d6d420bf74fd48832caa323</xliffext:olfilehash>
      <tool tool-id="mdxliff" tool-name="mdxliff" tool-version="1.0-02a95cf" tool-company="Microsoft" />
    </header>
    <body>
      <group id="content" extype="content">
        <trans-unit id="101" translate="yes" xml:space="preserve">
          <source>使用负载平衡集群集化 Linux 上的 MySQL</source>
          <target state="new">使用负载平衡集群集化 Linux 上的 MySQL</target>
        </trans-unit>
        <trans-unit id="102" translate="yes" xml:space="preserve">
          <source>该文章作为示例说明了在 Azure 中使用 MySQL 设置负载平衡的高可用性 Linux 群集的模式</source>
          <target state="new">该文章作为示例说明了在 Azure 中使用 MySQL 设置负载平衡的高可用性 Linux 群集的模式</target>
        </trans-unit>
        <trans-unit id="103" translate="yes" xml:space="preserve">
          <source>使用负载平衡集群集化 Linux 上的 MySQL</source>
          <target state="new">使用负载平衡集群集化 Linux 上的 MySQL</target>
        </trans-unit>
        <trans-unit id="104" translate="yes" xml:space="preserve">
          <source>做好准备</source>
          <target state="new">做好准备</target>
        </trans-unit>
        <trans-unit id="105" translate="yes" xml:space="preserve">
          <source>设置群集</source>
          <target state="new">设置群集</target>
        </trans-unit>
        <trans-unit id="106" translate="yes" xml:space="preserve">
          <source>设置 MySQL</source>
          <target state="new">设置 MySQL</target>
        </trans-unit>
        <trans-unit id="107" translate="yes" xml:space="preserve">
          <source>设置 Corosync</source>
          <target state="new">设置 Corosync</target>
        </trans-unit>
        <trans-unit id="108" translate="yes" xml:space="preserve">
          <source>设置 Pacemaker</source>
          <target state="new">设置 Pacemaker</target>
        </trans-unit>
        <trans-unit id="109" translate="yes" xml:space="preserve">
          <source>测试</source>
          <target state="new">测试</target>
        </trans-unit>
        <trans-unit id="110" translate="yes" xml:space="preserve">
          <source>STONITH</source>
          <target state="new">STONITH</target>
        </trans-unit>
        <trans-unit id="111" translate="yes" xml:space="preserve">
          <source>限制</source>
          <target state="new">限制</target>
        </trans-unit>
        <trans-unit id="112" translate="yes" xml:space="preserve">
          <source>介绍</source>
          <target state="new">介绍</target>
        </trans-unit>
        <trans-unit id="113" translate="yes" xml:space="preserve">
          <source>本文旨在探索并说明可用于在 Azure 上部署基于 Linux 的高度可用服务的不同方法，并作为入门书探索 MySQL Server 的高可用性。</source>
          <target state="new">本文旨在探索并说明可用于在 Azure 上部署基于 Linux 的高度可用服务的不同方法，并作为入门书探索 MySQL Server 的高可用性。</target>
        </trans-unit>
        <trans-unit id="114" translate="yes" xml:space="preserve">
          <source>我们将基于 DRBD、Corosync 和 Pacemaker 概述无共享双节点单主机 MySQL 高可用性解决方案。一次只有一个节点运行 MySQL。读取和写入 DRBD 资源也限制为一次只有一个节点。</source>
          <target state="new">我们将基于 DRBD、Corosync 和 Pacemaker 概述无共享双节点单主机 MySQL 高可用性解决方案。一次只有一个节点运行 MySQL。读取和写入 DRBD 资源也限制为一次只有一个节点。</target>
        </trans-unit>
        <trans-unit id="115" translate="yes" xml:space="preserve">
          <source>无需使用类似 LVS 的 VIP 解决方案，因为我们使用 Azure 负载平衡集来同时提供轮循功能和 VIP 的终结点检测、删除和正常恢复功能。VIP 是在首次创建云服务时由 Azure 分配的全局可路由 IPv4 地址。</source>
          <target state="new">无需使用类似 LVS 的 VIP 解决方案，因为我们使用 Azure 负载平衡集来同时提供轮循功能和 VIP 的终结点检测、删除和正常恢复功能。VIP 是在首次创建云服务时由 Azure 分配的全局可路由 IPv4 地址。</target>
        </trans-unit>
        <trans-unit id="116" translate="yes" xml:space="preserve">
          <source>MySQL 的其他可能体系结构包括 NBD 群集、Percona 和 Galera 以及多个中间件解决方案，其中至少有一个以 <bpt id="p1">[</bpt>VM Depot<ept id="p1">](http://vmdepot.msopentech.com)</ept> 中的 VM 的形式提供。只要这些解决方案可以复制到单播、多播或广播上，并且不要依赖于共享存储或多个网络接口，这些方案就应该很容易在 Azure 上部署。</source>
          <target state="new">MySQL 的其他可能体系结构包括 NBD 群集、Percona 和 Galera 以及多个中间件解决方案，其中至少有一个以 <bpt id="p1">[</bpt>VM Depot<ept id="p1">](http://vmdepot.msopentech.com)</ept> 中的 VM 的形式提供。只要这些解决方案可以复制到单播、多播或广播上，并且不要依赖于共享存储或多个网络接口，这些方案就应该很容易在 Azure 上部署。</target>
        </trans-unit>
        <trans-unit id="117" translate="yes" xml:space="preserve">
          <source>当然，这些群集体系结构可以类似方式扩展到其他产品（如 PostgreSQL 和 OpenLDAP）。例如，此无共享的负载平衡过程已成功在多主机 OpenLDAP 上测试，并可以在我们的第 9 频道博客上观看。</source>
          <target state="new">当然，这些群集体系结构可以类似方式扩展到其他产品（如 PostgreSQL 和 OpenLDAP）。例如，此无共享的负载平衡过程已成功在多主机 OpenLDAP 上测试，并可以在我们的第 9 频道博客上观看。</target>
        </trans-unit>
        <trans-unit id="118" translate="yes" xml:space="preserve">
          <source>做好准备</source>
          <target state="new">做好准备</target>
        </trans-unit>
        <trans-unit id="119" translate="yes" xml:space="preserve">
          <source>你将需要一个具有有效订阅可以创建至少两 (2) 个虚拟机的 Azure 帐户（在此示例中使用 XS）、一个网络和一个子网、一个地缘组和一个可用性集，以及能够在同一区域中创建新的 VHD 作为云服务，并将这些 VHD 附加到 Linux 虚拟机。</source>
          <target state="new">你将需要一个具有有效订阅可以创建至少两 (2) 个虚拟机的 Azure 帐户（在此示例中使用 XS）、一个网络和一个子网、一个地缘组和一个可用性集，以及能够在同一区域中创建新的 VHD 作为云服务，并将这些 VHD 附加到 Linux 虚拟机。</target>
        </trans-unit>
        <trans-unit id="120" translate="yes" xml:space="preserve">
          <source>已测试的环境</source>
          <target state="new">已测试的环境</target>
        </trans-unit>
        <trans-unit id="121" translate="yes" xml:space="preserve">
          <source>Ubuntu 13.10</source>
          <target state="new">Ubuntu 13.10</target>
        </trans-unit>
        <trans-unit id="122" translate="yes" xml:space="preserve">
          <source>DRBD</source>
          <target state="new">DRBD</target>
        </trans-unit>
        <trans-unit id="123" translate="yes" xml:space="preserve">
          <source>MySQL Server</source>
          <target state="new">MySQL Server</target>
        </trans-unit>
        <trans-unit id="124" translate="yes" xml:space="preserve">
          <source>Corosync 和 Pacemaker</source>
          <target state="new">Corosync 和 Pacemaker</target>
        </trans-unit>
        <trans-unit id="125" translate="yes" xml:space="preserve">
          <source>地缘组</source>
          <target state="new">地缘组</target>
        </trans-unit>
        <trans-unit id="126" translate="yes" xml:space="preserve">
          <source>解决方案的地缘组是通过登录到 Azure 门户，向下滚动到“设置”并创建新地缘组来创建的。稍后创建的已分配资源将分配给此地缘组。</source>
          <target state="new">解决方案的地缘组是通过登录到 Azure 门户，向下滚动到“设置”并创建新地缘组来创建的。稍后创建的已分配资源将分配给此地缘组。</target>
        </trans-unit>
        <trans-unit id="127" translate="yes" xml:space="preserve">
          <source>网络</source>
          <target state="new">网络</target>
        </trans-unit>
        <trans-unit id="128" translate="yes" xml:space="preserve">
          <source>将创建新网络，并在该网络内部创建子网。我们选择了其中只有一个 /24 子网的 10.10.10.0/24 网络。</source>
          <target state="new">将创建新网络，并在该网络内部创建子网。我们选择了其中只有一个 /24 子网的 10.10.10.0/24 网络。</target>
        </trans-unit>
        <trans-unit id="129" translate="yes" xml:space="preserve">
          <source>虚拟机</source>
          <target state="new">虚拟机</target>
        </trans-unit>
        <trans-unit id="130" translate="yes" xml:space="preserve">
          <source>第一个 Ubuntu 13.10 VM 是使用 Endorsed Ubuntu 库映像并调用 <ph id="ph1">`hadb01`</ph> 创建的。在此过程中，将创建名为 hadb 的新云服务。我们这样命名它是为了说明当我们添加更多资源时该服务所具有的共享的负载平衡性质。创建 <ph id="ph2">`hadb01`</ph> 是平淡无奇的，可以使用门户完成。将自动创建 SSH 的终结点，并选择我们创建的网络。我们还选择为虚拟机创建新的可用性集。</source>
          <target state="new">第一个 Ubuntu 13.10 VM 是使用 Endorsed Ubuntu 库映像并调用 <ph id="ph1">`hadb01`</ph> 创建的。在此过程中，将创建名为 hadb 的新云服务。我们这样命名它是为了说明当我们添加更多资源时该服务所具有的共享的负载平衡性质。创建 <ph id="ph2">`hadb01`</ph> 是平淡无奇的，可以使用门户完成。将自动创建 SSH 的终结点，并选择我们创建的网络。我们还选择为虚拟机创建新的可用性集。</target>
        </trans-unit>
        <trans-unit id="131" translate="yes" xml:space="preserve">
          <source>创建第一个虚拟机后（从技术上讲，创建云服务时），我们将继续创建第二个虚拟机 <ph id="ph1">`hadb02`</ph>。对于第二个虚拟机，我们还将通过门户使用库中的 Ubuntu 13.10 VM，但我们将选择使用现有的云服务 <ph id="ph2">`hadb.chinacloudapp.cn`</ph>，而不是创建一个新的。应为我们自动选择网络和可用性集。也将创建 SSH 终结点。</source>
          <target state="new">创建第一个虚拟机后（从技术上讲，创建云服务时），我们将继续创建第二个虚拟机 <ph id="ph1">`hadb02`</ph>。对于第二个虚拟机，我们还将通过门户使用库中的 Ubuntu 13.10 VM，但我们将选择使用现有的云服务 <ph id="ph2">`hadb.chinacloudapp.cn`</ph>，而不是创建一个新的。应为我们自动选择网络和可用性集。也将创建 SSH 终结点。</target>
        </trans-unit>
        <trans-unit id="132" translate="yes" xml:space="preserve">
          <source>创建两个 VM 后，我们将记下 <ph id="ph1">`hadb01`</ph> 的 SSH 端口 (TCP 22) 和 <ph id="ph2">`hadb02`</ph>（由 Azure 自动分配）</source>
          <target state="new">创建两个 VM 后，我们将记下 <ph id="ph1">`hadb01`</ph> 的 SSH 端口 (TCP 22) 和 <ph id="ph2">`hadb02`</ph>（由 Azure 自动分配）</target>
        </trans-unit>
        <trans-unit id="133" translate="yes" xml:space="preserve">
          <source>附加存储</source>
          <target state="new">附加存储</target>
        </trans-unit>
        <trans-unit id="134" translate="yes" xml:space="preserve">
          <source>我们将新磁盘附加到这两个 VM，并在进程中创建新的 5 GB 磁盘。磁盘将在 VHD 容器中托管，用作我们的主要操作系统磁盘。创建并附加磁盘后，无需重启 Linux，因为内核将会发现新设备（通常为 <ph id="ph1">`/dev/sdc`</ph>，你可以检查 <ph id="ph2">`dmesg`</ph> 的输出）</source>
          <target state="new">我们将新磁盘附加到这两个 VM，并在进程中创建新的 5 GB 磁盘。磁盘将在 VHD 容器中托管，用作我们的主要操作系统磁盘。创建并附加磁盘后，无需重启 Linux，因为内核将会发现新设备（通常为 <ph id="ph1">`/dev/sdc`</ph>，你可以检查 <ph id="ph2">`dmesg`</ph> 的输出）</target>
        </trans-unit>
        <trans-unit id="135" translate="yes" xml:space="preserve">
          <source>在每个虚拟机上，我们继续使用 <ph id="ph1">`cfdisk`</ph> 创建新分区（主 Linux 分区），并写入新的分区表。<bpt id="p1">**</bpt>不要在此分区上创建文件系统<ept id="p1">**</ept>。</source>
          <target state="new">在每个虚拟机上，我们继续使用 <ph id="ph1">`cfdisk`</ph> 创建新分区（主 Linux 分区），并写入新的分区表。<bpt id="p1">**</bpt>不要在此分区上创建文件系统<ept id="p1">**</ept>。</target>
        </trans-unit>
        <trans-unit id="136" translate="yes" xml:space="preserve">
          <source>设置群集</source>
          <target state="new">设置群集</target>
        </trans-unit>
        <trans-unit id="137" translate="yes" xml:space="preserve">
          <source>在这两个 Ubuntu VM 中，将需要使用 APT 安装 Corosync、Pacemaker 和 DRBD。使用 <ph id="ph1">`apt-get`</ph>：</source>
          <target state="new">在这两个 Ubuntu VM 中，将需要使用 APT 安装 Corosync、Pacemaker 和 DRBD。使用 <ph id="ph1">`apt-get`</ph>：</target>
        </trans-unit>
        <trans-unit id="138" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>这次不安装 MySQL<ept id="p1">**</ept>。Debian 和 Ubuntu 安装脚本将在 <ph id="ph1">`/var/lib/mysql`</ph> 上初始化 MySQL 数据目录，但由于该目录将由 DRBD 文件系统取代，因此我们需要稍后执行此操作。</source>
          <target state="new"><bpt id="p1">**</bpt>这次不安装 MySQL<ept id="p1">**</ept>。Debian 和 Ubuntu 安装脚本将在 <ph id="ph1">`/var/lib/mysql`</ph> 上初始化 MySQL 数据目录，但由于该目录将由 DRBD 文件系统取代，因此我们需要稍后执行此操作。</target>
        </trans-unit>
        <trans-unit id="139" translate="yes" xml:space="preserve">
          <source>此时我们还应该验证（使用 <ph id="ph1">`/sbin/ifconfig`</ph>）这两个 VM 是否使用 10.10.10.0/24 子网中的地址，并且它们是否可以用名称彼此 ping 通。如果需要，还可以使用 <ph id="ph2">`ssh-keygen`</ph> 和 <ph id="ph3">`ssh-copy-id`</ph> 以确保这两个 VM 可以通过 SSH 通信而无需密码。</source>
          <target state="new">此时我们还应该验证（使用 <ph id="ph1">`/sbin/ifconfig`</ph>）这两个 VM 是否使用 10.10.10.0/24 子网中的地址，并且它们是否可以用名称彼此 ping 通。如果需要，还可以使用 <ph id="ph2">`ssh-keygen`</ph> 和 <ph id="ph3">`ssh-copy-id`</ph> 以确保这两个 VM 可以通过 SSH 通信而无需密码。</target>
        </trans-unit>
        <trans-unit id="140" translate="yes" xml:space="preserve">
          <source>设置 DRBD</source>
          <target state="new">设置 DRBD</target>
        </trans-unit>
        <trans-unit id="141" translate="yes" xml:space="preserve">
          <source>我们将创建一个 DRBD 资源，该资源使用基础 <ph id="ph1">`/dev/sdc1`</ph> 分区生成能够使用 ext3 格式化并在主节点和辅助节点中使用的 <ph id="ph2">`/dev/drbd1`</ph> 资源。若要执行此操作，请打开 <ph id="ph3">`/etc/drbd.d/r0.res`</ph> 并复制以下资源定义。在这两个 VM 中执行此操作：</source>
          <target state="new">我们将创建一个 DRBD 资源，该资源使用基础 <ph id="ph1">`/dev/sdc1`</ph> 分区生成能够使用 ext3 格式化并在主节点和辅助节点中使用的 <ph id="ph2">`/dev/drbd1`</ph> 资源。若要执行此操作，请打开 <ph id="ph3">`/etc/drbd.d/r0.res`</ph> 并复制以下资源定义。在这两个 VM 中执行此操作：</target>
        </trans-unit>
        <trans-unit id="142" translate="yes" xml:space="preserve">
          <source>执行此操作后，在这两个 VM 中使用 <ph id="ph1">`drbdadm`</ph> 初始化资源：</source>
          <target state="new">执行此操作后，在这两个 VM 中使用 <ph id="ph1">`drbdadm`</ph> 初始化资源：</target>
        </trans-unit>
        <trans-unit id="143" translate="yes" xml:space="preserve">
          <source>最后，在主节点 (<ph id="ph1">`hadb01`</ph>) 中强制实施 DRBD 资源的所有权（主）：</source>
          <target state="new">最后，在主节点 (<ph id="ph1">`hadb01`</ph>) 中强制实施 DRBD 资源的所有权（主）：</target>
        </trans-unit>
        <trans-unit id="144" translate="yes" xml:space="preserve">
          <source>如果你在这两个 VM 中检查 /proc/drbd (<ph id="ph1">`sudo cat /proc/drbd`</ph>) 的内容，你应在 <ph id="ph2">`hadb01`</ph> 上看到 <ph id="ph3">`Primary/Secondary`</ph>，在 <ph id="ph4">`hadb02`</ph> 上看到 <ph id="ph5">`Secondary/Primary`</ph>，与此时的解决方案保持一致。5 GB 磁盘将通过 10.10.10.0/24 网络进行同步，而不会向客户收取费用。</source>
          <target state="new">如果你在这两个 VM 中检查 /proc/drbd (<ph id="ph1">`sudo cat /proc/drbd`</ph>) 的内容，你应在 <ph id="ph2">`hadb01`</ph> 上看到 <ph id="ph3">`Primary/Secondary`</ph>，在 <ph id="ph4">`hadb02`</ph> 上看到 <ph id="ph5">`Secondary/Primary`</ph>，与此时的解决方案保持一致。5 GB 磁盘将通过 10.10.10.0/24 网络进行同步，而不会向客户收取费用。</target>
        </trans-unit>
        <trans-unit id="145" translate="yes" xml:space="preserve">
          <source>同步磁盘后，便可以在 <ph id="ph1">`hadb01`</ph> 上创建文件系统了。出于测试目的，我们使用了 ext2，但以下指令将创建一个 ext3 文件系统：</source>
          <target state="new">同步磁盘后，便可以在 <ph id="ph1">`hadb01`</ph> 上创建文件系统了。出于测试目的，我们使用了 ext2，但以下指令将创建一个 ext3 文件系统：</target>
        </trans-unit>
        <trans-unit id="146" translate="yes" xml:space="preserve">
          <source>装载 DRBD 资源</source>
          <target state="new">装载 DRBD 资源</target>
        </trans-unit>
        <trans-unit id="147" translate="yes" xml:space="preserve">
          <source>在 <ph id="ph1">`hadb01`</ph> 上，我们现已准备好装载 DRBD 资源。Debian 和派生物使用 <ph id="ph2">`/var/lib/mysql`</ph> 作为 MySQL 的数据目录。由于我们尚未安装 MySQL，我们将创建该目录并装载 DRBD 资源。在 <ph id="ph3">`hadb01`</ph> 上：</source>
          <target state="new">在 <ph id="ph1">`hadb01`</ph> 上，我们现已准备好装载 DRBD 资源。Debian 和派生物使用 <ph id="ph2">`/var/lib/mysql`</ph> 作为 MySQL 的数据目录。由于我们尚未安装 MySQL，我们将创建该目录并装载 DRBD 资源。在 <ph id="ph3">`hadb01`</ph> 上：</target>
        </trans-unit>
        <trans-unit id="148" translate="yes" xml:space="preserve">
          <source>设置 MySQL</source>
          <target state="new">设置 MySQL</target>
        </trans-unit>
        <trans-unit id="149" translate="yes" xml:space="preserve">
          <source>现在你已准备好在 <ph id="ph1">`hadb01`</ph> 上安装 MySQL：</source>
          <target state="new">现在你已准备好在 <ph id="ph1">`hadb01`</ph> 上安装 MySQL：</target>
        </trans-unit>
        <trans-unit id="150" translate="yes" xml:space="preserve">
          <source>对于 <ph id="ph1">`hadb02`</ph>，可以使用两个选项。现在可以安装 mysql-server 了，这将创建 /var/lib/mysql 并填入一个新的数据目录，然后继续执行以删除内容。在 <ph id="ph2">`hadb02`</ph> 上：</source>
          <target state="new">对于 <ph id="ph1">`hadb02`</ph>，可以使用两个选项。现在可以安装 mysql-server 了，这将创建 /var/lib/mysql 并填入一个新的数据目录，然后继续执行以删除内容。在 <ph id="ph2">`hadb02`</ph> 上：</target>
        </trans-unit>
        <trans-unit id="151" translate="yes" xml:space="preserve">
          <source>第二个选项用于故障转移到 <ph id="ph1">`hadb02`</ph>，然后在该处安装 mysql-server（安装脚本会注意到现有安装并且不会动它）</source>
          <target state="new">第二个选项用于故障转移到 <ph id="ph1">`hadb02`</ph>，然后在该处安装 mysql-server（安装脚本会注意到现有安装并且不会动它）</target>
        </trans-unit>
        <trans-unit id="152" translate="yes" xml:space="preserve">
          <source>在 <ph id="ph1">`hadb01`</ph> 上：</source>
          <target state="new">在 <ph id="ph1">`hadb01`</ph> 上：</target>
        </trans-unit>
        <trans-unit id="153" translate="yes" xml:space="preserve">
          <source>在 <ph id="ph1">`hadb02`</ph> 上：</source>
          <target state="new">在 <ph id="ph1">`hadb02`</ph> 上：</target>
        </trans-unit>
        <trans-unit id="154" translate="yes" xml:space="preserve">
          <source>如果你现在不打算故障转移 DRBD，则第一个选项虽说算不上极好但更容易。设置此项后，但可以开始处理 MySQL 数据库了。在 <ph id="ph1">`hadb02`</ph>（或根据 DRBD 处于活动状态的服务器之一）上：</source>
          <target state="new">如果你现在不打算故障转移 DRBD，则第一个选项虽说算不上极好但更容易。设置此项后，但可以开始处理 MySQL 数据库了。在 <ph id="ph1">`hadb02`</ph>（或根据 DRBD 处于活动状态的服务器之一）上：</target>
        </trans-unit>
        <trans-unit id="155" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>警告<ept id="p1">**</ept>：此最后一条语句有效地对该表中的根用户禁用身份验证。这应替换为生产级别 GRANT 语句，并且仅为说明目的才包括在内。</source>
          <target state="new"><bpt id="p1">**</bpt>警告<ept id="p1">**</ept>：此最后一条语句有效地对该表中的根用户禁用身份验证。这应替换为生产级别 GRANT 语句，并且仅为说明目的才包括在内。</target>
        </trans-unit>
        <trans-unit id="156" translate="yes" xml:space="preserve">
          <source>如果要从 VM 外部进行查询，则还需要为 MySQL 启用网络，这是本指南的目的。在这两个 VM 上，打开 <ph id="ph1">`/etc/mysql/my.cnf`</ph> 并浏览到 <ph id="ph2">`bind-address`</ph>，将它从 127.0.0.1 更改为 0.0.0.0。保存该文件之后，在当前主节点上发出 <ph id="ph3">`sudo service mysql restart`</ph>。</source>
          <target state="new">如果要从 VM 外部进行查询，则还需要为 MySQL 启用网络，这是本指南的目的。在这两个 VM 上，打开 <ph id="ph1">`/etc/mysql/my.cnf`</ph> 并浏览到 <ph id="ph2">`bind-address`</ph>，将它从 127.0.0.1 更改为 0.0.0.0。保存该文件之后，在当前主节点上发出 <ph id="ph3">`sudo service mysql restart`</ph>。</target>
        </trans-unit>
        <trans-unit id="157" translate="yes" xml:space="preserve">
          <source>创建 MySQL 负载平衡集</source>
          <target state="new">创建 MySQL 负载平衡集</target>
        </trans-unit>
        <trans-unit id="158" translate="yes" xml:space="preserve">
          <source>我们将返回到 Azure 门户并浏览到 <ph id="ph1">`hadb01`</ph> VM，然后终结点。我们将创建一个新的终结点，从下拉列表中选择 MySQL (TCP 3306)，并勾选<bpt id="p1">*</bpt>“新建负载平衡集”<ept id="p1">*</ept>框。我们将调用我们的负载平衡终结点 <ph id="ph2">`lb-mysql`</ph>。我们将保留大多数选项不动，但时间除外，我们会将其减少到 5（秒，最小值）</source>
          <target state="new">我们将返回到 Azure 门户并浏览到 <ph id="ph1">`hadb01`</ph> VM，然后终结点。我们将创建一个新的终结点，从下拉列表中选择 MySQL (TCP 3306)，并勾选<bpt id="p1">*</bpt>“新建负载平衡集”<ept id="p1">*</ept>框。我们将调用我们的负载平衡终结点 <ph id="ph2">`lb-mysql`</ph>。我们将保留大多数选项不动，但时间除外，我们会将其减少到 5（秒，最小值）</target>
        </trans-unit>
        <trans-unit id="159" translate="yes" xml:space="preserve">
          <source>创建终结点后，我们将转到 <ph id="ph1">`hadb02`</ph> 终结点并创建新的终结点，但我们将选择 <ph id="ph2">`lb-mysql`</ph>，然后从下拉菜单中选择 MySQL。还可以将 Azure CLI 用于此步骤。</source>
          <target state="new">创建终结点后，我们将转到 <ph id="ph1">`hadb02`</ph> 终结点并创建新的终结点，但我们将选择 <ph id="ph2">`lb-mysql`</ph>，然后从下拉菜单中选择 MySQL。还可以将 Azure CLI 用于此步骤。</target>
        </trans-unit>
        <trans-unit id="160" translate="yes" xml:space="preserve">
          <source>此时，我们已具备对群集执行手动操作所需的一切条件。</source>
          <target state="new">此时，我们已具备对群集执行手动操作所需的一切条件。</target>
        </trans-unit>
        <trans-unit id="161" translate="yes" xml:space="preserve">
          <source>测试负载平衡集</source>
          <target state="new">测试负载平衡集</target>
        </trans-unit>
        <trans-unit id="162" translate="yes" xml:space="preserve">
          <source>可以从外部计算机使用任何 MySQL 客户端以及应用程序（例如，作为 Azure Web 应用运行的 phpMyAdmin）执行测试。在这种情况下，我们在另一台 Linux 计算机上使用 MySQL 的命令行工具：</source>
          <target state="new">可以从外部计算机使用任何 MySQL 客户端以及应用程序（例如，作为 Azure Web 应用运行的 phpMyAdmin）执行测试。在这种情况下，我们在另一台 Linux 计算机上使用 MySQL 的命令行工具：</target>
        </trans-unit>
        <trans-unit id="163" translate="yes" xml:space="preserve">
          <source>手动故障转移</source>
          <target state="new">手动故障转移</target>
        </trans-unit>
        <trans-unit id="164" translate="yes" xml:space="preserve">
          <source>现在可以通过关闭 MySQL、切换 DRBD 的主节点并重启 MySQL 来模拟故障转移。</source>
          <target state="new">现在可以通过关闭 MySQL、切换 DRBD 的主节点并重启 MySQL 来模拟故障转移。</target>
        </trans-unit>
        <trans-unit id="165" translate="yes" xml:space="preserve">
          <source>在 hadb01 上：</source>
          <target state="new">在 hadb01 上：</target>
        </trans-unit>
        <trans-unit id="166" translate="yes" xml:space="preserve">
          <source>然后，在 hadb02 上：</source>
          <target state="new">然后，在 hadb02 上：</target>
        </trans-unit>
        <trans-unit id="167" translate="yes" xml:space="preserve">
          <source>手动故障转移后，你可以重复执行远程查询，并且它应该能够完美运行。</source>
          <target state="new">手动故障转移后，你可以重复执行远程查询，并且它应该能够完美运行。</target>
        </trans-unit>
        <trans-unit id="168" translate="yes" xml:space="preserve">
          <source>设置 Corosync</source>
          <target state="new">设置 Corosync</target>
        </trans-unit>
        <trans-unit id="169" translate="yes" xml:space="preserve">
          <source>Corosync 是使 Pacemaker 工作所需的基础群集基础结构。对于检测信号 v1 和 v2 用户（以及 Ultramonkey 等其他方法），Corosync 是 CRM 功能的拆分，而 Pacemaker 将保持更类似于功能中的检测信号。</source>
          <target state="new">Corosync 是使 Pacemaker 工作所需的基础群集基础结构。对于检测信号 v1 和 v2 用户（以及 Ultramonkey 等其他方法），Corosync 是 CRM 功能的拆分，而 Pacemaker 将保持更类似于功能中的检测信号。</target>
        </trans-unit>
        <trans-unit id="170" translate="yes" xml:space="preserve">
          <source>Azure 上 Corosync 的主要约束是 Corosync 首选多播，其次广播，再其次单播通信，但 Azure 网络仅支持单播。</source>
          <target state="new">Azure 上 Corosync 的主要约束是 Corosync 首选多播，其次广播，再其次单播通信，但 Azure 网络仅支持单播。</target>
        </trans-unit>
        <trans-unit id="171" translate="yes" xml:space="preserve">
          <source>幸运的是，Corosync 具有一种工作单播模式，并且唯一的真正约束是，由于并非所有节点之间都<bpt id="p1">*</bpt>自动<ept id="p1">*</ept>互相通信，因此需要在配置文件中定义节点，包括其 IP 地址。我们可以对单播使用 Corosync 示例文件，并只需更改绑定地址、节点列表和日志记录目录（Ubuntu 使用 <ph id="ph1">`/var/log/corosync`</ph>，而示例文件使用 <ph id="ph2">`/var/log/cluster`</ph>），并启用仲裁工具。</source>
          <target state="new">幸运的是，Corosync 具有一种工作单播模式，并且唯一的真正约束是，由于并非所有节点之间都<bpt id="p1">*</bpt>自动<ept id="p1">*</ept>互相通信，因此需要在配置文件中定义节点，包括其 IP 地址。我们可以对单播使用 Corosync 示例文件，并只需更改绑定地址、节点列表和日志记录目录（Ubuntu 使用 <ph id="ph1">`/var/log/corosync`</ph>，而示例文件使用 <ph id="ph2">`/var/log/cluster`</ph>），并启用仲裁工具。</target>
        </trans-unit>
        <trans-unit id="172" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>请记下下面的 <ph id="ph1">`transport: udpu`</ph> 指令以及为节点手动定义的 IP 地址<ept id="p1">**</ept>。</source>
          <target state="new"><bpt id="p1">**</bpt>请记下下面的 <ph id="ph1">`transport: udpu`</ph> 指令以及为节点手动定义的 IP 地址<ept id="p1">**</ept>。</target>
        </trans-unit>
        <trans-unit id="173" translate="yes" xml:space="preserve">
          <source>在两个节点的 <ph id="ph1">`/etc/corosync/corosync.conf`</ph> 上：</source>
          <target state="new">在两个节点的 <ph id="ph1">`/etc/corosync/corosync.conf`</ph> 上：</target>
        </trans-unit>
        <trans-unit id="174" translate="yes" xml:space="preserve">
          <source>我们将此配置文件复制到这两个 VM 中，并在这两个节点中启动 Corosync：</source>
          <target state="new">我们将此配置文件复制到这两个 VM 中，并在这两个节点中启动 Corosync：</target>
        </trans-unit>
        <trans-unit id="175" translate="yes" xml:space="preserve">
          <source>启动该服务后不久，群集应在当前环中建立，并应构成仲裁。我们可以通过查看日志或以下项来检查此功能：</source>
          <target state="new">启动该服务后不久，群集应在当前环中建立，并应构成仲裁。我们可以通过查看日志或以下项来检查此功能：</target>
        </trans-unit>
        <trans-unit id="176" translate="yes" xml:space="preserve">
          <source>应符合类似于下图所示的输出：</source>
          <target state="new">应符合类似于下图所示的输出：</target>
        </trans-unit>
        <trans-unit id="177" translate="yes" xml:space="preserve">
          <source>corosync-quorumtool -l sample output</source>
          <target state="new">corosync-quorumtool -l sample output</target>
        </trans-unit>
        <trans-unit id="178" translate="yes" xml:space="preserve">
          <source>设置 Pacemaker</source>
          <target state="new">设置 Pacemaker</target>
        </trans-unit>
        <trans-unit id="179" translate="yes" xml:space="preserve">
          <source>Pacemaker 使用群集监视资源、定义主节点何时停机，并将这些资源切换到辅助节点。可以通过一组可用脚本或 LSB（类似 init）脚本以及其他选项定义资源。</source>
          <target state="new">Pacemaker 使用群集监视资源、定义主节点何时停机，并将这些资源切换到辅助节点。可以通过一组可用脚本或 LSB（类似 init）脚本以及其他选项定义资源。</target>
        </trans-unit>
        <trans-unit id="180" translate="yes" xml:space="preserve">
          <source>我们想要 Pacemaker“拥有”DRBD 资源、装入点和 MySQL 服务。如果在主节点出现问题时 Pacemaker 可以启用和关闭 DRBD，请按正确的顺序装载/卸载它，并启动/停止 MySQL，我们的设置已完成。</source>
          <target state="new">我们想要 Pacemaker“拥有”DRBD 资源、装入点和 MySQL 服务。如果在主节点出现问题时 Pacemaker 可以启用和关闭 DRBD，请按正确的顺序装载/卸载它，并启动/停止 MySQL，我们的设置已完成。</target>
        </trans-unit>
        <trans-unit id="181" translate="yes" xml:space="preserve">
          <source>首次安装 Pacemaker 时，你的配置应足够简单，如下所示：</source>
          <target state="new">首次安装 Pacemaker 时，你的配置应足够简单，如下所示：</target>
        </trans-unit>
        <trans-unit id="182" translate="yes" xml:space="preserve">
          <source>通过运行 <ph id="ph1">`sudo crm configure show`</ph> 来检查它。现在，使用以下资源创建一个文件（假设 <ph id="ph2">`/tmp/cluster.conf`</ph>）：</source>
          <target state="new">通过运行 <ph id="ph1">`sudo crm configure show`</ph> 来检查它。现在，使用以下资源创建一个文件（假设 <ph id="ph2">`/tmp/cluster.conf`</ph>）：</target>
        </trans-unit>
        <trans-unit id="183" translate="yes" xml:space="preserve">
          <source>并立即将其加载到配置中（只需在一个节点上执行此操作）：</source>
          <target state="new">并立即将其加载到配置中（只需在一个节点上执行此操作）：</target>
        </trans-unit>
        <trans-unit id="184" translate="yes" xml:space="preserve">
          <source>此处，请确保 Pacemaker 在这两个节点中引导时启动：</source>
          <target state="new">此处，请确保 Pacemaker 在这两个节点中引导时启动：</target>
        </trans-unit>
        <trans-unit id="185" translate="yes" xml:space="preserve">
          <source>几秒钟后，请使用 <ph id="ph1">`sudo crm_mon –L`</ph> 验证你的节点之一是否已成为群集的主机并且正在运行所有资源。可以使用 mount 和 PS 来检查资源是否正在运行。</source>
          <target state="new">几秒钟后，请使用 <ph id="ph1">`sudo crm_mon –L`</ph> 验证你的节点之一是否已成为群集的主机并且正在运行所有资源。可以使用 mount 和 PS 来检查资源是否正在运行。</target>
        </trans-unit>
        <trans-unit id="186" translate="yes" xml:space="preserve">
          <source>下面的屏幕截图显示一个节点已停止的 <ph id="ph1">`crm_mon`</ph>（使用 Control-C 退出）</source>
          <target state="new">下面的屏幕截图显示一个节点已停止的 <ph id="ph1">`crm_mon`</ph>（使用 Control-C 退出）</target>
        </trans-unit>
        <trans-unit id="187" translate="yes" xml:space="preserve">
          <source>crm\_mon 节点已停止</source>
          <target state="new">crm\_mon 节点已停止</target>
        </trans-unit>
        <trans-unit id="188" translate="yes" xml:space="preserve">
          <source>并且此屏幕截图显示这两个节点（一个主节点和一个从节点）：</source>
          <target state="new">并且此屏幕截图显示这两个节点（一个主节点和一个从节点）：</target>
        </trans-unit>
        <trans-unit id="189" translate="yes" xml:space="preserve">
          <source>crm\_mon 操作主/从</source>
          <target state="new">crm\_mon 操作主/从</target>
        </trans-unit>
        <trans-unit id="190" translate="yes" xml:space="preserve">
          <source>测试</source>
          <target state="new">测试</target>
        </trans-unit>
        <trans-unit id="191" translate="yes" xml:space="preserve">
          <source>我们已准备好进行自动故障转移模拟。可通过两种方式执行此操作：软方式和硬方式。软方式使用群集的关闭功能：<ph id="ph1">``crm_standby -U `uname -n` -v on``</ph>。在主节点上使用此功能时，从节点将接管。记住将此功能重新设为 off（crm_mon 会指示一个节点处于启用状态，其他节点处入待机状态）</source>
          <target state="new">我们已准备好进行自动故障转移模拟。可通过两种方式执行此操作：软方式和硬方式。软方式使用群集的关闭功能：<ph id="ph1">``crm_standby -U `uname -n` -v on``</ph>。在主节点上使用此功能时，从节点将接管。记住将此功能重新设为 off（crm_mon 会指示一个节点处于启用状态，其他节点处入待机状态）</target>
        </trans-unit>
        <trans-unit id="192" translate="yes" xml:space="preserve">
          <source>硬方式是通过门户关闭主虚拟机 (hadb01) 或更改虚拟机上的运行级别（即，停止、关闭），然后，我们将通过指示主节点将要关闭来帮助 Corosync 和 Pacemaker。我们可以对此进行测试（适用于维护窗口），但我们也可以通过只冻结虚拟机来强制实施该方案。</source>
          <target state="new">硬方式是通过门户关闭主虚拟机 (hadb01) 或更改虚拟机上的运行级别（即，停止、关闭），然后，我们将通过指示主节点将要关闭来帮助 Corosync 和 Pacemaker。我们可以对此进行测试（适用于维护窗口），但我们也可以通过只冻结虚拟机来强制实施该方案。</target>
        </trans-unit>
        <trans-unit id="193" translate="yes" xml:space="preserve">
          <source>STONITH</source>
          <target state="new">STONITH</target>
        </trans-unit>
        <trans-unit id="194" translate="yes" xml:space="preserve">
          <source>它应该能够通过 Azure CLI 代替用于控制物理设备的 STONITH 脚本向 VM 发出关闭命令。可以使用 <ph id="ph1">`/usr/lib/stonith/plugins/external/ssh`</ph> 作为基础并在群集的配置中启用 STONITH。应全局安装 Azure CLI 并应为群集的用户加载发布设置/配置文件。</source>
          <target state="new">它应该能够通过 Azure CLI 代替用于控制物理设备的 STONITH 脚本向 VM 发出关闭命令。可以使用 <ph id="ph1">`/usr/lib/stonith/plugins/external/ssh`</ph> 作为基础并在群集的配置中启用 STONITH。应全局安装 Azure CLI 并应为群集的用户加载发布设置/配置文件。</target>
        </trans-unit>
        <trans-unit id="195" translate="yes" xml:space="preserve">
          <source>资源的示例代码可在 <bpt id="p1">[</bpt>GitHub<ept id="p1">](https://github.com/bureado/aztonith)</ept> 上找到。你需要更改群集的配置，方法是将以下代码添加到 <ph id="ph1">`sudo crm configure`</ph>：</source>
          <target state="new">资源的示例代码可在 <bpt id="p1">[</bpt>GitHub<ept id="p1">](https://github.com/bureado/aztonith)</ept> 上找到。你需要更改群集的配置，方法是将以下代码添加到 <ph id="ph1">`sudo crm configure`</ph>：</target>
        </trans-unit>
        <trans-unit id="196" translate="yes" xml:space="preserve">
          <source><bpt id="p1">**</bpt>注意：<ept id="p1">**</ept> 该脚本不执行向上/向下检查。原始 SSH 资源使用 15 次 ping 检查，但 Azure VM 的恢复时间可能更多变。</source>
          <target state="new"><bpt id="p1">**</bpt>注意：<ept id="p1">**</ept> 该脚本不执行向上/向下检查。原始 SSH 资源使用 15 次 ping 检查，但 Azure VM 的恢复时间可能更多变。</target>
        </trans-unit>
        <trans-unit id="197" translate="yes" xml:space="preserve">
          <source>限制</source>
          <target state="new">限制</target>
        </trans-unit>
        <trans-unit id="198" translate="yes" xml:space="preserve">
          <source>以下限制适用：</source>
          <target state="new">以下限制适用：</target>
        </trans-unit>
        <trans-unit id="199" translate="yes" xml:space="preserve">
          <source>管理 DRBD 的 linbit DRBD 资源脚本作为 Pacemaker 中的资源在关闭节点时使用 <ph id="ph1">`drbdadm down`</ph>，即使该节点只是转为待机状态也是如此。这并不理想，因为当主节点获得写入时，从节点将不会同步 DRBD 资源。如果主节点未优雅地失败，则从节点可以接受较旧的文件系统状态。可通过两种可能方式来解决此问题：</source>
          <target state="new">管理 DRBD 的 linbit DRBD 资源脚本作为 Pacemaker 中的资源在关闭节点时使用 <ph id="ph1">`drbdadm down`</ph>，即使该节点只是转为待机状态也是如此。这并不理想，因为当主节点获得写入时，从节点将不会同步 DRBD 资源。如果主节点未优雅地失败，则从节点可以接受较旧的文件系统状态。可通过两种可能方式来解决此问题：</target>
        </trans-unit>
        <trans-unit id="200" translate="yes" xml:space="preserve">
          <source>在所有群集节点上通过本地（非群集化）监视程序强制执行 <ph id="ph1">`drbdadm up r0`</ph>，或者</source>
          <target state="new">在所有群集节点上通过本地（非群集化）监视程序强制执行 <ph id="ph1">`drbdadm up r0`</ph>，或者</target>
        </trans-unit>
        <trans-unit id="201" translate="yes" xml:space="preserve">
          <source>编辑 linbit DRBD 脚本以确保未在 <ph id="ph1">`/usr/lib/ocf/resource.d/linbit/drbd`</ph> 中调用 <ph id="ph2">`down`</ph>。</source>
          <target state="new">编辑 linbit DRBD 脚本以确保未在 <ph id="ph1">`/usr/lib/ocf/resource.d/linbit/drbd`</ph> 中调用 <ph id="ph2">`down`</ph>。</target>
        </trans-unit>
        <trans-unit id="202" translate="yes" xml:space="preserve">
          <source>负载平衡器至少需要 5 秒钟才能做出响应，因此应用程序应是群集感知的并更容忍超时；其他体系结构也会有帮助，例如应用程序中队列、查询中间件等。</source>
          <target state="new">负载平衡器至少需要 5 秒钟才能做出响应，因此应用程序应是群集感知的并更容忍超时；其他体系结构也会有帮助，例如应用程序中队列、查询中间件等。</target>
        </trans-unit>
        <trans-unit id="203" translate="yes" xml:space="preserve">
          <source>有必要进行 MySQL 优化以确保以合理的速度完成写入，并且尽可能频繁地将缓存刷新到磁盘</source>
          <target state="new">有必要进行 MySQL 优化以确保以合理的速度完成写入，并且尽可能频繁地将缓存刷新到磁盘</target>
        </trans-unit>
        <trans-unit id="204" translate="yes" xml:space="preserve">
          <source>写入性能将依赖于虚拟交换机中的 VM 互连，因为这是 DRBD 用于复制设备的机制</source>
          <target state="new">写入性能将依赖于虚拟交换机中的 VM 互连，因为这是 DRBD 用于复制设备的机制</target>
        </trans-unit>
      </group>
    </body>
  </file>
</xliff>