{
  "nodes": [
    {
      "content": "为 Apache Storm 开发基于 Java 的拓扑 | Azure",
      "pos": [
        26,
        62
      ]
    },
    {
      "content": "了解如何通过创建一个简单的单词计数拓扑，来以 Java 语言创建一个 Storm 拓扑。",
      "pos": [
        80,
        124
      ]
    },
    {
      "content": "使用 Apache Storm 和 HDInsight 上的 Maven 为基本的单词计数应用程序开发基于 Java 的拓扑",
      "pos": [
        358,
        420
      ]
    },
    {
      "content": "了解使用 Maven 为 Apache Storm on HDInsight 创建基于 Java 的拓扑的基本过程。将会演练使用 Maven 和 Java 创建基本单词计数应用程序的过程。虽然本文提供了有关使用 Eclipse 的说明，但你也可以使用所选的文本编辑器。",
      "pos": [
        422,
        556
      ]
    },
    {
      "content": "完成本文档中的步骤之后，你将会获得一个用于部署到 Apache Storm on HDInsight 的基本拓扑。",
      "pos": [
        558,
        615
      ]
    },
    {
      "pos": [
        619,
        777
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>：此拓扑的完整版本在 <bpt id=\"p1\">[</bpt>https://github.com/Azure-Samples/hdinsight-java-storm-wordcount<ept id=\"p1\">](https://github.com/Azure-Samples/hdinsight-java-storm-wordcount)</ept> 中提供。"
    },
    {
      "content": "先决条件",
      "pos": [
        781,
        785
      ]
    },
    {
      "pos": [
        789,
        927
      ],
      "content": "<ph id=\"ph1\">&lt;a href=\"https://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html\" target=\"_blank\"&gt;</ph>Java 开发人员工具包 (JDK) 版本 7<ph id=\"ph2\">&lt;/a&gt;</ph>"
    },
    {
      "pos": [
        931,
        1028
      ],
      "content": "<ph id=\"ph1\">&lt;a href=\"https://maven.apache.org/download.cgi\" target=\"_blank\"&gt;</ph>Maven<ph id=\"ph2\">&lt;/a&gt;</ph>：Maven 是 Java 项目的项目生成系统。"
    },
    {
      "pos": [
        1032,
        1393
      ],
      "content": "文本编辑器，例如记事本、<ph id=\"ph1\">&lt;a href=\"http://www.gnu.org/software/emacs/\" target=\"_blank\"&gt;</ph>Emacs<ph id=\"ph2\">&lt;a&gt;</ph>、<ph id=\"ph3\">&lt;a href=\"http://www.sublimetext.com/\" target=\"_blank\"&gt;</ph>Sublime Text<ph id=\"ph4\">&lt;/a&gt;</ph>、<ph id=\"ph5\">&lt;a href=\"https://atom.io/\" target=\"_blank\"&gt;</ph>Atom.io<ph id=\"ph6\">&lt;/a&gt;</ph>、<ph id=\"ph7\">&lt;a href=\"http://brackets.io/\" target=\"_blank\"&gt;</ph>Brackets.io<ph id=\"ph8\">&lt;/a&gt;</ph>。或者使用集成开发环境 (IDE)，例如 <ph id=\"ph9\">&lt;a href=\"https://eclipse.org/\" target=\"_blank\"&gt;</ph>Eclipse<ph id=\"ph10\">&lt;/a&gt;</ph>（Luna 或更高版本）。"
    },
    {
      "pos": [
        1401,
        1481
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> 你的编辑器或 IDE 可能具有处理 Maven 的特定功能，但本文档中未提供说明。有关环境编辑功能的详细信息，请参阅所使用产品的文档。"
    },
    {
      "content": "配置环境变量",
      "pos": [
        1485,
        1491
      ]
    },
    {
      "content": "可以在安装 Java 和 JDK 时设置以下环境变量。不过，你应该检查它们是否存在并且包含系统的正确值。",
      "pos": [
        1493,
        1545
      ]
    },
    {
      "pos": [
        1549,
        1653
      ],
      "content": "<bpt id=\"p1\">**</bpt>JAVA\\_HOME<ept id=\"p1\">**</ept> - 应该指向已安装 Java 运行时环境 (JRE) 的目录。例如，在 Windows 中，它的值类似于 <ph id=\"ph1\">`c:\\Program Files (x86)\\Java\\jre1.7`</ph>"
    },
    {
      "pos": [
        1657,
        1677
      ],
      "content": "<bpt id=\"p1\">**</bpt>PATH<ept id=\"p1\">**</ept> - 应该包含以下路径："
    },
    {
      "pos": [
        1685,
        1707
      ],
      "content": "<bpt id=\"p1\">**</bpt>JAVA\\_HOME<ept id=\"p1\">**</ept>（或等效的路径）"
    },
    {
      "pos": [
        1715,
        1742
      ],
      "content": "<bpt id=\"p1\">**</bpt>JAVA\\_HOME\\\\bin<ept id=\"p1\">**</ept>（或等效的路径）"
    },
    {
      "content": "安装 Maven 的目录",
      "pos": [
        1750,
        1762
      ]
    },
    {
      "content": "创建新的 Maven 项目",
      "pos": [
        1766,
        1779
      ]
    },
    {
      "pos": [
        1781,
        1824
      ],
      "content": "从命令行中，使用以下代码创建名为 <bpt id=\"p1\">**</bpt>WordCount<ept id=\"p1\">**</ept> 的新 Maven 项目："
    },
    {
      "pos": [
        1982,
        2029
      ],
      "content": "这会在当前位置创建名为 <bpt id=\"p1\">**</bpt>WordCount<ept id=\"p1\">**</ept> 的新目录，其中包含基本 Maven 项目。"
    },
    {
      "pos": [
        2031,
        2054
      ],
      "content": "<bpt id=\"p1\">**</bpt>WordCount<ept id=\"p1\">**</ept> 目录将包含以下项："
    },
    {
      "pos": [
        2058,
        2085
      ],
      "content": "<bpt id=\"p1\">**</bpt>pom.xml<ept id=\"p1\">**</ept>：包含 Maven 项目的设置。"
    },
    {
      "pos": [
        2089,
        2143
      ],
      "content": "<bpt id=\"p1\">**</bpt>src\\\\main\\\\java\\\\com\\\\microsoft\\\\example<ept id=\"p1\">**</ept>：包含应用程序代码。"
    },
    {
      "pos": [
        2147,
        2217
      ],
      "content": "<bpt id=\"p1\">**</bpt>src\\\\test\\\\java\\\\com\\\\microsoft\\\\example<ept id=\"p1\">**</ept>：包含应用程序的测试。对于本示例，我们将不创建测试。"
    },
    {
      "content": "删除示例代码",
      "pos": [
        2222,
        2228
      ]
    },
    {
      "content": "由于我们要创建应用程序，因此请删除生成的测试和应用程序文件：",
      "pos": [
        2230,
        2260
      ]
    },
    {
      "content": "src\\\\test\\\\java\\\\com\\\\microsoft\\\\example\\\\AppTest.java",
      "pos": [
        2267,
        2321
      ]
    },
    {
      "content": "src\\\\main\\\\java\\\\com\\\\microsoft\\\\example\\\\App.java",
      "pos": [
        2330,
        2380
      ]
    },
    {
      "content": "添加依赖项",
      "pos": [
        2386,
        2391
      ]
    },
    {
      "pos": [
        2393,
        2479
      ],
      "content": "由于这是一个 Storm 拓扑，因此你必须添加 Storm 组件的依赖项。打开 <bpt id=\"p1\">**</bpt>pom.xml<ept id=\"p1\">**</ept>，并在 <bpt id=\"p2\">**</bpt>&amp;lt;dependencies&gt;<ept id=\"p2\">**</ept> 节中添加以下代码："
    },
    {
      "pos": [
        2732,
        2839
      ],
      "content": "在编译时，Maven 会使用此信息来查找 Maven 存储库中的 <bpt id=\"p1\">**</bpt>storm-core<ept id=\"p1\">**</ept>。它会先查找本地计算机上的存储库。如果文件不存在，它会从公共 Maven 存储库下载这些文件，并将其存储在本地存储库中。"
    },
    {
      "pos": [
        2843,
        3020
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> 请注意我们在该节中添加的 <ph id=\"ph2\">`&lt;scope&gt;provided&lt;/scope&gt;`</ph> 行。这会告诉 Maven 从我们创建的任何 JAR 文件中排除 <bpt id=\"p1\">**</bpt>storm-core<ept id=\"p1\">**</ept>，因为系统将会予以提供。这样，便可以稍微减小所创建的包，并确保它们使用 Storm on HDInsight 群集中包含的 <bpt id=\"p2\">**</bpt>storm-core<ept id=\"p2\">**</ept> 位。"
    },
    {
      "content": "生成配置",
      "pos": [
        3024,
        3028
      ]
    },
    {
      "pos": [
        3030,
        3123
      ],
      "content": "Maven 插件可让你自定义项目的生成阶段，例如，如何编译项目，或者如何将它打包成 JAR 文件。打开 <bpt id=\"p1\">**</bpt>pom.xml<ept id=\"p1\">**</ept>，并紧靠在 <ph id=\"ph1\">`&lt;/project&gt;`</ph> 行的上方添加以下代码。"
    },
    {
      "content": "此节将用来添加插件和其他生成配置选项。",
      "pos": [
        3184,
        3203
      ]
    },
    {
      "content": "添加插件",
      "pos": [
        3208,
        3212
      ]
    },
    {
      "pos": [
        3214,
        3396
      ],
      "content": "针对 Storm 拓扑，<ph id=\"ph1\">&lt;a href=\"http://mojo.codehaus.org/exec-maven-plugin/\" target=\"_blank\"&gt;</ph>Exec Maven 插件<ph id=\"ph2\">&lt;/a&gt;</ph>十分有用，因为它可让你轻松地在开发环境本地运行拓扑。将以下内容添加至 <bpt id=\"p1\">**</bpt>pom.xml<ept id=\"p1\">**</ept> 文件的 <ph id=\"ph3\">`&lt;plugins&gt;`</ph> 节，以包括 Exec Maven 插件："
    },
    {
      "pos": [
        3979,
        4164
      ],
      "content": "另一个有用的插件是用于更改编译选项的 <ph id=\"ph1\">&lt;a href=\"http://maven.apache.org/plugins/maven-compiler-plugin/\" target=\"_blank\"&gt;</ph>Apache Maven Compiler 插件<ph id=\"ph2\">&lt;/a&gt;</ph>。我们需要此插件的主要原因是要更改 Maven 用作应用程序源和目标的 Java 版本。我们需要的是版本 1.7。"
    },
    {
      "pos": [
        4166,
        4247
      ],
      "content": "在 <bpt id=\"p1\">**</bpt>pom.xml<ept id=\"p1\">**</ept> 的 <ph id=\"ph1\">`&lt;plugins&gt;`</ph> 节中添加以下内容，以包括 Apache Maven Compiler 插件并将源和目标版本设置为 1.7。"
    },
    {
      "content": "创建拓扑",
      "pos": [
        4485,
        4489
      ]
    },
    {
      "content": "基于 Java 的 Storm 拓扑包含你必须编写（或引用）为依赖项的三个组件。",
      "pos": [
        4491,
        4531
      ]
    },
    {
      "pos": [
        4535,
        4567
      ],
      "content": "<bpt id=\"p1\">**</bpt>Spout<ept id=\"p1\">**</ept>：读取外部源中的数据，并发出进入拓扑的数据流。"
    },
    {
      "pos": [
        4571,
        4621
      ],
      "content": "<bpt id=\"p1\">**</bpt>Bolt<ept id=\"p1\">**</ept>：对 Spout 或其他 Bolt 所发出的数据流执行处理，并发出一个或多个数据流。"
    },
    {
      "pos": [
        4625,
        4662
      ],
      "content": "<bpt id=\"p1\">**</bpt>拓扑<ept id=\"p1\">**</ept>：定义如何排列 Spout 和 Bolt，并提供拓扑的入口点。"
    },
    {
      "content": "创建 Spout",
      "pos": [
        4667,
        4675
      ]
    },
    {
      "pos": [
        4677,
        4843
      ],
      "content": "为了降低设置外部数据源的要求，以下 Spout 只会发出随机句子。它是 <ph id=\"ph1\">&lt;a href=\"https://github.com/apache/storm/blob/master/examples/storm-starter/\" target=\"_blank\"&gt;</ph>Storm-Starter 示例<ph id=\"ph2\">&lt;/a&gt;</ph>随附的 Spout 的修改版本。"
    },
    {
      "pos": [
        4847,
        5016
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> 有关从外部数据源读取的 Spout 的示例，请参阅以下示例：<ph id=\"ph2\">&lt;a href=\"https://github.com/apache/storm/tree/master/external/storm-kafka\" target=\"_blank\"&gt;</ph>Storm-Kafka<ph id=\"ph3\">&lt;/a&gt;</ph>：从 Kafka 读取数据的 Spout"
    },
    {
      "pos": [
        5018,
        5128
      ],
      "content": "对于 Spout，在 <bpt id=\"p1\">**</bpt>src\\\\main\\\\java\\\\com\\\\microsoft\\\\example<ept id=\"p1\">**</ept> 目录中创建名为 <bpt id=\"p2\">**</bpt>RandomSentenceSpout.java<ept id=\"p2\">**</ept> 的新文件，并使用以下内容做为内容："
    },
    {
      "content": "请花费片刻时间通读代码注释，以了解此 Spout 的工作原理。",
      "pos": [
        8221,
        8252
      ]
    },
    {
      "pos": [
        8256,
        8316
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> 虽然此拓扑只使用一个 Spout，但其他拓扑可能存在将数据从不同源送入拓扑的多个 Spout。"
    },
    {
      "content": "创建 Bolt",
      "pos": [
        8321,
        8328
      ]
    },
    {
      "content": "Bolt 用于处理数据。此拓扑有两个 Bolt：",
      "pos": [
        8330,
        8354
      ]
    },
    {
      "pos": [
        8358,
        8416
      ],
      "content": "<bpt id=\"p1\">**</bpt>SplitSentence<ept id=\"p1\">**</ept>：将 <bpt id=\"p2\">**</bpt>RandomSentenceSpout<ept id=\"p2\">**</ept> 发出的句子分割成不同的单词。"
    },
    {
      "pos": [
        8420,
        8446
      ],
      "content": "<bpt id=\"p1\">**</bpt>WordCount<ept id=\"p1\">**</ept>：统计每个单词的出现次数。"
    },
    {
      "pos": [
        8450,
        8498
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> Bolt 几乎可以执行任何操作，例如，计算、保存，或者与外部组件通信。"
    },
    {
      "pos": [
        8500,
        8617
      ],
      "content": "在 <bpt id=\"p1\">**</bpt>src\\\\main\\\\java\\\\com\\\\microsoft\\\\example<ept id=\"p1\">**</ept> 目录中创建两个新文件：<bpt id=\"p2\">**</bpt>SplitSentence.java<ept id=\"p2\">**</ept> 和 <bpt id=\"p3\">**</bpt>WordCount.Java<ept id=\"p3\">**</ept>。将以下内容用作这些文件的内容："
    },
    {
      "content": "SplitSentence",
      "pos": [
        8621,
        8634
      ]
    },
    {
      "content": "WordCount",
      "pos": [
        10340,
        10349
      ]
    },
    {
      "content": "请花费片刻时间通读代码注释，以了解每个 Bolt 的工作原理。",
      "pos": [
        11797,
        11828
      ]
    },
    {
      "content": "创建拓扑",
      "pos": [
        11833,
        11837
      ]
    },
    {
      "content": "拓扑将 Spout 和 Bolt 一起绑定到图形，该图形定义了组件之间的数据流动方式。它还提供 Storm 在群集内创建组件的实例时使用的并行度提示。",
      "pos": [
        11839,
        11914
      ]
    },
    {
      "content": "以下是此拓扑的组件的基本原理图。",
      "pos": [
        11916,
        11932
      ]
    },
    {
      "content": "显示 Spout 和 Bolt 排列方式的示意图",
      "pos": [
        11936,
        11960
      ]
    },
    {
      "pos": [
        12033,
        12143
      ],
      "content": "若要实现该拓扑，请在 <bpt id=\"p1\">**</bpt>src\\\\main\\\\java\\\\com\\\\microsoft\\\\example<ept id=\"p1\">**</ept> 目录中创建名为 <bpt id=\"p2\">**</bpt>WordCountTopology.java<ept id=\"p2\">**</ept> 的新文件。将以下内容用作该文件的内容："
    },
    {
      "content": "请花片刻时间通读代码注释以了解拓扑的定义方式，然后将拓扑提交到群集。",
      "pos": [
        14488,
        14522
      ]
    },
    {
      "content": "在本地测试拓扑",
      "pos": [
        14526,
        14533
      ]
    },
    {
      "content": "保存文件之后，请使用以下命令在本地测试拓扑。",
      "pos": [
        14535,
        14557
      ]
    },
    {
      "content": "运行该命令时，拓扑会显示启动信息。然后开始显示与下面类似的行，因为句子是从 Spout 发出，然后由 Bolt 处理的。",
      "pos": [
        14643,
        14703
      ]
    },
    {
      "content": "从此输出中可以看到发生了以下情况：",
      "pos": [
        16208,
        16225
      ]
    },
    {
      "content": "Spout 发出“an apple a day keeps the doctor away”。",
      "pos": [
        16230,
        16277
      ]
    },
    {
      "content": "Split Bolt 开始发出句子中的各个单词。",
      "pos": [
        16282,
        16306
      ]
    },
    {
      "content": "Count Bolt 开始发出每个单词及其发出次数。",
      "pos": [
        16311,
        16337
      ]
    },
    {
      "content": "查看 Count Bolt 所发出的数据，“apple”已发出 53 次。只要拓扑运行，计数就会持续增加，因为系统会随机反复发出相同的句子，并且永不会重置计数。",
      "pos": [
        16339,
        16419
      ]
    },
    {
      "content": "Trident",
      "pos": [
        16423,
        16430
      ]
    },
    {
      "content": "Trident 是 Storm 提供的高级抽象。它支持有状态处理。Trident 的主要优点在于，它可以保证进入拓扑的每个消息只会处理一次。这在保证消息至少处理一次的原始 Java 拓扑中很难实现。两者还有其他方面的差异，例如，可以使用内置组件，而无需创建 Bolt。事实上，可以使用低泛型组件（例如筛选、投影和函数）来完全取代 Bolt。",
      "pos": [
        16432,
        16602
      ]
    },
    {
      "content": "你可以使用 Maven 项目来创建 Trident 应用程序。使用本文前面所述的相同基本步骤 - 只有代码不同。",
      "pos": [
        16604,
        16660
      ]
    },
    {
      "pos": [
        16662,
        16792
      ],
      "content": "有关 Trident 的详细信息，请参阅 <ph id=\"ph1\">&lt;a href=\"http://storm.apache.org/documentation/Trident-API-Overview.html\" target=\"_blank\"&gt;</ph>Trident API 概述<ph id=\"ph2\">&lt;/a&gt;</ph>。"
    },
    {
      "content": "后续步骤",
      "pos": [
        16796,
        16800
      ]
    },
    {
      "content": "你已学习如何使用 Java 创建 Storm 拓扑。接下来，请学习如何：",
      "pos": [
        16802,
        16838
      ]
    },
    {
      "content": "在 HDInsight 上部署和管理 Apache Storm 拓扑",
      "pos": [
        16843,
        16877
      ]
    },
    {
      "content": "使用 Visual Studio 开发 Apache Storm on HDInsight 的 C# 拓扑",
      "pos": [
        16948,
        17001
      ]
    },
    {
      "pos": [
        17083,
        17187
      ],
      "content": "如需更多 Storm 拓扑示例，请访问 <bpt id=\"p1\">[</bpt>Storm on HDInsight 拓扑示例<ept id=\"p1\">](/documentation/articles/hdinsight-storm-example-topology)</ept>。"
    }
  ],
  "content": "<properties\n   pageTitle=\"为 Apache Storm 开发基于 Java 的拓扑 | Azure\"\n   description=\"了解如何通过创建一个简单的单词计数拓扑，来以 Java 语言创建一个 Storm 拓扑。\"\n   services=\"hdinsight\"\n   documentationCenter=\"\"\n   authors=\"Blackmist\"\n   manager=\"paulettm\"\n   editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.date=\"01/29/2016\"\n    wacn.date=\"03/17/2016\"/>\n\n#使用 Apache Storm 和 HDInsight 上的 Maven 为基本的单词计数应用程序开发基于 Java 的拓扑\n\n了解使用 Maven 为 Apache Storm on HDInsight 创建基于 Java 的拓扑的基本过程。将会演练使用 Maven 和 Java 创建基本单词计数应用程序的过程。虽然本文提供了有关使用 Eclipse 的说明，但你也可以使用所选的文本编辑器。\n\n完成本文档中的步骤之后，你将会获得一个用于部署到 Apache Storm on HDInsight 的基本拓扑。\n\n> [AZURE.NOTE]：此拓扑的完整版本在 [https://github.com/Azure-Samples/hdinsight-java-storm-wordcount](https://github.com/Azure-Samples/hdinsight-java-storm-wordcount) 中提供。\n\n##先决条件\n\n* <a href=\"https://www.oracle.com/technetwork/java/javase/downloads/jdk7-downloads-1880260.html\" target=\"_blank\">Java 开发人员工具包 (JDK) 版本 7</a>\n\n* <a href=\"https://maven.apache.org/download.cgi\" target=\"_blank\">Maven</a>：Maven 是 Java 项目的项目生成系统。\n\n* 文本编辑器，例如记事本、<a href=\"http://www.gnu.org/software/emacs/\" target=\"_blank\">Emacs<a>、<a href=\"http://www.sublimetext.com/\" target=\"_blank\">Sublime Text</a>、<a href=\"https://atom.io/\" target=\"_blank\">Atom.io</a>、<a href=\"http://brackets.io/\" target=\"_blank\">Brackets.io</a>。或者使用集成开发环境 (IDE)，例如 <a href=\"https://eclipse.org/\" target=\"_blank\">Eclipse</a>（Luna 或更高版本）。\n\n    > [AZURE.NOTE] 你的编辑器或 IDE 可能具有处理 Maven 的特定功能，但本文档中未提供说明。有关环境编辑功能的详细信息，请参阅所使用产品的文档。\n\n##配置环境变量\n\n可以在安装 Java 和 JDK 时设置以下环境变量。不过，你应该检查它们是否存在并且包含系统的正确值。\n\n* **JAVA\\_HOME** - 应该指向已安装 Java 运行时环境 (JRE) 的目录。例如，在 Windows 中，它的值类似于 `c:\\Program Files (x86)\\Java\\jre1.7`\n\n* **PATH** - 应该包含以下路径：\n\n    * **JAVA\\_HOME**（或等效的路径）\n\n    * **JAVA\\_HOME\\\\bin**（或等效的路径）\n\n    * 安装 Maven 的目录\n\n##创建新的 Maven 项目\n\n从命令行中，使用以下代码创建名为 **WordCount** 的新 Maven 项目：\n\n    mvn archetype:generate -DarchetypeArtifactId=maven-archetype-quickstart -DgroupId=com.microsoft.example -DartifactId=WordCount -DinteractiveMode=false\n\n这会在当前位置创建名为 **WordCount** 的新目录，其中包含基本 Maven 项目。\n\n**WordCount** 目录将包含以下项：\n\n* **pom.xml**：包含 Maven 项目的设置。\n\n* **src\\\\main\\\\java\\\\com\\\\microsoft\\\\example**：包含应用程序代码。\n\n* **src\\\\test\\\\java\\\\com\\\\microsoft\\\\example**：包含应用程序的测试。对于本示例，我们将不创建测试。\n\n###删除示例代码\n\n由于我们要创建应用程序，因此请删除生成的测试和应用程序文件：\n\n*  **src\\\\test\\\\java\\\\com\\\\microsoft\\\\example\\\\AppTest.java**\n\n*  **src\\\\main\\\\java\\\\com\\\\microsoft\\\\example\\\\App.java**\n\n##添加依赖项\n\n由于这是一个 Storm 拓扑，因此你必须添加 Storm 组件的依赖项。打开 **pom.xml**，并在 **&lt;dependencies>** 节中添加以下代码：\n\n    <dependency>\n      <groupId>org.apache.storm</groupId>\n      <artifactId>storm-core</artifactId>\n      <version>0.9.2-incubating</version>\n      <!-- keep storm out of the jar-with-dependencies -->\n      <scope>provided</scope>\n    </dependency>\n\n在编译时，Maven 会使用此信息来查找 Maven 存储库中的 **storm-core**。它会先查找本地计算机上的存储库。如果文件不存在，它会从公共 Maven 存储库下载这些文件，并将其存储在本地存储库中。\n\n> [AZURE.NOTE] 请注意我们在该节中添加的 `<scope>provided</scope>` 行。这会告诉 Maven 从我们创建的任何 JAR 文件中排除 **storm-core**，因为系统将会予以提供。这样，便可以稍微减小所创建的包，并确保它们使用 Storm on HDInsight 群集中包含的 **storm-core** 位。\n\n##生成配置\n\nMaven 插件可让你自定义项目的生成阶段，例如，如何编译项目，或者如何将它打包成 JAR 文件。打开 **pom.xml**，并紧靠在 `</project>` 行的上方添加以下代码。\n\n    <build>\n      <plugins>\n      </plugins>\n    </build>\n\n此节将用来添加插件和其他生成配置选项。\n\n###添加插件\n\n针对 Storm 拓扑，<a href=\"http://mojo.codehaus.org/exec-maven-plugin/\" target=\"_blank\">Exec Maven 插件</a>十分有用，因为它可让你轻松地在开发环境本地运行拓扑。将以下内容添加至 **pom.xml** 文件的 `<plugins>` 节，以包括 Exec Maven 插件：\n\n    <plugin>\n      <groupId>org.codehaus.mojo</groupId>\n      <artifactId>exec-maven-plugin</artifactId>\n      <executions>\n        <execution>\n        <goals>\n          <goal>exec</goal>\n        </goals>\n        </execution>\n      </executions>\n      <configuration>\n        <executable>java</executable>\n        <includeProjectDependencies>true</includeProjectDependencies>\n        <includePluginDependencies>false</includePluginDependencies>\n        <classpathScope>compile</classpathScope>\n        <mainClass>${storm.topology}</mainClass>\n      </configuration>\n    </plugin>\n\n另一个有用的插件是用于更改编译选项的 <a href=\"http://maven.apache.org/plugins/maven-compiler-plugin/\" target=\"_blank\">Apache Maven Compiler 插件</a>。我们需要此插件的主要原因是要更改 Maven 用作应用程序源和目标的 Java 版本。我们需要的是版本 1.7。\n\n在 **pom.xml** 的 `<plugins>` 节中添加以下内容，以包括 Apache Maven Compiler 插件并将源和目标版本设置为 1.7。\n\n    <plugin>\n      <groupId>org.apache.maven.plugins</groupId>\n      <artifactId>maven-compiler-plugin</artifactId>\n      <configuration>\n        <source>1.7</source>\n        <target>1.7</target>\n      </configuration>\n    </plugin>\n\n##创建拓扑\n\n基于 Java 的 Storm 拓扑包含你必须编写（或引用）为依赖项的三个组件。\n\n* **Spout**：读取外部源中的数据，并发出进入拓扑的数据流。\n\n* **Bolt**：对 Spout 或其他 Bolt 所发出的数据流执行处理，并发出一个或多个数据流。\n\n* **拓扑**：定义如何排列 Spout 和 Bolt，并提供拓扑的入口点。\n\n###创建 Spout\n\n为了降低设置外部数据源的要求，以下 Spout 只会发出随机句子。它是 <a href=\"https://github.com/apache/storm/blob/master/examples/storm-starter/\" target=\"_blank\">Storm-Starter 示例</a>随附的 Spout 的修改版本。\n\n> [AZURE.NOTE] 有关从外部数据源读取的 Spout 的示例，请参阅以下示例：<a href=\"https://github.com/apache/storm/tree/master/external/storm-kafka\" target=\"_blank\">Storm-Kafka</a>：从 Kafka 读取数据的 Spout\n\n对于 Spout，在 **src\\\\main\\\\java\\\\com\\\\microsoft\\\\example** 目录中创建名为 **RandomSentenceSpout.java** 的新文件，并使用以下内容做为内容：\n\n    /**\n     * Licensed to the Apache Software Foundation (ASF) under one\n     * or more contributor license agreements.  See the NOTICE file\n     * distributed with this work for additional information\n     * regarding copyright ownership.  The ASF licenses this file\n     * to you under the Apache License, Version 2.0 (the\n     * \"License\"); you may not use this file except in compliance\n     * with the License.  You may obtain a copy of the License at\n     *\n     * http://www.apache.org/licenses/LICENSE-2.0\n     *\n     * Unless required by applicable law or agreed to in writing, software\n     * distributed under the License is distributed on an \"AS IS\" BASIS,\n     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n     * See the License for the specific language governing permissions and\n     * limitations under the License.\n     */\n\n     /**\n      * Original is available at https://github.com/apache/storm/blob/master/examples/storm-starter/src/jvm/storm/starter/spout/RandomSentenceSpout.java\n      */\n\n    package com.microsoft.example;\n\n    import backtype.storm.spout.SpoutOutputCollector;\n    import backtype.storm.task.TopologyContext;\n    import backtype.storm.topology.OutputFieldsDeclarer;\n    import backtype.storm.topology.base.BaseRichSpout;\n    import backtype.storm.tuple.Fields;\n    import backtype.storm.tuple.Values;\n    import backtype.storm.utils.Utils;\n\n    import java.util.Map;\n    import java.util.Random;\n\n    //This spout randomly emits sentences\n    public class RandomSentenceSpout extends BaseRichSpout {\n      //Collector used to emit output\n      SpoutOutputCollector _collector;\n      //Used to generate a random number\n      Random _rand;\n\n      //Open is called when an instance of the class is created\n      @Override\n      public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {\n      //Set the instance collector to the one passed in\n        _collector = collector;\n        //For randomness\n        _rand = new Random();\n      }\n\n      //Emit data to the stream\n      @Override\n      public void nextTuple() {\n      //Sleep for a bit\n        Utils.sleep(100);\n        //The sentences that will be randomly emitted\n        String[] sentences = new String[]{ \"the cow jumped over the moon\", \"an apple a day keeps the doctor away\",\n            \"four score and seven years ago\", \"snow white and the seven dwarfs\", \"i am at two with nature\" };\n        //Randomly pick a sentence\n        String sentence = sentences[_rand.nextInt(sentences.length)];\n        //Emit the sentence\n        _collector.emit(new Values(sentence));\n      }\n\n      //Ack is not implemented since this is a basic example\n      @Override\n      public void ack(Object id) {\n      }\n\n      //Fail is not implemented since this is a basic example\n      @Override\n      public void fail(Object id) {\n      }\n\n      //Declare the output fields. In this case, an sentence\n      @Override\n      public void declareOutputFields(OutputFieldsDeclarer declarer) {\n        declarer.declare(new Fields(\"sentence\"));\n      }\n    }\n\n请花费片刻时间通读代码注释，以了解此 Spout 的工作原理。\n\n> [AZURE.NOTE] 虽然此拓扑只使用一个 Spout，但其他拓扑可能存在将数据从不同源送入拓扑的多个 Spout。\n\n###创建 Bolt\n\nBolt 用于处理数据。此拓扑有两个 Bolt：\n\n* **SplitSentence**：将 **RandomSentenceSpout** 发出的句子分割成不同的单词。\n\n* **WordCount**：统计每个单词的出现次数。\n\n> [AZURE.NOTE] Bolt 几乎可以执行任何操作，例如，计算、保存，或者与外部组件通信。\n\n在 **src\\\\main\\\\java\\\\com\\\\microsoft\\\\example** 目录中创建两个新文件：**SplitSentence.java** 和 **WordCount.Java**。将以下内容用作这些文件的内容：\n\n**SplitSentence**\n\n    package com.microsoft.example;\n\n    import java.text.BreakIterator;\n\n    import backtype.storm.topology.BasicOutputCollector;\n    import backtype.storm.topology.OutputFieldsDeclarer;\n    import backtype.storm.topology.base.BaseBasicBolt;\n    import backtype.storm.tuple.Fields;\n    import backtype.storm.tuple.Tuple;\n    import backtype.storm.tuple.Values;\n\n    //There are a variety of bolt types. In this case, we use BaseBasicBolt\n    public class SplitSentence extends BaseBasicBolt {\n\n      //Execute is called to process tuples\n      @Override\n      public void execute(Tuple tuple, BasicOutputCollector collector) {\n        //Get the sentence content from the tuple\n        String sentence = tuple.getString(0);\n        //An iterator to get each word\n        BreakIterator boundary=BreakIterator.getWordInstance();\n        //Give the iterator the sentence\n        boundary.setText(sentence);\n        //Find the beginning first word\n        int start=boundary.first();\n        //Iterate over each word and emit it to the output stream\n        for (int end=boundary.next(); end != BreakIterator.DONE; start=end, end=boundary.next()) {\n          //get the word\n          String word=sentence.substring(start,end);\n          //If a word is whitespace characters, replace it with empty\n          word=word.replaceAll(\"\\\\s+\",\"\");\n          //if it's an actual word, emit it\n          if (!word.equals(\"\")) {\n            collector.emit(new Values(word));\n          }\n        }\n      }\n\n      //Declare that emitted tuples will contain a word field\n      @Override\n      public void declareOutputFields(OutputFieldsDeclarer declarer) {\n        declarer.declare(new Fields(\"word\"));\n      }\n    }\n\n**WordCount**\n\n    package com.microsoft.example;\n\n    import java.util.HashMap;\n    import java.util.Map;\n\n    import backtype.storm.topology.BasicOutputCollector;\n    import backtype.storm.topology.OutputFieldsDeclarer;\n    import backtype.storm.topology.base.BaseBasicBolt;\n    import backtype.storm.tuple.Fields;\n    import backtype.storm.tuple.Tuple;\n    import backtype.storm.tuple.Values;\n\n    //There are a variety of bolt types. In this case, we use BaseBasicBolt\n    public class WordCount extends BaseBasicBolt {\n      //For holding words and counts\n        Map<String, Integer> counts = new HashMap<String, Integer>();\n\n        //execute is called to process tuples\n        @Override\n        public void execute(Tuple tuple, BasicOutputCollector collector) {\n          //Get the word contents from the tuple\n          String word = tuple.getString(0);\n          //Have we counted any already?\n          Integer count = counts.get(word);\n          if (count == null)\n            count = 0;\n          //Increment the count and store it\n          count++;\n          counts.put(word, count);\n          //Emit the word and the current count\n          collector.emit(new Values(word, count));\n        }\n\n        //Declare that we will emit a tuple containing two fields; word and count\n        @Override\n        public void declareOutputFields(OutputFieldsDeclarer declarer) {\n          declarer.declare(new Fields(\"word\", \"count\"));\n        }\n      }\n\n请花费片刻时间通读代码注释，以了解每个 Bolt 的工作原理。\n\n###创建拓扑\n\n拓扑将 Spout 和 Bolt 一起绑定到图形，该图形定义了组件之间的数据流动方式。它还提供 Storm 在群集内创建组件的实例时使用的并行度提示。\n\n以下是此拓扑的组件的基本原理图。\n\n![显示 Spout 和 Bolt 排列方式的示意图](./media/hdinsight-storm-develop-java-topology/wordcount-topology.png)\n\n若要实现该拓扑，请在 **src\\\\main\\\\java\\\\com\\\\microsoft\\\\example** 目录中创建名为 **WordCountTopology.java** 的新文件。将以下内容用作该文件的内容：\n\n    package com.microsoft.example;\n\n    import backtype.storm.Config;\n    import backtype.storm.LocalCluster;\n    import backtype.storm.StormSubmitter;\n    import backtype.storm.topology.TopologyBuilder;\n    import backtype.storm.tuple.Fields;\n\n    import com.microsoft.example.RandomSentenceSpout;\n\n    public class WordCountTopology {\n\n      //Entry point for the topology\n      public static void main(String[] args) throws Exception {\n      //Used to build the topology\n        TopologyBuilder builder = new TopologyBuilder();\n        //Add the spout, with a name of 'spout'\n        //and parallelism hint of 5 executors\n        builder.setSpout(\"spout\", new RandomSentenceSpout(), 5);\n        //Add the SplitSentence bolt, with a name of 'split'\n        //and parallelism hint of 8 executors\n        //shufflegrouping subscribes to the spout, and equally distributes\n        //tuples (sentences) across instances of the SplitSentence bolt\n        builder.setBolt(\"split\", new SplitSentence(), 8).shuffleGrouping(\"spout\");\n        //Add the counter, with a name of 'count'\n        //and parallelism hint of 12 executors\n        //fieldsgrouping subscribes to the split bolt, and\n        //ensures that the same word is sent to the same instance (group by field 'word')\n        builder.setBolt(\"count\", new WordCount(), 12).fieldsGrouping(\"split\", new Fields(\"word\"));\n\n        //new configuration\n        Config conf = new Config();\n        conf.setDebug(true);\n\n        //If there are arguments, we are running on a cluster\n        if (args != null && args.length > 0) {\n          //parallelism hint to set the number of workers\n          conf.setNumWorkers(3);\n          //submit the topology\n          StormSubmitter.submitTopology(args[0], conf, builder.createTopology());\n        }\n        //Otherwise, we are running locally\n        else {\n          //Cap the maximum number of executors that can be spawned\n          //for a component to 3\n          conf.setMaxTaskParallelism(3);\n          //LocalCluster is used to run locally\n          LocalCluster cluster = new LocalCluster();\n          //submit the topology\n          cluster.submitTopology(\"word-count\", conf, builder.createTopology());\n          //sleep\n          Thread.sleep(10000);\n          //shut down the cluster\n          cluster.shutdown();\n        }\n      }\n    }\n\n请花片刻时间通读代码注释以了解拓扑的定义方式，然后将拓扑提交到群集。\n\n##在本地测试拓扑\n\n保存文件之后，请使用以下命令在本地测试拓扑。\n\n    mvn compile exec:java -Dstorm.topology=com.microsoft.example.WordCountTopology\n\n运行该命令时，拓扑会显示启动信息。然后开始显示与下面类似的行，因为句子是从 Spout 发出，然后由 Bolt 处理的。\n\n    15398 [Thread-16-split] INFO  backtype.storm.daemon.executor - Processing received message source: spout:10, stream: default, id: {}, [an apple a day keeps thedoctor away]]\n    15398 [Thread-16-split] INFO  backtype.storm.daemon.task - Emitting: split default [an]\n    15399 [Thread-10-count] INFO  backtype.storm.daemon.executor - Processing received message source: split:6, stream: default, id: {}, [an]\n    15399 [Thread-16-split] INFO  backtype.storm.daemon.task - Emitting: split default [apple]\n    15400 [Thread-8-count] INFO  backtype.storm.daemon.executor - Processing received message source: split:6, stream: default, id: {}, [apple]\n    15400 [Thread-16-split] INFO  backtype.storm.daemon.task - Emitting: split default [a]\n    15399 [Thread-10-count] INFO  backtype.storm.daemon.task - Emitting: count default [an, 53]\n    15400 [Thread-12-count] INFO  backtype.storm.daemon.executor - Processing received message source: split:6, stream: default, id: {}, [a]\n    15400 [Thread-16-split] INFO  backtype.storm.daemon.task - Emitting: split default [day]\n    15400 [Thread-8-count] INFO  backtype.storm.daemon.task - Emitting: count default [apple, 53]\n    15401 [Thread-10-count] INFO  backtype.storm.daemon.executor - Processing received message source: split:6, stream: default, id: {}, [day]\n    15401 [Thread-16-split] INFO  backtype.storm.daemon.task - Emitting: split default [keeps]\n    15401 [Thread-12-count] INFO  backtype.storm.daemon.task - Emitting: count default [a, 53]\n\n从此输出中可以看到发生了以下情况：\n\n1. Spout 发出“an apple a day keeps the doctor away”。\n\n2. Split Bolt 开始发出句子中的各个单词。\n\n3. Count Bolt 开始发出每个单词及其发出次数。\n\n查看 Count Bolt 所发出的数据，“apple”已发出 53 次。只要拓扑运行，计数就会持续增加，因为系统会随机反复发出相同的句子，并且永不会重置计数。\n\n##Trident\n\nTrident 是 Storm 提供的高级抽象。它支持有状态处理。Trident 的主要优点在于，它可以保证进入拓扑的每个消息只会处理一次。这在保证消息至少处理一次的原始 Java 拓扑中很难实现。两者还有其他方面的差异，例如，可以使用内置组件，而无需创建 Bolt。事实上，可以使用低泛型组件（例如筛选、投影和函数）来完全取代 Bolt。\n\n你可以使用 Maven 项目来创建 Trident 应用程序。使用本文前面所述的相同基本步骤 - 只有代码不同。\n\n有关 Trident 的详细信息，请参阅 <a href=\"http://storm.apache.org/documentation/Trident-API-Overview.html\" target=\"_blank\">Trident API 概述</a>。\n\n##后续步骤\n\n你已学习如何使用 Java 创建 Storm 拓扑。接下来，请学习如何：\n\n* [在 HDInsight 上部署和管理 Apache Storm 拓扑](/documentation/articles/hdinsight-storm-deploy-monitor-topology)\n\n* [使用 Visual Studio 开发 Apache Storm on HDInsight 的 C# 拓扑](/documentation/articles/hdinsight-storm-develop-csharp-visual-studio-topology)\n\n如需更多 Storm 拓扑示例，请访问 [Storm on HDInsight 拓扑示例](/documentation/articles/hdinsight-storm-example-topology)。\n\n<!---HONumber=Mooncake_0307_2016-->"
}