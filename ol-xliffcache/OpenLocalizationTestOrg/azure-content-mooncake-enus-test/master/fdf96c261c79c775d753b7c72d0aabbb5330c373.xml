{
  "nodes": [
    {
      "content": "在 HDInsight 中将 Hadoop Hive 与远程桌面配合使用 | Azure",
      "pos": [
        26,
        70
      ]
    },
    {
      "content": "学习如何通过使用远程桌面连接到 HDInsight 中的 Hadoop 群集，然后通过使用 Hive 命令行界面运行 Hive 查询。",
      "pos": [
        88,
        155
      ]
    },
    {
      "content": "通过远程桌面将 Hive 与 HDInsight 上的 Hadoop 配合使用",
      "pos": [
        389,
        428
      ]
    },
    {
      "content": "在本文中，你将学习如何通过使用远程桌面连接到 HDInsight 群集，然后通过使用 Hive 命令行界面 (CLI) 运行 Hive 查询。",
      "pos": [
        507,
        578
      ]
    },
    {
      "pos": [
        582,
        728
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>本文档未详细描述示例中使用的 HiveQL 语句的作用。有关此示例中使用的 HiveQL 的详细信息，请参阅<bpt id=\"p1\">[</bpt>将 Hive 与 HDInsight 上的 Hadoop 配合使用<ept id=\"p1\">](/documentation/articles/hdinsight-use-hive)</ept>。"
    },
    {
      "pos": [
        732,
        755
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"prereq\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>先决条件"
    },
    {
      "content": "若要完成本文中的步骤，你将需要：",
      "pos": [
        757,
        773
      ]
    },
    {
      "content": "基于 Windows 的 HDInsight（HDInsight 上的 Hadoop）群集",
      "pos": [
        777,
        822
      ]
    },
    {
      "content": "运行 Windows 10、Window 8 或 Windows 7 的客户端计算机",
      "pos": [
        826,
        868
      ]
    },
    {
      "pos": [
        872,
        902
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"connect\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>使用远程桌面进行连接"
    },
    {
      "pos": [
        904,
        1040
      ],
      "content": "为 HDInsight 群集启用远程桌面，然后根据<bpt id=\"p1\">[</bpt>使用 RDP 连接到 HDInsight 群集<ept id=\"p1\">](/documentation/articles/hdinsight-administer-use-management-portal-v1#rdp)</ept>中的说明连接到该群集。"
    },
    {
      "pos": [
        1044,
        1071
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"hive\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>使用 Hive 命令"
    },
    {
      "content": "连接到 HDInsight 群集的桌面之后，请执行以下步骤来使用 Hive：",
      "pos": [
        1073,
        1111
      ]
    },
    {
      "content": "从 HDInsight 桌面启动“Hadoop 命令行”。",
      "pos": [
        1116,
        1145
      ]
    },
    {
      "content": "输入以下命令启动 Hive CLI：",
      "pos": [
        1150,
        1168
      ]
    },
    {
      "pos": [
        1204,
        1241
      ],
      "content": "在启动 CLI 后，你将会看到 Hive CLI 提示符：<ph id=\"ph1\">`hive&gt;`</ph>。"
    },
    {
      "pos": [
        1246,
        1290
      ],
      "content": "在 CLI 中输入以下语句，以使用示例数据创建名为 <bpt id=\"p1\">**</bpt>log4jLogs<ept id=\"p1\">**</ept> 的新表："
    },
    {
      "content": "这些语句将执行以下操作：",
      "pos": [
        1688,
        1700
      ]
    },
    {
      "pos": [
        1708,
        1741
      ],
      "content": "<bpt id=\"p1\">**</bpt>DROP TABLE<ept id=\"p1\">**</ept>：删除表和数据文件（如果该表已存在）。"
    },
    {
      "pos": [
        1749,
        1822
      ],
      "content": "<bpt id=\"p1\">**</bpt>CREATE EXTERNAL TABLE<ept id=\"p1\">**</ept>：在 Hive 中创建新的“外部”表。外部表仅在 Hive 中存储表定义；数据会保留在原始位置。"
    },
    {
      "pos": [
        1834,
        1927
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>当你预期以外部源更新基础数据（例如自动化数据上载过程），或以其他 MapReduce 操作更新基础数据，但希望 Hive 查询始终使用最新数据时，必须使用外部表。"
    },
    {
      "content": "删除外部表<bpt id=\"p1\">**</bpt>不会<ept id=\"p1\">**</ept>删除数据，只会删除表定义。",
      "pos": [
        1941,
        1965
      ]
    },
    {
      "pos": [
        1973,
        2026
      ],
      "content": "<bpt id=\"p1\">**</bpt>ROW FORMAT<ept id=\"p1\">**</ept>：告知 Hive 如何设置数据的格式。在此情况下，每个日志中的字段以空格分隔。"
    },
    {
      "pos": [
        2034,
        2111
      ],
      "content": "<bpt id=\"p1\">**</bpt>STORED AS TEXTFILE LOCATION<ept id=\"p1\">**</ept>：让 Hive 知道数据的存储位置（example/data 目录），并且数据已存储为文本。"
    },
    {
      "pos": [
        2119,
        2192
      ],
      "content": "<bpt id=\"p1\">**</bpt>SELECT<ept id=\"p1\">**</ept> - 选择第 <bpt id=\"p2\">**</bpt>t4<ept id=\"p2\">**</ept> 列包含值 <bpt id=\"p3\">**</bpt>[ERROR]<ept id=\"p3\">**</ept> 的所有行的计数。这应会返回值 <bpt id=\"p4\">**</bpt>3<ept id=\"p4\">**</ept>，因为有三个行包含此值。"
    },
    {
      "pos": [
        2200,
        2329
      ],
      "content": "<bpt id=\"p1\">**</bpt>INPUT\\_\\_FILE\\_\\_NAME LIKE '%.log'<ept id=\"p1\">**</ept> - 告诉 Hive，我们只应返回以 .log 结尾的文件中的数据。此项将搜索限定于包含数据的 sample.log 文件，使搜索不会返回与所定义架构不符的其他示例数据文件中的数据。"
    },
    {
      "pos": [
        2335,
        2368
      ],
      "content": "使用以下语句创建名为 <bpt id=\"p1\">**</bpt>errorLogs<ept id=\"p1\">**</ept> 的新“内部”表："
    },
    {
      "content": "这些语句将执行以下操作：",
      "pos": [
        2660,
        2672
      ]
    },
    {
      "pos": [
        2680,
        2787
      ],
      "content": "<bpt id=\"p1\">**</bpt>CREATE TABLE IF NOT EXISTS<ept id=\"p1\">**</ept>：创建表（如果该表尚不存在）。由于未使用 <bpt id=\"p2\">**</bpt>EXTERNAL<ept id=\"p2\">**</ept> 关键字，因此这是一个内部表，它存储在 Hive 数据仓库中并完全受 Hive 的管理。"
    },
    {
      "pos": [
        2799,
        2845
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>与 <bpt id=\"p1\">**</bpt>EXTERNAL<ept id=\"p1\">**</ept> 表不同，删除内部表会同时删除基础数据。"
    },
    {
      "pos": [
        2853,
        2915
      ],
      "content": "<bpt id=\"p1\">**</bpt>STORED AS ORC<ept id=\"p1\">**</ept>：以优化行纵栏表 (ORC) 格式存储数据。这是高度优化且有效的 Hive 数据存储格式。"
    },
    {
      "pos": [
        2923,
        3017
      ],
      "content": "<bpt id=\"p1\">**</bpt>INSERT OVERWRITE ...SELECT<ept id=\"p1\">**</ept>：从包含 <bpt id=\"p2\">**</bpt>[ERROR]<ept id=\"p2\">**</ept> 的 <bpt id=\"p3\">**</bpt>log4jLogs<ept id=\"p3\">**</ept> 表中选择行，然后将数据插入 <bpt id=\"p4\">**</bpt>errorLogs<ept id=\"p4\">**</ept> 表中。"
    },
    {
      "pos": [
        3023,
        3105
      ],
      "content": "若要验证是否只将第 t4 列中包含 <bpt id=\"p1\">**</bpt>[ERROR]<ept id=\"p1\">**</ept> 的行存储到了 <bpt id=\"p2\">**</bpt>errorLogs<ept id=\"p2\">**</ept> 表，请使用以下语句从 <bpt id=\"p3\">**</bpt>errorLogs<ept id=\"p3\">**</ept> 返回所有行："
    },
    {
      "pos": [
        3145,
        3179
      ],
      "content": "应返回三行数据，所有行都包含列 t4 中的 <bpt id=\"p1\">**</bpt>[ERROR]<ept id=\"p1\">**</ept>。"
    },
    {
      "pos": [
        3183,
        3205
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"summary\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>摘要"
    },
    {
      "content": "如你所见，Hive 命令提供了简单的方法让你以交互方式在 HDInsight 群集上运行 Hive 查询、监视作业状态，以及检索输出。",
      "pos": [
        3207,
        3274
      ]
    },
    {
      "pos": [
        3278,
        3304
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"nextsteps\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>后续步骤"
    },
    {
      "content": "有关 HDInsight 中的 Hive 的一般信息：",
      "pos": [
        3306,
        3333
      ]
    },
    {
      "content": "将 Hive 与 HDInsight 上的 Hadoop 配合使用",
      "pos": [
        3338,
        3371
      ]
    },
    {
      "content": "有关 HDInsight 上的 Hadoop 的其他使用方法的信息：",
      "pos": [
        3418,
        3452
      ]
    },
    {
      "content": "将 Pig 与 HDInsight 上的 Hadoop 配合使用",
      "pos": [
        3457,
        3489
      ]
    },
    {
      "content": "将 MapReduce 与 HDInsight 上的 Hadoop 配合使用",
      "pos": [
        3538,
        3576
      ]
    }
  ],
  "content": "<properties\n   pageTitle=\"在 HDInsight 中将 Hadoop Hive 与远程桌面配合使用 | Azure\"\n   description=\"学习如何通过使用远程桌面连接到 HDInsight 中的 Hadoop 群集，然后通过使用 Hive 命令行界面运行 Hive 查询。\"\n   services=\"hdinsight\"\n   documentationCenter=\"\"\n   authors=\"Blackmist\"\n   manager=\"paulettm\"\n   editor=\"cgronlun\"\n   tags=\"azure-portal\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.date=\"12/04/2015\"\n    wacn.date=\"01/14/2016\"/>\n\n# 通过远程桌面将 Hive 与 HDInsight 上的 Hadoop 配合使用\n\n[AZURE.INCLUDE [hive-selector](../includes/hdinsight-selector-use-hive.md)]\n\n在本文中，你将学习如何通过使用远程桌面连接到 HDInsight 群集，然后通过使用 Hive 命令行界面 (CLI) 运行 Hive 查询。\n\n> [AZURE.NOTE]本文档未详细描述示例中使用的 HiveQL 语句的作用。有关此示例中使用的 HiveQL 的详细信息，请参阅[将 Hive 与 HDInsight 上的 Hadoop 配合使用](/documentation/articles/hdinsight-use-hive)。\n\n##<a id=\"prereq\"></a>先决条件\n\n若要完成本文中的步骤，你将需要：\n\n* 基于 Windows 的 HDInsight（HDInsight 上的 Hadoop）群集\n\n* 运行 Windows 10、Window 8 或 Windows 7 的客户端计算机\n\n##<a id=\"connect\"></a>使用远程桌面进行连接\n\n为 HDInsight 群集启用远程桌面，然后根据[使用 RDP 连接到 HDInsight 群集](/documentation/articles/hdinsight-administer-use-management-portal-v1#rdp)中的说明连接到该群集。\n\n##<a id=\"hive\"></a>使用 Hive 命令\n\n连接到 HDInsight 群集的桌面之后，请执行以下步骤来使用 Hive：\n\n1. 从 HDInsight 桌面启动“Hadoop 命令行”。\n\n2. 输入以下命令启动 Hive CLI：\n\n        %hive_home%\\bin\\hive\n\n    在启动 CLI 后，你将会看到 Hive CLI 提示符：`hive>`。\n\n3. 在 CLI 中输入以下语句，以使用示例数据创建名为 **log4jLogs** 的新表：\n\n        DROP TABLE log4jLogs;\n        CREATE EXTERNAL TABLE log4jLogs (t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string)\n        ROW FORMAT DELIMITED FIELDS TERMINATED BY ' '\n        STORED AS TEXTFILE LOCATION 'wasb:///example/data/';\n        SELECT t4 AS sev, COUNT(*) AS count FROM log4jLogs WHERE t4 = '[ERROR]' AND INPUT__FILE__NAME LIKE '%.log' GROUP BY t4;\n\n    这些语句将执行以下操作：\n\n    * **DROP TABLE**：删除表和数据文件（如果该表已存在）。\n\n    * **CREATE EXTERNAL TABLE**：在 Hive 中创建新的“外部”表。外部表仅在 Hive 中存储表定义；数据会保留在原始位置。\n\n        > [AZURE.NOTE]当你预期以外部源更新基础数据（例如自动化数据上载过程），或以其他 MapReduce 操作更新基础数据，但希望 Hive 查询始终使用最新数据时，必须使用外部表。\n        > <p>删除外部表**不会**删除数据，只会删除表定义。\n\n    * **ROW FORMAT**：告知 Hive 如何设置数据的格式。在此情况下，每个日志中的字段以空格分隔。\n\n    * **STORED AS TEXTFILE LOCATION**：让 Hive 知道数据的存储位置（example/data 目录），并且数据已存储为文本。\n\n    * **SELECT** - 选择第 **t4** 列包含值 **[ERROR]** 的所有行的计数。这应会返回值 **3**，因为有三个行包含此值。\n\n    * **INPUT\\_\\_FILE\\_\\_NAME LIKE '%.log'** - 告诉 Hive，我们只应返回以 .log 结尾的文件中的数据。此项将搜索限定于包含数据的 sample.log 文件，使搜索不会返回与所定义架构不符的其他示例数据文件中的数据。\n\n\n4. 使用以下语句创建名为 **errorLogs** 的新“内部”表：\n\n        CREATE TABLE IF NOT EXISTS errorLogs (t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string) STORED AS ORC;\n        INSERT OVERWRITE TABLE errorLogs SELECT t1, t2, t3, t4, t5, t6, t7 FROM log4jLogs WHERE t4 = '[ERROR]' AND INPUT__FILE__NAME LIKE '%.log';\n\n    这些语句将执行以下操作：\n\n    * **CREATE TABLE IF NOT EXISTS**：创建表（如果该表尚不存在）。由于未使用 **EXTERNAL** 关键字，因此这是一个内部表，它存储在 Hive 数据仓库中并完全受 Hive 的管理。\n\n        > [AZURE.NOTE]与 **EXTERNAL** 表不同，删除内部表会同时删除基础数据。\n\n    * **STORED AS ORC**：以优化行纵栏表 (ORC) 格式存储数据。这是高度优化且有效的 Hive 数据存储格式。\n\n    * **INSERT OVERWRITE ...SELECT**：从包含 **[ERROR]** 的 **log4jLogs** 表中选择行，然后将数据插入 **errorLogs** 表中。\n\n    若要验证是否只将第 t4 列中包含 **[ERROR]** 的行存储到了 **errorLogs** 表，请使用以下语句从 **errorLogs** 返回所有行：\n\n        SELECT * from errorLogs;\n\n    应返回三行数据，所有行都包含列 t4 中的 **[ERROR]**。\n\n##<a id=\"summary\"></a>摘要\n\n如你所见，Hive 命令提供了简单的方法让你以交互方式在 HDInsight 群集上运行 Hive 查询、监视作业状态，以及检索输出。\n\n##<a id=\"nextsteps\"></a>后续步骤\n\n有关 HDInsight 中的 Hive 的一般信息：\n\n* [将 Hive 与 HDInsight 上的 Hadoop 配合使用](/documentation/articles/hdinsight-use-hive)\n\n有关 HDInsight 上的 Hadoop 的其他使用方法的信息：\n\n* [将 Pig 与 HDInsight 上的 Hadoop 配合使用](/documentation/articles/hdinsight-use-pig)\n\n* [将 MapReduce 与 HDInsight 上的 Hadoop 配合使用](/documentation/articles/hdinsight-use-mapreduce)\n\n\n[1]: /documentation/articles/hdinsight-hadoop-visual-studio-tools-get-started\n[hdinsight-sdk-documentation]: http://msdnstage.redmond.corp.microsoft.com/zh-cn/library/dn479185.aspx\n\n[azure-purchase-options]: /pricing/overview/\n[azure-member-offers]: /pricing/member-offers/\n[azure-trial]: /pricing/1rmb-trial/\n\n[apache-tez]: http://tez.apache.org\n[apache-hive]: http://hive.apache.org/\n[apache-log4j]: http://zh.wikipedia.org/wiki/Log4j\n[hive-on-tez-wiki]: https://cwiki.apache.org/confluence/display/Hive/Hive+on+Tez\n[import-to-excel]: /documentation/articles/hdinsight-connect-excel-power-query/\n\n\n[hdinsight-use-oozie]: /documentation/articles/hdinsight-use-oozie\n[hdinsight-analyze-flight-data]: /documentation/articles/hdinsight-analyze-flight-delay-data\n[hdinsight-storage]: /documentation/articles/hdinsight-use-blob-storage\n[hdinsight-provision]: /documentation/articles/hdinsight-provision-clusters-v1\n[hdinsight-submit-jobs]: /documentation/articles/hdinsight-submit-hadoop-jobs-programmatically\n[hdinsight-upload-data]: /documentation/articles/hdinsight-upload-data\n[hdinsight-get-started]: /documentation/articles/hdinsight-get-started\n[Powershell-install-configure]: /documentation/articles/powershell-install-configure\n[powershell-here-strings]: http://technet.microsoft.com/zh-cn/library/ee692792.aspx\n\n[image-hdi-hive-powershell]: ./media/hdinsight-use-hive/HDI.HIVE.PowerShell.png\n[img-hdi-hive-powershell-output]: ./media/hdinsight-use-hive/HDI.Hive.PowerShell.Output.png\n[image-hdi-hive-architecture]: ./media/hdinsight-use-hive/HDI.Hive.Architecture.png\n\n<!---HONumber=79-->"
}