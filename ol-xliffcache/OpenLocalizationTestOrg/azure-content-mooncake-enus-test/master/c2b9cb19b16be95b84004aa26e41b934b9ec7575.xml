{
  "nodes": [
    {
      "content": "使用 HDInsight 中的 Hive 分析和处理 JSON 文档 | Azure",
      "pos": [
        26,
        68
      ]
    },
    {
      "content": "了解如何使用 JSON 文档，以及如何使用 HDInsight 中的 Hive 来分析这些文档。",
      "pos": [
        86,
        134
      ]
    },
    {
      "content": "使用 HDInsight 中的 Hive 处理和分析 JSON 文档",
      "pos": [
        340,
        374
      ]
    },
    {
      "content": "了解如何使用 HDInsight 中的 Hive 处理和分析 JSON 文件。本教程将使用以下 JSON 文档",
      "pos": [
        376,
        431
      ]
    },
    {
      "pos": [
        1461,
        1707
      ],
      "content": "可以在 wasb://processjson@hditutorialdata.blob.core.windows.net/ 上找到该文件。有关将 Azure Blob 存储与 HDInsight 配合使用的详细信息，请参阅<bpt id=\"p1\">[</bpt>将 HDFS 兼容的 Azure Blob 存储与 HDInsight 中的 Hadoop 配合使用<ept id=\"p1\">](/documentation/articles/hdinsight-hadoop-use-blob-storage)</ept>。如果需要，你可以将该文件复制到群集的默认容器。"
    },
    {
      "pos": [
        1709,
        1857
      ],
      "content": "在本教程中，你将使用 Hive 控制台。有关打开 Hive 控制台的说明，请参阅<bpt id=\"p1\">[</bpt>通过远程桌面将 Hive 与 HDInsight 上的 Hadoop 配合使用<ept id=\"p1\">](/documentation/articles/hdinsight-hadoop-use-hive-remote-desktop)</ept>。"
    },
    {
      "content": "平展 JSON 文档",
      "pos": [
        1861,
        1871
      ]
    },
    {
      "content": "下一部分中所列的方法需要 JSON 文档在单一行中。因此，你必须将 JSON 文档平展成字符串。如果 JSON 文档已平展，则你可以跳过此步骤，直接转到有关分析 JSON 数据的下一部分。",
      "pos": [
        1873,
        1967
      ]
    },
    {
      "pos": [
        2684,
        2797
      ],
      "content": "原始 JSON 文件位于 <bpt id=\"p1\">**</bpt>wasb://processjson@hditutorialdata.blob.core.windows.net/<ept id=\"p1\">**</ept>。 <bpt id=\"p2\">*</bpt>StudentsRaw<ept id=\"p2\">*</ept> Hive 表指向原始的未平展 JSON 文档。"
    },
    {
      "pos": [
        2799,
        2871
      ],
      "content": "<bpt id=\"p1\">*</bpt>StudentsOneLine<ept id=\"p1\">*</ept> Hive 表将数据存储在 HDInsight 默认文件系统中的 <bpt id=\"p2\">*</bpt>/json/students/<ept id=\"p2\">*</ept> 路径下。"
    },
    {
      "content": "INSERT 语句在 StudentOneLine 表中填充平展的 JSON 数据。",
      "pos": [
        2873,
        2915
      ]
    },
    {
      "content": "SELECT 语句应只返回 1 行。",
      "pos": [
        2917,
        2935
      ]
    },
    {
      "content": "下面是 SELECT 语句的输出：",
      "pos": [
        2937,
        2954
      ]
    },
    {
      "content": "平展 JSON 文档。",
      "pos": [
        2958,
        2969
      ]
    },
    {
      "content": "在 Hive 中分析 JSON 文档",
      "pos": [
        3002,
        3020
      ]
    },
    {
      "content": "Hive 提供了三种不同的机制用于对 JSON 文档运行查询：",
      "pos": [
        3022,
        3053
      ]
    },
    {
      "content": "使用 GET\\_JSON\\_OBJECT UDF（用户定义的函数）",
      "pos": [
        3057,
        3090
      ]
    },
    {
      "content": "使用 JSON\\_TUPLE UDF",
      "pos": [
        3093,
        3111
      ]
    },
    {
      "content": "使用自定义 SerDe",
      "pos": [
        3114,
        3125
      ]
    },
    {
      "pos": [
        3128,
        3208
      ],
      "content": "使用 Python 或其他语言编写你自己的 UDF。请参阅<bpt id=\"p1\">[</bpt>此文<ept id=\"p1\">][hdinsight-python]</ept>，了解如何使用 Hive 运行自己的 Python 代码。"
    },
    {
      "content": "使用 GET\\_JSON\\_OBJECT UDF",
      "pos": [
        3215,
        3239
      ]
    },
    {
      "pos": [
        3240,
        3477
      ],
      "content": "Hive 提供了名为 <bpt id=\"p1\">[</bpt>get\\_json\\_object<ept id=\"p1\">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object)</ept> 的内置 UDF，它可以在运行时执行 JSON 查询。此方法采用两个参数 – 表名称和方法名称，具有平展的 JSON 文档和需要进行分析的 JSON 字段。让我们来探讨一个示例，以了解此 UDF 的工作原理。"
    },
    {
      "content": "获取每个学生的名字和姓氏",
      "pos": [
        3479,
        3491
      ]
    },
    {
      "content": "这是在控制台窗口中运行此查询时的输出。",
      "pos": [
        3690,
        3709
      ]
    },
    {
      "content": "get\\_json\\_object UDF",
      "pos": [
        3713,
        3734
      ]
    },
    {
      "content": "get-json\\_object UDF 有一些限制。",
      "pos": [
        3771,
        3798
      ]
    },
    {
      "content": "由于查询中的每个字段都需要重新分析查询，因此会影响性能。",
      "pos": [
        3802,
        3830
      ]
    },
    {
      "content": "GET\\_JSON\\_OBJECT() 返回数组的字符串表示形式。若要将其转换为 Hive 数组，你必须使用正则表达式来替换方括号“[”和“]”，然后调用拆分来获取数组。",
      "pos": [
        3833,
        3918
      ]
    },
    {
      "content": "正因如此，Hive wiki 建议使用 json\\_tuple。",
      "pos": [
        3921,
        3953
      ]
    },
    {
      "content": "使用 JSON\\_TUPLE UDF",
      "pos": [
        3959,
        3977
      ]
    },
    {
      "pos": [
        3979,
        4304
      ],
      "content": "Hive 提供的另一个 UDF 称为 <bpt id=\"p1\">[</bpt>json\\_tuple<ept id=\"p1\">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-json_tuple)</ept>，其性能比 <bpt id=\"p2\">[</bpt>get\\_ json \\_object<ept id=\"p2\">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object)</ept> 要高。此方法采用一组键和一个 JSON 字符串，并使用一个函数返回值的元组。以下查询将从 JSON 文档返回学生 ID 和年级："
    },
    {
      "content": "此脚本在 Hive 控制台中的输出：",
      "pos": [
        4470,
        4488
      ]
    },
    {
      "content": "json\\_tuple UDF",
      "pos": [
        4492,
        4507
      ]
    },
    {
      "pos": [
        4540,
        4748
      ],
      "content": "JSON\\_TUPLE 在 Hive 中使用了<bpt id=\"p1\">[</bpt>横向视图<ept id=\"p1\">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView)</ept>语法，使 json\\_tuple 能够通过将 UDT 函数应用于原始表的每一行来创建虚拟表。由于重复使用横向视图，复杂的 JSON 会变得过于庞大。此外，JSON_TUPLE 无法处理嵌套的 JSONs。"
    },
    {
      "content": "使用自定义 SerDe",
      "pos": [
        4754,
        4765
      ]
    },
    {
      "pos": [
        4767,
        4887
      ],
      "content": "SerDe 是用于分析嵌套 JSON 文档的最佳选择，它可让你定义 JSON 架构，并使用该架构来分析文档。在本教程中，你将使用其中 <bpt id=\"p1\">[</bpt>rcongiu<ept id=\"p1\">](https://github.com/rcongiu)</ept> 开发的热门 SerDe 之一。"
    },
    {
      "content": "使用自定义 SerDe：",
      "pos": [
        4891,
        4903
      ]
    },
    {
      "pos": [
        4910,
        5118
      ],
      "content": "安装 <bpt id=\"p1\">[</bpt>Java SE 开发工具包 7u55 JDK 1.7.0_55<ept id=\"p1\">](http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html#jdk-7u55-oth-JPR)</ept>。如果你要使用 HDInsight 的 Windows 部署，请选择 Windows X64 版本的 JDK。"
    },
    {
      "pos": [
        5125,
        5160
      ],
      "content": "<ph id=\"ph1\">[AZURE.WARNING]</ph>JDK 1.8 不适用于此 SerDe。"
    },
    {
      "content": "安装完成之后，请添加新的用户环境变量：",
      "pos": [
        5166,
        5185
      ]
    },
    {
      "content": "从 Windows 屏幕打开“查看高级系统设置”。",
      "pos": [
        5194,
        5219
      ]
    },
    {
      "content": "单击“环境变量”。",
      "pos": [
        5227,
        5236
      ]
    },
    {
      "pos": [
        5246,
        5327
      ],
      "content": "添加指向 <bpt id=\"p1\">**</bpt>C:\\\\Program Files\\\\Java\\\\jdk1.7.0\\_55<ept id=\"p1\">**</ept> 或任何 JDK 安装位置的新 <bpt id=\"p2\">**</bpt>JAVA_HOME<ept id=\"p2\">**</ept> 环境变量。"
    },
    {
      "content": "为 JDK 设置正确的配置值",
      "pos": [
        5335,
        5349
      ]
    },
    {
      "pos": [
        5379,
        5491
      ],
      "content": "安装 <bpt id=\"p1\">[</bpt>Maven 3.3.1<ept id=\"p1\">](http://mirror.olnevhost.net/pub/apache/maven/maven-3/3.3.1/binaries/apache-maven-3.3.1-bin.zip)</ept>"
    },
    {
      "content": "转到“控件面板”-&gt;“编辑系统变量”（对应于你帐户的环境变量），将 bin 文件夹添加到你的路径。以下屏幕截图显示了如何执行此操作。",
      "pos": [
        5497,
        5563
      ]
    },
    {
      "content": "设置 Maven",
      "pos": [
        5571,
        5579
      ]
    },
    {
      "pos": [
        5611,
        5739
      ],
      "content": "从 <bpt id=\"p1\">[</bpt>Hive-JSON-SerDe<ept id=\"p1\">](https://github.com/sheetaldolas/Hive-JSON-Serde/tree/master)</ept> github 站点克隆项目。可以通过按以下屏幕截图中所示单击“下载 Zip”按钮来实现此目的。"
    },
    {
      "content": "克隆项目",
      "pos": [
        5747,
        5751
      ]
    },
    {
      "content": "4：转到此包下载到的文件夹，然后键入“mvn package”。这应会创建必要的 jar 文件，然后你可以将其复制到群集。",
      "pos": [
        5780,
        5841
      ]
    },
    {
      "content": "5：转到根文件夹下存放所下载包的目标文件夹。将 json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar 文件上载到群集的头节点。我通常会将它放在 hive bin 文件夹下：C:\\\\apps\\\\dist\\\\hive-0.13.0.2.1.11.0-2316\\\\bin 或类似的文件夹。",
      "pos": [
        5843,
        6009
      ]
    },
    {
      "content": "6：在 hive 提示符下，键入“add jar /path/to/json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar”。由于在我的示例中，jar 在 C:\\\\apps\\\\dist\\\\hive-0.13.x\\\\bin 文件夹中，因此我可以直接添加名称如下的 jar：",
      "pos": [
        6012,
        6171
      ]
    },
    {
      "content": "现在，你可以使用 SerDe 对 JSON 文档运行查询。",
      "pos": [
        6301,
        6330
      ]
    },
    {
      "content": "以下语句将创建使用所定义架构的表",
      "pos": [
        6332,
        6348
      ]
    },
    {
      "content": "列出学生的名字和姓氏",
      "pos": [
        6910,
        6920
      ]
    },
    {
      "content": "下面是 Hive 控制台输出的结果。",
      "pos": [
        7001,
        7019
      ]
    },
    {
      "content": "SerDe 查询 1",
      "pos": [
        7023,
        7033
      ]
    },
    {
      "content": "计算 JSON 文档的总分",
      "pos": [
        7069,
        7082
      ]
    },
    {
      "pos": [
        7220,
        7345
      ],
      "content": "以上查询使用 <bpt id=\"p1\">[</bpt>lateral view explode<ept id=\"p1\">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView)</ept> UDF 展开分数数组，以便可以求和。"
    },
    {
      "content": "下面是 Hive 控制台的输出。",
      "pos": [
        7347,
        7363
      ]
    },
    {
      "content": "SerDe 查询 2",
      "pos": [
        7367,
        7377
      ]
    },
    {
      "content": "查找给定的学生在哪些科目取得了 80 以上的分数 SELECT jt.StudentClassCollection.ClassId FROM json\\_table jt lateral view explode(jt.StudentClassCollection.Score) collection as score where score &gt; 80;",
      "pos": [
        7413,
        7590
      ]
    },
    {
      "content": "上面的查询将返回一个 Hive 数组，这与 get\\_json\\_object 不同，后者返回一个字符串。",
      "pos": [
        7598,
        7651
      ]
    },
    {
      "content": "SerDe 查询 3",
      "pos": [
        7655,
        7665
      ]
    },
    {
      "pos": [
        7701,
        7822
      ],
      "content": "如果你想要跳过格式不正确的 JSON，可以根据此 SerDe 的 <bpt id=\"p1\">[</bpt>wiki 页面<ept id=\"p1\">](https://github.com/sheetaldolas/Hive-JSON-Serde/tree/master)</ept>中所述，通过键入以下代码实现此目的："
    },
    {
      "content": "摘要",
      "pos": [
        7914,
        7916
      ]
    },
    {
      "content": "总之，在 Hive 中选择的 JSON 运算符类型取决于你的方案。如果你有一个简单的 JSON 文档，并只有一个要查找的字段，则你可以选择使用 Hive UDF get\\_json\\_object。如果你有多个键用于查找，则可以使用 json\\_tuple。如果你有嵌套的文档，则应使用 JSON SerDe。",
      "pos": [
        7917,
        8072
      ]
    },
    {
      "content": "如需其他相关文章，请参阅",
      "pos": [
        8074,
        8086
      ]
    },
    {
      "content": "将 Hive 和 HiveQL 与 HDInsight 中的 Hadoop 配合使用以分析示例 Apache log4j 文件",
      "pos": [
        8091,
        8154
      ]
    },
    {
      "content": "使用 HDInsight 中的 Hive 分析航班延误数据",
      "pos": [
        8203,
        8232
      ]
    }
  ],
  "content": "<properties\n   pageTitle=\"使用 HDInsight 中的 Hive 分析和处理 JSON 文档 | Azure\"\n   description=\"了解如何使用 JSON 文档，以及如何使用 HDInsight 中的 Hive 来分析这些文档。\"\n   services=\"hdinsight\"\n   documentationCenter=\"\"\n   authors=\"rashimg\"\n   manager=\"mwinkle\"\n   editor=\"cgronlun\"/>\n\n<tags\n   ms.service=\"hdinsight\"\n   ms.date=\"06/22/2015\"\n   wacn.date=\"12/15/2015\"/>\n\n\n# 使用 HDInsight 中的 Hive 处理和分析 JSON 文档\n\n了解如何使用 HDInsight 中的 Hive 处理和分析 JSON 文件。本教程将使用以下 JSON 文档\n\n    {\n        \"StudentId\": \"trgfg-5454-fdfdg-4346\",\n        \"Grade\": 7,\n        \"StudentDetails\": [\n            {\n                \"FirstName\": \"Peggy\",\n                \"LastName\": \"Williams\",\n                \"YearJoined\": 2012\n            }\n        ],\n        \"StudentClassCollection\": [\n            {\n                \"ClassId\": \"89084343\",\n                \"ClassParticipation\": \"Satisfied\",\n                \"ClassParticipationRank\": \"High\",\n                \"Score\": 93,\n                \"PerformedActivity\": false\n            },\n            {\n                \"ClassId\": \"78547522\",\n                \"ClassParticipation\": \"NotSatisfied\",\n                \"ClassParticipationRank\": \"None\",\n                \"Score\": 74,\n                \"PerformedActivity\": false\n            },\n            {\n                \"ClassId\": \"78675563\",\n                \"ClassParticipation\": \"Satisfied\",\n                \"ClassParticipationRank\": \"Low\",\n                \"Score\": 83,\n                \"PerformedActivity\": true\n            }\n        ]\n    }\n\n可以在 wasb://processjson@hditutorialdata.blob.core.windows.net/ 上找到该文件。有关将 Azure Blob 存储与 HDInsight 配合使用的详细信息，请参阅[将 HDFS 兼容的 Azure Blob 存储与 HDInsight 中的 Hadoop 配合使用](/documentation/articles/hdinsight-hadoop-use-blob-storage)。如果需要，你可以将该文件复制到群集的默认容器。\n\n在本教程中，你将使用 Hive 控制台。有关打开 Hive 控制台的说明，请参阅[通过远程桌面将 Hive 与 HDInsight 上的 Hadoop 配合使用](/documentation/articles/hdinsight-hadoop-use-hive-remote-desktop)。\n\n##平展 JSON 文档\n\n下一部分中所列的方法需要 JSON 文档在单一行中。因此，你必须将 JSON 文档平展成字符串。如果 JSON 文档已平展，则你可以跳过此步骤，直接转到有关分析 JSON 数据的下一部分。\n\n    DROP TABLE IF EXISTS StudentsRaw;\n    CREATE EXTERNAL TABLE StudentsRaw (textcol string) STORED AS TEXTFILE LOCATION \"wasb://processjson@hditutorialdata.blob.core.windows.net/\";\n    \n    DROP TABLE IF EXISTS StudentsOneLine;\n    CREATE EXTERNAL TABLE StudentsOneLine\n    (\n      json_body string\n    )\n    STORED AS TEXTFILE LOCATION '/json/students';\n    \n    INSERT OVERWRITE TABLE StudentsOneLine\n    SELECT CONCAT_WS(' ',COLLECT_LIST(textcol)) AS singlelineJSON \n          FROM (SELECT INPUT__FILE__NAME,BLOCK__OFFSET__INSIDE__FILE, textcol FROM StudentsRaw DISTRIBUTE BY INPUT__FILE__NAME SORT BY BLOCK__OFFSET__INSIDE__FILE) x\n          GROUP BY INPUT__FILE__NAME;\n    \n    SELECT * FROM StudentsOneLine\n\n原始 JSON 文件位于 **wasb://processjson@hditutorialdata.blob.core.windows.net/**。 *StudentsRaw* Hive 表指向原始的未平展 JSON 文档。\n\n*StudentsOneLine* Hive 表将数据存储在 HDInsight 默认文件系统中的 */json/students/* 路径下。\n\nINSERT 语句在 StudentOneLine 表中填充平展的 JSON 数据。\n\nSELECT 语句应只返回 1 行。\n\n下面是 SELECT 语句的输出：\n\n![平展 JSON 文档。][image-hdi-hivejson-flatten]\n\n##在 Hive 中分析 JSON 文档\n\nHive 提供了三种不同的机制用于对 JSON 文档运行查询：\n\n- 使用 GET\\_JSON\\_OBJECT UDF（用户定义的函数）\n- 使用 JSON\\_TUPLE UDF\n- 使用自定义 SerDe\n- 使用 Python 或其他语言编写你自己的 UDF。请参阅[此文][hdinsight-python]，了解如何使用 Hive 运行自己的 Python 代码。 \n\n### 使用 GET\\_JSON\\_OBJECT UDF\nHive 提供了名为 [get\\_json\\_object](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object) 的内置 UDF，它可以在运行时执行 JSON 查询。此方法采用两个参数 – 表名称和方法名称，具有平展的 JSON 文档和需要进行分析的 JSON 字段。让我们来探讨一个示例，以了解此 UDF 的工作原理。\n\n获取每个学生的名字和姓氏\n\n    SELECT \n      GET_JSON_OBJECT(StudentsOneLine.json_body,'$.StudentDetails.FirstName'), \n      GET_JSON_OBJECT(StudentsOneLine.json_body,'$.StudentDetails.LastName') \n    FROM StudentsOneLine;\n\n这是在控制台窗口中运行此查询时的输出。\n\n![get\\_json\\_object UDF][image-hdi-hivejson-getjsonobject]\n\nget-json\\_object UDF 有一些限制。\n\n- 由于查询中的每个字段都需要重新分析查询，因此会影响性能。\n- GET\\_JSON\\_OBJECT() 返回数组的字符串表示形式。若要将其转换为 Hive 数组，你必须使用正则表达式来替换方括号“[”和“]”，然后调用拆分来获取数组。\n\n\n正因如此，Hive wiki 建议使用 json\\_tuple。\n\n### 使用 JSON\\_TUPLE UDF\n\nHive 提供的另一个 UDF 称为 [json\\_tuple](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-json_tuple)，其性能比 [get\\_ json \\_object](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-get_json_object) 要高。此方法采用一组键和一个 JSON 字符串，并使用一个函数返回值的元组。以下查询将从 JSON 文档返回学生 ID 和年级：\n\n    SELECT q1.StudentId, q1.Grade \n      FROM StudentsOneLine jt\n      LATERAL VIEW JSON_TUPLE(jt.json_body, 'StudentId', 'Grade') q1\n        AS StudentId, Grade;\n\n此脚本在 Hive 控制台中的输出：\n\n![json\\_tuple UDF][image-hdi-hivejson-jsontuple]\n\nJSON\\_TUPLE 在 Hive 中使用了[横向视图](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView)语法，使 json\\_tuple 能够通过将 UDT 函数应用于原始表的每一行来创建虚拟表。由于重复使用横向视图，复杂的 JSON 会变得过于庞大。此外，JSON_TUPLE 无法处理嵌套的 JSONs。\n\n\n###使用自定义 SerDe\n\nSerDe 是用于分析嵌套 JSON 文档的最佳选择，它可让你定义 JSON 架构，并使用该架构来分析文档。在本教程中，你将使用其中 [rcongiu](https://github.com/rcongiu) 开发的热门 SerDe 之一。\n\n**使用自定义 SerDe：**\n\n1. 安装 [Java SE 开发工具包 7u55 JDK 1.7.0_55](http://www.oracle.com/technetwork/java/javase/downloads/java-archive-downloads-javase7-521261.html#jdk-7u55-oth-JPR)。如果你要使用 HDInsight 的 Windows 部署，请选择 Windows X64 版本的 JDK。\n\n    >[AZURE.WARNING]JDK 1.8 不适用于此 SerDe。\n\n    安装完成之后，请添加新的用户环境变量：\n\n    1. 从 Windows 屏幕打开“查看高级系统设置”。\n    2. 单击“环境变量”。  \n    3. 添加指向 **C:\\\\Program Files\\\\Java\\\\jdk1.7.0\\_55** 或任何 JDK 安装位置的新 **JAVA_HOME** 环境变量。\n\n    ![为 JDK 设置正确的配置值][image-hdi-hivejson-jdk]\n\n2. 安装 [Maven 3.3.1](http://mirror.olnevhost.net/pub/apache/maven/maven-3/3.3.1/binaries/apache-maven-3.3.1-bin.zip)\n\n    转到“控件面板”->“编辑系统变量”（对应于你帐户的环境变量），将 bin 文件夹添加到你的路径。以下屏幕截图显示了如何执行此操作。\n\n    ![设置 Maven][image-hdi-hivejson-maven]\n\n3. 从 [Hive-JSON-SerDe](https://github.com/sheetaldolas/Hive-JSON-Serde/tree/master) github 站点克隆项目。可以通过按以下屏幕截图中所示单击“下载 Zip”按钮来实现此目的。\n\n    ![克隆项目][image-hdi-hivejson-serde]\n\n4：转到此包下载到的文件夹，然后键入“mvn package”。这应会创建必要的 jar 文件，然后你可以将其复制到群集。\n\n5：转到根文件夹下存放所下载包的目标文件夹。将 json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar 文件上载到群集的头节点。我通常会将它放在 hive bin 文件夹下：C:\\\\apps\\\\dist\\\\hive-0.13.0.2.1.11.0-2316\\\\bin 或类似的文件夹。\n \n6：在 hive 提示符下，键入“add jar /path/to/json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar”。由于在我的示例中，jar 在 C:\\\\apps\\\\dist\\\\hive-0.13.x\\\\bin 文件夹中，因此我可以直接添加名称如下的 jar：\n\n    add jar json-serde-1.1.9.9-Hive13-jar-with-dependencies.jar;\n\n    ![Adding JAR to your project][image-hdi-hivejson-addjar]\n\n现在，你可以使用 SerDe 对 JSON 文档运行查询。\n\n以下语句将创建使用所定义架构的表\n\n    DROP TABLE json_table;\n    CREATE EXTERNAL TABLE json_table (\n      StudentId string, \n      Grade int,\n      StudentDetails array<struct<\n          FirstName:string,\n          LastName:string,\n          YearJoined:int\n          >\n      >,\n      StudentClassCollection array<struct<\n          ClassId:string,\n          ClassParticipation:string,\n          ClassParticipationRank:string,\n          Score:int,\n          PerformedActivity:boolean\n          >\n      >\n    ) ROW FORMAT SERDE 'org.openx.data.jsonserde.JsonSerDe'\n    LOCATION '/json/students';\n\n列出学生的名字和姓氏\n\n    SELECT StudentDetails.FirstName, StudentDetails.LastName FROM json_table;\n\n下面是 Hive 控制台输出的结果。\n\n![SerDe 查询 1][image-hdi-hivejson-serde_query1]\n\n计算 JSON 文档的总分\n\n    SELECT SUM(scores)\n    FROM json_table jt\n      lateral view explode(jt.StudentClassCollection.Score) collection as scores;\n       \n以上查询使用 [lateral view explode](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+LateralView) UDF 展开分数数组，以便可以求和。\n\n下面是 Hive 控制台的输出。\n\n![SerDe 查询 2][image-hdi-hivejson-serde_query2]\n\n查找给定的学生在哪些科目取得了 80 以上的分数 SELECT jt.StudentClassCollection.ClassId FROM json\\_table jt lateral view explode(jt.StudentClassCollection.Score) collection as score where score > 80;\n      \n上面的查询将返回一个 Hive 数组，这与 get\\_json\\_object 不同，后者返回一个字符串。\n\n![SerDe 查询 3][image-hdi-hivejson-serde_query3]\n\n如果你想要跳过格式不正确的 JSON，可以根据此 SerDe 的 [wiki 页面](https://github.com/sheetaldolas/Hive-JSON-Serde/tree/master)中所述，通过键入以下代码实现此目的：\n\n    ALTER TABLE json_table SET SERDEPROPERTIES ( \"ignore.malformed.json\" = \"true\");\n\n\n\n\n##摘要\n总之，在 Hive 中选择的 JSON 运算符类型取决于你的方案。如果你有一个简单的 JSON 文档，并只有一个要查找的字段，则你可以选择使用 Hive UDF get\\_json\\_object。如果你有多个键用于查找，则可以使用 json\\_tuple。如果你有嵌套的文档，则应使用 JSON SerDe。\n\n如需其他相关文章，请参阅\n\n- [将 Hive 和 HiveQL 与 HDInsight 中的 Hadoop 配合使用以分析示例 Apache log4j 文件](/documentation/articles/hdinsight-use-hive)\n- [使用 HDInsight 中的 Hive 分析航班延误数据](/documentation/articles/hdinsight-analyze-flight-delay-data)\n\n\n[hdinsight-python]: /documentation/articles/hdinsight-python\n\n[image-hdi-hivejson-flatten]: ./media/hdinsight-using-json-in-hive/flatten.png\n[image-hdi-hivejson-getjsonobject]: ./media/hdinsight-using-json-in-hive/getjsonobject.png\n[image-hdi-hivejson-jsontuple]: ./media/hdinsight-using-json-in-hive/jsontuple.png\n[image-hdi-hivejson-jdk]: ./media/hdinsight-using-json-in-hive/jdk.png\n[image-hdi-hivejson-maven]: ./media/hdinsight-using-json-in-hive/maven.png\n[image-hdi-hivejson-serde]: ./media/hdinsight-using-json-in-hive/serde.png\n[image-hdi-hivejson-addjar]: ./media/hdinsight-using-json-in-hive/addjar.png\n[image-hdi-hivejson-serde_query1]: ./media/hdinsight-using-json-in-hive/serde_query1.png\n[image-hdi-hivejson-serde_query2]: ./media/hdinsight-using-json-in-hive/serde_query2.png\n[image-hdi-hivejson-serde_query3]: ./media/hdinsight-using-json-in-hive/serde_query3.png\n[image-hdi-hivejson-serde_result]: ./media/hdinsight-using-json-in-hive/serde_result.png\n\n<!---HONumber=71-->"
}