{
  "nodes": [
    {
      "content": "在 HDInsight 中使用 Hadoop Oozie | Azure",
      "pos": [
        27,
        63
      ]
    },
    {
      "content": "在 HDInsight 中使用大数据服务 Hadoop Oozie。了解如何定义 Oozie 工作流，并提交 Oozie 作业。",
      "pos": [
        82,
        146
      ]
    },
    {
      "content": "在 HDInsight 中将 Oozie 与 Hadoop 配合使用以定义和运行工作流",
      "pos": [
        384,
        427
      ]
    },
    {
      "pos": [
        504,
        631
      ],
      "content": "了解如何定义工作流，以及如何在 HDInsight 上运行工作流。若要了解 Oozie 协调器，请参阅<bpt id=\"p1\">[</bpt>将基于时间的 Hadoop Oozie 协调器与 HDInsight 配合使用<ept id=\"p1\">][hdinsight-oozie-coordinator-time]</ept>。"
    },
    {
      "content": "Apache Oozie 是一个管理 Hadoop 作业的工作流/协调系统。它与 Hadoop 堆栈集成，支持 Apache MapReduce、Apache Pig、Apache Hive 和 Apache Sqoop 的 Hadoop 作业。它也能用于安排特定于某系统的作业，例如 Java 程序或 shell 脚本。",
      "pos": [
        633,
        794
      ]
    },
    {
      "content": "你要根据本教程中的说明实现的工作流包含两个操作：",
      "pos": [
        796,
        820
      ]
    },
    {
      "content": "工作流关系图",
      "pos": [
        824,
        830
      ]
    },
    {
      "content": "Hive 操作运行 HiveQL 脚本以统计 log4j 文件中每个日志级类型的次数。每个 log4j 文件都包含一行字段，其中包含 [LOG LEVEL] 字段用于显示类型和严重性，例如：",
      "pos": [
        858,
        953
      ]
    },
    {
      "content": "该 Hive 脚本的输出结果类似于：",
      "pos": [
        1210,
        1228
      ]
    },
    {
      "pos": [
        1348,
        1411
      ],
      "content": "有关 Hive 的详细信息，请参阅<bpt id=\"p1\">[</bpt>将 Hive 与 HDInsight 配合使用<ept id=\"p1\">][hdinsight-use-hive]</ept>。"
    },
    {
      "pos": [
        1417,
        1532
      ],
      "content": "Sqoop 操作将 HiveQL 输出结果导出到 Azure SQL 数据库中的表。有关 Sqoop 的详细信息，请参阅<bpt id=\"p1\">[</bpt>将 Hadoop Sqoop 与 HDInsight 配合使用<ept id=\"p1\">][hdinsight-use-sqoop]</ept>。"
    },
    {
      "pos": [
        1536,
        1638
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>有关在 HDInsight 群集上支持的 Oozie 版本，请参阅 <bpt id=\"p1\">[</bpt>HDInsight 提供的 Hadoop 群集版本有哪些新增功能？<ept id=\"p1\">][hdinsight-versions]</ept>。"
    },
    {
      "pos": [
        1643,
        1675
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"prerequisites\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>先决条件"
    },
    {
      "content": "在开始阅读本教程前，你必须具有：",
      "pos": [
        1677,
        1693
      ]
    },
    {
      "pos": [
        1697,
        1925
      ],
      "content": "<bpt id=\"p1\">**</bpt>配备 Azure PowerShell 的工作站<ept id=\"p1\">**</ept>。请参阅<bpt id=\"p2\">[</bpt>安装和使用 Azure PowerShell<ept id=\"p2\">](/documentation/articles/powershell-install-configure)</ept>。若要执行 Windows PowerShell 脚本，必须以管理员身份运行并将执行策略设为 <bpt id=\"p3\">*</bpt>RemoteSigned<ept id=\"p3\">*</ept>。有关详细信息，请参阅<bpt id=\"p4\">[</bpt>运行 Windows PowerShell 脚本<ept id=\"p4\">][powershell-script]</ept>。"
    },
    {
      "content": "定义 Oozie 工作流及相关 HiveQL 脚本",
      "pos": [
        1929,
        1954
      ]
    },
    {
      "pos": [
        1956,
        2038
      ],
      "content": "Oozie 工作流定义是用 hPDL（一种 XML 过程定义语言）编写的。默认的工作流文件名为 <bpt id=\"p1\">*</bpt>workflow.xml<ept id=\"p1\">*</ept>。以下是你要在本教程中使用的工作流文件。"
    },
    {
      "pos": [
        4066,
        4143
      ],
      "content": "该工作流中定义了两个操作。start-to 操作是 <bpt id=\"p1\">*</bpt>RunHiveScript<ept id=\"p1\">*</ept>。如果该操作成功运行，则下一个操作是 <bpt id=\"p2\">*</bpt>RunSqoopExport<ept id=\"p2\">*</ept>。"
    },
    {
      "content": "RunHiveScript 有几个变量。在从工作站使用 Azure PowerShell 提交 Oozie 作业时，将会传递值。",
      "pos": [
        4145,
        4209
      ]
    },
    {
      "content": "工作流变量",
      "pos": [
        4240,
        4245
      ]
    },
    {
      "content": "说明",
      "pos": [
        4254,
        4256
      ]
    },
    {
      "content": "${jobTracker}",
      "pos": [
        4275,
        4288
      ]
    },
    {
      "content": "指定 Hadoop 作业跟踪器的 URL。在 HDInsight 版本 3.0 和 2.1 中使用 <ph id=\"ph1\">&lt;strong&gt;</ph>jobtrackerhost:9010<ph id=\"ph2\">&lt;/strong&gt;</ph>。",
      "pos": [
        4297,
        4384
      ]
    },
    {
      "content": "${nameNode}",
      "pos": [
        4403,
        4414
      ]
    },
    {
      "content": "指定 Hadoop 名称节点的 URL。请使用默认文件系统地址，例如 <ph id=\"ph1\">&lt;i&gt;</ph>wasb://&amp;lt;containerName&gt;@&amp;lt;storageAccountName&gt;.blob.core.chinacloudapi.cn<ph id=\"ph2\">&lt;/i&gt;</ph>。",
      "pos": [
        4423,
        4542
      ]
    },
    {
      "content": "${queueName}",
      "pos": [
        4561,
        4573
      ]
    },
    {
      "content": "指定要将作业提交到的队列名称。使用<ph id=\"ph1\">&lt;strong&gt;</ph>默认值<ph id=\"ph2\">&lt;/strong&gt;</ph>。",
      "pos": [
        4582,
        4620
      ]
    },
    {
      "content": "Hive 操作变量",
      "pos": [
        4670,
        4679
      ]
    },
    {
      "content": "说明",
      "pos": [
        4688,
        4690
      ]
    },
    {
      "content": "${hiveDataFolder}",
      "pos": [
        4709,
        4726
      ]
    },
    {
      "content": "指定 Hive Create Table 命令的源目录。",
      "pos": [
        4735,
        4763
      ]
    },
    {
      "content": "${hiveOutputFolder}",
      "pos": [
        4782,
        4801
      ]
    },
    {
      "content": "指定 INSERT OVERWRITE 语句的输出文件夹。",
      "pos": [
        4810,
        4839
      ]
    },
    {
      "content": "${hiveTableName}",
      "pos": [
        4858,
        4874
      ]
    },
    {
      "content": "指定引用 log4j 数据文件的 Hive 表的名称。",
      "pos": [
        4883,
        4910
      ]
    },
    {
      "content": "Sqoop 操作变量",
      "pos": [
        4960,
        4970
      ]
    },
    {
      "content": "说明",
      "pos": [
        4979,
        4981
      ]
    },
    {
      "content": "${sqlDatabaseConnectionString}",
      "pos": [
        5000,
        5030
      ]
    },
    {
      "content": "指定 Azure SQL 数据库连接字符串。",
      "pos": [
        5039,
        5061
      ]
    },
    {
      "content": "${sqlDatabaseTableName}",
      "pos": [
        5080,
        5103
      ]
    },
    {
      "content": "指定要将数据导出到的 Azure SQL 数据库表。",
      "pos": [
        5112,
        5138
      ]
    },
    {
      "content": "${hiveOutputFolder}",
      "pos": [
        5157,
        5176
      ]
    },
    {
      "content": "指定 Hive INSERT OVERWRITE 语句的输出文件夹。这是用于 Sqoop 导出 (export-dir) 的同一个文件夹。",
      "pos": [
        5185,
        5254
      ]
    },
    {
      "pos": [
        5275,
        5430
      ],
      "content": "有关 Oozie 工作流和使用工作流操作的详细信息，请参阅 <bpt id=\"p1\">[</bpt>Apache Oozie 4.0 文档<ept id=\"p1\">][apache-oozie-400]</ept>（适用于 HDInsight 3.0 版）或 <bpt id=\"p2\">[</bpt>Apache Oozie 3.3.2 文档<ept id=\"p2\">][apache-oozie-332]</ept>（适用于 HDInsight 2.1 版）。"
    },
    {
      "pos": [
        5435,
        5527
      ],
      "content": "使用 ANSI (ASCII) 编码将文件另存为 <bpt id=\"p1\">**</bpt>C:\\\\Tutorials\\\\UseOozie\\\\workflow.xml<ept id=\"p1\">**</ept>。（如果你的文本编辑器不提供此选项，则使用记事本。）"
    },
    {
      "content": "部署 Oozie 项目并准备教程",
      "pos": [
        5535,
        5551
      ]
    },
    {
      "content": "你将运行 Windows PowerShell 脚本来执行以下操作：",
      "pos": [
        5553,
        5587
      ]
    },
    {
      "content": "将 HiveQL 脚本 (useoozie.hql) 复制到 Azure 存储空间 (wasb:///tutorials/useoozie/useoozie.hql)。",
      "pos": [
        5591,
        5675
      ]
    },
    {
      "content": "将 workflow.xml 复制到 wasb:///tutorials/useoozie/workflow.xml。",
      "pos": [
        5678,
        5737
      ]
    },
    {
      "content": "将数据文件 (/example/data/sample.log) 复制到 wasb:///tutorials/useoozie/data/sample.log。",
      "pos": [
        5740,
        5820
      ]
    },
    {
      "pos": [
        5824,
        5880
      ],
      "content": "创建用于存储 Sqoop 导出数据的 Azure SQL 数据库表。表的名称为 <bpt id=\"p1\">*</bpt>log4jLogCount<ept id=\"p1\">*</ept>。"
    },
    {
      "content": "了解 HDInsight 存储",
      "pos": [
        5884,
        5899
      ]
    },
    {
      "pos": [
        5903,
        6003
      ],
      "content": "HDInsight 使用 Azure 存储空间中的 Blob 来存储数据。有关详细信息，请参阅<bpt id=\"p1\">[</bpt>将 Azure Blob 存储与 HDInsight 配合使用<ept id=\"p1\">][hdinsight-storage]</ept>。"
    },
    {
      "pos": [
        6005,
        6303
      ],
      "content": "设置 HDInsight 群集时，请将 Azure 存储帐户和该帐户上的特定 Blob 容器指定为默认文件系统，就像在 HDFS 中一样。除了此存储帐户外，在设置过程中，你还可以从同一 Azure 订阅或不同 Azure 订阅添加其他存储帐户。有关添加其他存储帐户的详细信息，请参阅<bpt id=\"p1\">[</bpt>在 HDInsight 中预配 Hadoop 群集<ept id=\"p1\">][hdinsight-provision]</ept>。为了简化本教程中使用的 Windows PowerShell 脚本，所有文件都存储在默认文件存储容器（位于 <bpt id=\"p2\">*</bpt>/tutorials/useoozie<ept id=\"p2\">*</ept>）中。默认情况下，此容器与 HDInsight 群集同名。语法为："
    },
    {
      "pos": [
        6404,
        6523
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>HDInsight 版本 3.0 群集仅支持 *<bpt id=\"p1\">*</bpt>wasb://<ept id=\"p1\">*</ept> 语法。较早的 *<bpt id=\"p2\">*</bpt>asv://<ept id=\"p2\">*</ept> 语法在 HDInsight 2.1 和 1.6 群集中受支持，但在 HDInsight 3.0 群集中不受支持。"
    },
    {
      "pos": [
        6527,
        6618
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>wasb:// 路径是虚拟路径。有关详细信息，请参阅<bpt id=\"p1\">[</bpt>将 Azure Blob 存储与 HDInsight 配合使用<ept id=\"p1\">][hdinsight-storage]</ept>。"
    },
    {
      "content": "存储在默认文件系统容器中的文件可以使用以下任一 URI 从 HDInsight 进行访问（以下代码使用 workflow.xml 为例）：",
      "pos": [
        6620,
        6689
      ]
    },
    {
      "content": "如果要从存储帐户直接访问该文件，则请注意，该文件的 Blob 名称是：",
      "pos": [
        6872,
        6907
      ]
    },
    {
      "content": "了解 Hive 内部表和外部表",
      "pos": [
        6948,
        6963
      ]
    },
    {
      "content": "以下是你需要了解的有关 Hive 内部表和外部表的一些信息：",
      "pos": [
        6967,
        6997
      ]
    },
    {
      "content": "CREATE TABLE 命令创建内部表，也称为托管表。数据文件必须位于默认容器中。",
      "pos": [
        7001,
        7043
      ]
    },
    {
      "content": "CREATE TABLE 命令将数据文件移动到默认容器中的 /hive/warehouse/",
      "pos": [
        7046,
        7092
      ]
    },
    {
      "content": "文件夹。",
      "pos": [
        7104,
        7108
      ]
    },
    {
      "content": "CREATE EXTERNAL TABLE 命令创建外部表。数据文件可以位于默认容器以外的位置。",
      "pos": [
        7111,
        7159
      ]
    },
    {
      "content": "CREATE EXTERNAL TABLE 命令不移动数据文件。",
      "pos": [
        7162,
        7194
      ]
    },
    {
      "content": "CREATE EXTERNAL TABLE 命令不允许 LOCATION 子句中指定的文件夹下有任何子文件夹。这是本教程生成 sample.log 文件的副本的原因。",
      "pos": [
        7197,
        7280
      ]
    },
    {
      "pos": [
        7282,
        7343
      ],
      "content": "有关详细信息，请参阅 <bpt id=\"p1\">[</bpt>HDInsight：Hive 内部和外部表简介<ept id=\"p1\">][cindygross-hive-tables]</ept>。"
    },
    {
      "content": "准备教程",
      "pos": [
        7347,
        7351
      ]
    },
    {
      "pos": [
        7358,
        7532
      ],
      "content": "打开 Windows PowerShell ISE。（在 Windows 8 的“开始”屏幕上键入 <bpt id=\"p1\">**</bpt>PowerShell_ISE<ept id=\"p1\">**</ept>，然后单击“Windows PowerShell ISE”。有关详细信息，请参阅<bpt id=\"p2\">[</bpt>在 Windows 8 和 Windows 上启动 Windows PowerShell<ept id=\"p2\">][powershell-start]</ept>）。"
    },
    {
      "content": "在底部窗格中，运行以下命令以连接到 Azure 订阅：",
      "pos": [
        7536,
        7563
      ]
    },
    {
      "content": "系统将提示你输入 Azure 帐户凭据。这种添加订阅连接的方法会超时，12 个小时之后，你将需要再次运行该 cmdlet。",
      "pos": [
        7624,
        7685
      ]
    },
    {
      "pos": [
        7693,
        7797
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>如果你有多个 Azure 订阅，而默认订阅不是你想使用的，则请使用 <ph id=\"ph2\">&lt;strong&gt;</ph>Select-AzureSubscription<ph id=\"ph3\">&lt;/strong&gt;</ph> cmdlet 来选择正确的订阅。"
    },
    {
      "content": "将以下脚本复制到脚本窗格，然后设置前六个变量：",
      "pos": [
        7802,
        7825
      ]
    },
    {
      "pos": [
        8616,
        8661
      ],
      "content": "有关这些变量的详细说明，请参阅本教程中的<bpt id=\"p1\">[</bpt>先决条件<ept id=\"p1\">](#prerequisites)</ept>部分。"
    },
    {
      "content": "在脚本窗格中将以下内容追加到脚本：",
      "pos": [
        8666,
        8683
      ]
    },
    {
      "pos": [
        11327,
        11362
      ],
      "content": "单击“运行脚本”或按 <bpt id=\"p1\">**</bpt>F5<ept id=\"p1\">**</ept> 键以运行该脚本。输出将类似于下面："
    },
    {
      "content": "教程准备的输出结果",
      "pos": [
        11370,
        11379
      ]
    },
    {
      "content": "运行 Oozie 项目",
      "pos": [
        11408,
        11419
      ]
    },
    {
      "pos": [
        11421,
        11712
      ],
      "content": "Azure PowerShell 目前不提供任何用于定义 Oozie 作业的 cmdlet。你可以使用 <bpt id=\"p1\">**</bpt>Invoke-RestMethod<ept id=\"p1\">**</ept> cmdlet 来调用 Oozie Web 服务。Oozie Web 服务 API 是 HTTP REST JSON API。有关 Oozie Web 服务 API 的详细信息，请参阅 <bpt id=\"p2\">[</bpt>Apache Oozie 4.0 文档<ept id=\"p2\">][apache-oozie-400]</ept>（用于 HDInsight 版本 3.0）或 <bpt id=\"p3\">[</bpt>Apache Oozie 3.3.2 文档<ept id=\"p3\">][apache-oozie-332]</ept>（用于 HDInsight 版本 2.1）。"
    },
    {
      "content": "提交 Oozie 作业",
      "pos": [
        11716,
        11727
      ]
    },
    {
      "pos": [
        11734,
        11908
      ],
      "content": "打开 Windows PowerShell ISE。（在 Windows 8 的“开始”屏幕上键入 <bpt id=\"p1\">**</bpt>PowerShell_ISE<ept id=\"p1\">**</ept>，然后单击“Windows PowerShell ISE”。有关详细信息，请参阅<bpt id=\"p2\">[</bpt>在 Windows 8 和 Windows 上启动 Windows PowerShell<ept id=\"p2\">][powershell-start]</ept>）。"
    },
    {
      "content": "将以下脚本复制到脚本窗格，然后设置前 10 个变量（跳过 $storageUri 变量）。",
      "pos": [
        11913,
        11958
      ]
    },
    {
      "pos": [
        13660,
        13705
      ],
      "content": "有关这些变量的详细说明，请参阅本教程中的<bpt id=\"p1\">[</bpt>先决条件<ept id=\"p1\">](#prerequisites)</ept>部分。"
    },
    {
      "content": "将以下内容追加到脚本。此脚本定义 Oozie 负载。",
      "pos": [
        13710,
        13736
      ]
    },
    {
      "content": "将以下内容追加到脚本。此脚本检查 Oozie Web 服务状态。",
      "pos": [
        15694,
        15726
      ]
    },
    {
      "content": "将以下内容追加到脚本。这部分创建并启动一项 Oozie 作业：",
      "pos": [
        16259,
        16290
      ]
    },
    {
      "content": "将以下内容追加到脚本。此脚本检查 Oozie 作业状态。",
      "pos": [
        17303,
        17331
      ]
    },
    {
      "content": "如果你的 HDinsight 群集是 2.1 版的，请将“https://$clusterName.azurehdinsight.cn:443/oozie/v2/”替换为“https://$clusterName.azurehdinsight.cn:443/oozie/v1/”。HDInsight 群集版本 2.1 不支持 Web 服务的版本 2。",
      "pos": [
        18714,
        18889
      ]
    },
    {
      "pos": [
        18894,
        18929
      ],
      "content": "单击“运行脚本”或按 <bpt id=\"p1\">**</bpt>F5<ept id=\"p1\">**</ept> 键以运行该脚本。输出将类似于下面："
    },
    {
      "content": "教程运行工作流输出",
      "pos": [
        18937,
        18946
      ]
    },
    {
      "content": "连接到 Azure SQL 数据库以查看导出的数据。",
      "pos": [
        18976,
        19002
      ]
    },
    {
      "content": "检查作业错误日志",
      "pos": [
        19006,
        19014
      ]
    },
    {
      "pos": [
        19018,
        19291
      ],
      "content": "若要对工作流进行故障排除，可从群集头节点找到 Oozie 日志文件，位置是 <bpt id=\"p1\">*</bpt>C:\\\\apps\\\\dist\\\\oozie-3.3.2.1.3.2.0-05\\\\oozie-win-distro\\\\logs\\\\Oozie.log<ept id=\"p1\">*</ept> 或 <bpt id=\"p2\">*</bpt>C:\\\\apps\\\\dist\\\\oozie-4.0.0.2.0.7.0-1528\\\\oozie-win-distro\\\\logs\\\\Oozie.log<ept id=\"p2\">*</ept>。有关 RDP 的信息，请参阅<bpt id=\"p3\">[</bpt>在 HDInsight 中使用 Azure 管理门户管理 Hadoop 群集<ept id=\"p3\">][hdinsight-admin-portal]</ept>。"
    },
    {
      "content": "重新运行教程",
      "pos": [
        19295,
        19301
      ]
    },
    {
      "content": "若要重新运行该工作流，必须删除以下内容：",
      "pos": [
        19305,
        19325
      ]
    },
    {
      "content": "Hive 脚本输出文件",
      "pos": [
        19329,
        19340
      ]
    },
    {
      "content": "log4jLogsCount 表中的数据",
      "pos": [
        19343,
        19363
      ]
    },
    {
      "content": "这是你可以使用的一个示例 Windows PowerShell 脚本：",
      "pos": [
        19365,
        19400
      ]
    },
    {
      "content": "后续步骤",
      "pos": [
        20806,
        20810
      ]
    },
    {
      "content": "在本教程中，你已经学习了如何定义 Oozie 工作流，以及如何使用 Windows PowerShell 运行 Oozie 作业。若要了解更多信息，请参阅下列文章：",
      "pos": [
        20811,
        20893
      ]
    },
    {
      "content": "将基于时间的 Oozie 协调器与 HDInsight 配合使用",
      "pos": [
        20898,
        20930
      ]
    },
    {
      "content": "将 Hadoop 与 HDInsight 中的 Hive 配合使用以分析手机使用情况",
      "pos": [
        20969,
        21011
      ]
    },
    {
      "content": "HDInsight Emulator 入门",
      "pos": [
        21039,
        21060
      ]
    },
    {
      "content": "将 Azure Blob 存储与 HDInsight 配合使用",
      "pos": [
        21097,
        21128
      ]
    },
    {
      "content": "使用 PowerShell 管理 HDInsight",
      "pos": [
        21152,
        21178
      ]
    },
    {
      "content": "在 HDInsight 中上载 Hadoop 作业的数据",
      "pos": [
        21211,
        21239
      ]
    },
    {
      "content": "将 Sqoop 与 HDInsight 中的 Hadoop 配合使用",
      "pos": [
        21267,
        21301
      ]
    },
    {
      "content": "将 Hive 与 HDInsight 上的 Hadoop 配合使用",
      "pos": [
        21327,
        21360
      ]
    },
    {
      "content": "将 Pig 与 HDInsight 上的 Hadoop 配合使用",
      "pos": [
        21385,
        21417
      ]
    },
    {
      "content": "为 HDInsight 开发 C# Hadoop 流作业",
      "pos": [
        21441,
        21469
      ]
    },
    {
      "content": "为 HDInsight 开发 Java MapReduce 程序",
      "pos": [
        21508,
        21540
      ]
    }
  ],
  "content": "<properties\n    pageTitle=\"在 HDInsight 中使用 Hadoop Oozie | Azure\"\n    description=\"在 HDInsight 中使用大数据服务 Hadoop Oozie。了解如何定义 Oozie 工作流，并提交 Oozie 作业。\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    tags=\"azure-portal\"\n    authors=\"mumian\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.date=\"12/02/2015\"\n    wacn.date=\"01/14/2016\"/>\n\n\n# 在 HDInsight 中将 Oozie 与 Hadoop 配合使用以定义和运行工作流\n\n[AZURE.INCLUDE [oozie-selector](../includes/hdinsight-oozie-selector.md)]\n\n了解如何定义工作流，以及如何在 HDInsight 上运行工作流。若要了解 Oozie 协调器，请参阅[将基于时间的 Hadoop Oozie 协调器与 HDInsight 配合使用][hdinsight-oozie-coordinator-time]。\n\nApache Oozie 是一个管理 Hadoop 作业的工作流/协调系统。它与 Hadoop 堆栈集成，支持 Apache MapReduce、Apache Pig、Apache Hive 和 Apache Sqoop 的 Hadoop 作业。它也能用于安排特定于某系统的作业，例如 Java 程序或 shell 脚本。\n\n你要根据本教程中的说明实现的工作流包含两个操作：\n\n![工作流关系图][img-workflow-diagram]\n\n1. Hive 操作运行 HiveQL 脚本以统计 log4j 文件中每个日志级类型的次数。每个 log4j 文件都包含一行字段，其中包含 [LOG LEVEL] 字段用于显示类型和严重性，例如：\n\n        2012-02-03 18:35:34 SampleClass6 [INFO] everything normal for id 577725851\n        2012-02-03 18:35:34 SampleClass4 [FATAL] system problem at id 1991281254\n        2012-02-03 18:35:34 SampleClass3 [DEBUG] detail for id 1304807656\n        ...\n\n    该 Hive 脚本的输出结果类似于：\n\n        [DEBUG] 434\n        [ERROR] 3\n        [FATAL] 1\n        [INFO]  96\n        [TRACE] 816\n        [WARN]  4\n\n    有关 Hive 的详细信息，请参阅[将 Hive 与 HDInsight 配合使用][hdinsight-use-hive]。\n\n2.  Sqoop 操作将 HiveQL 输出结果导出到 Azure SQL 数据库中的表。有关 Sqoop 的详细信息，请参阅[将 Hadoop Sqoop 与 HDInsight 配合使用][hdinsight-use-sqoop]。\n\n> [AZURE.NOTE]有关在 HDInsight 群集上支持的 Oozie 版本，请参阅 [HDInsight 提供的 Hadoop 群集版本有哪些新增功能？][hdinsight-versions]。\n\n###<a name=\"prerequisites\"></a>先决条件\n\n在开始阅读本教程前，你必须具有：\n\n- **配备 Azure PowerShell 的工作站**。请参阅[安装和使用 Azure PowerShell](/documentation/articles/powershell-install-configure)。若要执行 Windows PowerShell 脚本，必须以管理员身份运行并将执行策略设为 *RemoteSigned*。有关详细信息，请参阅[运行 Windows PowerShell 脚本][powershell-script]。\n\n##定义 Oozie 工作流及相关 HiveQL 脚本\n\nOozie 工作流定义是用 hPDL（一种 XML 过程定义语言）编写的。默认的工作流文件名为 *workflow.xml*。以下是你要在本教程中使用的工作流文件。\n\n    <workflow-app name=\"useooziewf\" xmlns=\"uri:oozie:workflow:0.2\">\n        <start to = \"RunHiveScript\"/>\n\n        <action name=\"RunHiveScript\">\n            <hive xmlns=\"uri:oozie:hive-action:0.2\">\n                <job-tracker>${jobTracker}</job-tracker>\n                <name-node>${nameNode}</name-node>\n                <configuration>\n                    <property>\n                        <name>mapred.job.queue.name</name>\n                        <value>${queueName}</value>\n                    </property>\n                </configuration>\n                <script>${hiveScript}</script>\n                <param>hiveTableName=${hiveTableName}</param>\n                <param>hiveDataFolder=${hiveDataFolder}</param>\n                <param>hiveOutputFolder=${hiveOutputFolder}</param>\n            </hive>\n            <ok to=\"RunSqoopExport\"/>\n            <error to=\"fail\"/>\n        </action>\n\n        <action name=\"RunSqoopExport\">\n            <sqoop xmlns=\"uri:oozie:sqoop-action:0.2\">\n                <job-tracker>${jobTracker}</job-tracker>\n                <name-node>${nameNode}</name-node>\n                <configuration>\n                    <property>\n                        <name>mapred.compress.map.output</name>\n                        <value>true</value>\n                    </property>\n                </configuration>\n            <arg>export</arg>\n            <arg>--connect</arg>\n            <arg>${sqlDatabaseConnectionString}</arg>\n            <arg>--table</arg>\n            <arg>${sqlDatabaseTableName}</arg>\n            <arg>--export-dir</arg>\n            <arg>${hiveOutputFolder}</arg>\n            <arg>-m</arg>\n            <arg>1</arg>\n            <arg>--input-fields-terminated-by</arg>\n            <arg>\"\\001\"</arg>\n            </sqoop>\n            <ok to=\"end\"/>\n            <error to=\"fail\"/>\n        </action>\n\n        <kill name=\"fail\">\n            <message>Job failed, error message[${wf:errorMessage(wf:lastErrorNode())}] </message>\n        </kill>\n\n        <end name=\"end\"/>\n    </workflow-app>\n\n该工作流中定义了两个操作。start-to 操作是 *RunHiveScript*。如果该操作成功运行，则下一个操作是 *RunSqoopExport*。\n\nRunHiveScript 有几个变量。在从工作站使用 Azure PowerShell 提交 Oozie 作业时，将会传递值。\n\n<table border = \"1\">\n<tr><th>工作流变量</th><th>说明</th></tr>\n<tr><td>${jobTracker}</td><td>指定 Hadoop 作业跟踪器的 URL。在 HDInsight 版本 3.0 和 2.1 中使用 <strong>jobtrackerhost:9010</strong>。</td></tr>\n<tr><td>${nameNode}</td><td>指定 Hadoop 名称节点的 URL。请使用默认文件系统地址，例如 <i>wasb://&lt;containerName>@&lt;storageAccountName>.blob.core.chinacloudapi.cn</i>。</td></tr>\n<tr><td>${queueName}</td><td>指定要将作业提交到的队列名称。使用<strong>默认值</strong>。</td></tr>\n</table>\n\n<table border = \"1\">\n<tr><th>Hive 操作变量</th><th>说明</th></tr>\n<tr><td>${hiveDataFolder}</td><td>指定 Hive Create Table 命令的源目录。</td></tr>\n<tr><td>${hiveOutputFolder}</td><td>指定 INSERT OVERWRITE 语句的输出文件夹。</td></tr>\n<tr><td>${hiveTableName}</td><td>指定引用 log4j 数据文件的 Hive 表的名称。</td></tr>\n</table>\n\n<table border = \"1\">\n<tr><th>Sqoop 操作变量</th><th>说明</th></tr>\n<tr><td>${sqlDatabaseConnectionString}</td><td>指定 Azure SQL 数据库连接字符串。</td></tr>\n<tr><td>${sqlDatabaseTableName}</td><td>指定要将数据导出到的 Azure SQL 数据库表。</td></tr>\n<tr><td>${hiveOutputFolder}</td><td>指定 Hive INSERT OVERWRITE 语句的输出文件夹。这是用于 Sqoop 导出 (export-dir) 的同一个文件夹。</td></tr>\n</table>\n\n有关 Oozie 工作流和使用工作流操作的详细信息，请参阅 [Apache Oozie 4.0 文档][apache-oozie-400]（适用于 HDInsight 3.0 版）或 [Apache Oozie 3.3.2 文档][apache-oozie-332]（适用于 HDInsight 2.1 版）。\n\n2. 使用 ANSI (ASCII) 编码将文件另存为 **C:\\\\Tutorials\\\\UseOozie\\\\workflow.xml**。（如果你的文本编辑器不提供此选项，则使用记事本。）\n    \n##部署 Oozie 项目并准备教程\n\n你将运行 Windows PowerShell 脚本来执行以下操作：\n\n- 将 HiveQL 脚本 (useoozie.hql) 复制到 Azure 存储空间 (wasb:///tutorials/useoozie/useoozie.hql)。\n- 将 workflow.xml 复制到 wasb:///tutorials/useoozie/workflow.xml。\n- 将数据文件 (/example/data/sample.log) 复制到 wasb:///tutorials/useoozie/data/sample.log。 \n- 创建用于存储 Sqoop 导出数据的 Azure SQL 数据库表。表的名称为 *log4jLogCount*。\n\n**了解 HDInsight 存储**\n\nHDInsight 使用 Azure 存储空间中的 Blob 来存储数据。有关详细信息，请参阅[将 Azure Blob 存储与 HDInsight 配合使用][hdinsight-storage]。\n\n设置 HDInsight 群集时，请将 Azure 存储帐户和该帐户上的特定 Blob 容器指定为默认文件系统，就像在 HDFS 中一样。除了此存储帐户外，在设置过程中，你还可以从同一 Azure 订阅或不同 Azure 订阅添加其他存储帐户。有关添加其他存储帐户的详细信息，请参阅[在 HDInsight 中预配 Hadoop 群集][hdinsight-provision]。为了简化本教程中使用的 Windows PowerShell 脚本，所有文件都存储在默认文件存储容器（位于 */tutorials/useoozie*）中。默认情况下，此容器与 HDInsight 群集同名。语法为：\n\n    wasb[s]://<ContainerName>@<StorageAccountName>.blob.core.chinacloudapi.cn/<path>/<filename>\n\n> [AZURE.NOTE]HDInsight 版本 3.0 群集仅支持 **wasb://* 语法。较早的 **asv://* 语法在 HDInsight 2.1 和 1.6 群集中受支持，但在 HDInsight 3.0 群集中不受支持。\n\n> [AZURE.NOTE]wasb:// 路径是虚拟路径。有关详细信息，请参阅[将 Azure Blob 存储与 HDInsight 配合使用][hdinsight-storage]。\n\n存储在默认文件系统容器中的文件可以使用以下任一 URI 从 HDInsight 进行访问（以下代码使用 workflow.xml 为例）：\n\n    wasb://mycontainer@mystorageaccount.blob.core.chinacloudapi.cn/tutorials/useoozie/workflow.xml\n    wasb:///tutorials/useoozie/workflow.xml\n    /tutorials/useoozie/workflow.xml\n\n如果要从存储帐户直接访问该文件，则请注意，该文件的 Blob 名称是：\n\n    tutorials/useoozie/workflow.xml\n\n**了解 Hive 内部表和外部表**\n\n以下是你需要了解的有关 Hive 内部表和外部表的一些信息：\n\n- CREATE TABLE 命令创建内部表，也称为托管表。数据文件必须位于默认容器中。\n- CREATE TABLE 命令将数据文件移动到默认容器中的 /hive/warehouse/<TableName> 文件夹。\n- CREATE EXTERNAL TABLE 命令创建外部表。数据文件可以位于默认容器以外的位置。\n- CREATE EXTERNAL TABLE 命令不移动数据文件。\n- CREATE EXTERNAL TABLE 命令不允许 LOCATION 子句中指定的文件夹下有任何子文件夹。这是本教程生成 sample.log 文件的副本的原因。\n\n有关详细信息，请参阅 [HDInsight：Hive 内部和外部表简介][cindygross-hive-tables]。\n\n**准备教程**\n\n1. 打开 Windows PowerShell ISE。（在 Windows 8 的“开始”屏幕上键入 **PowerShell_ISE**，然后单击“Windows PowerShell ISE”。有关详细信息，请参阅[在 Windows 8 和 Windows 上启动 Windows PowerShell][powershell-start]）。\n2. 在底部窗格中，运行以下命令以连接到 Azure 订阅：\n\n        Add-AzureAccount -Environment AzureChinaCloud\n\n    系统将提示你输入 Azure 帐户凭据。这种添加订阅连接的方法会超时，12 个小时之后，你将需要再次运行该 cmdlet。\n\n    > [AZURE.NOTE]如果你有多个 Azure 订阅，而默认订阅不是你想使用的，则请使用 <strong>Select-AzureSubscription</strong> cmdlet 来选择正确的订阅。\n\n3. 将以下脚本复制到脚本窗格，然后设置前六个变量：\n            \n        # WASB variables\n        $storageAccountName = \"<StorageAccountName>\"\n        $containerName = \"<BlobStorageContainerName>\"\n        \n        # SQL database variables\n        $sqlDatabaseServer = \"<SQLDatabaseServerName>\"  \n        $sqlDatabaseLogin = \"<SQLDatabaseLoginName>\"\n        $sqlDatabaseLoginPassword = \"SQLDatabaseLoginPassword>\"\n        $sqlDatabaseName = \"<SQLDatabaseName>\"  \n        $sqlDatabaseTableName = \"log4jLogsCount\"\n        \n        # Oozie files for the tutorial  \n        $workflowDefinition = \"C:\\Tutorials\\UseOozie\\workflow.xml\"\n        $hiveQLScript = \"C:\\Tutorials\\UseOozie\\useooziewf.hql\"\n        \n        # WASB folder for storing the Oozie tutorial files.\n        $destFolder = \"tutorials/useoozie\"  # Do NOT use the long path here\n\n\n    有关这些变量的详细说明，请参阅本教程中的[先决条件](#prerequisites)部分。\n\n3. 在脚本窗格中将以下内容追加到脚本：\n        \n        # Create a storage context object\n        $storageaccountkey = get-azurestoragekey $storageAccountName | %{$_.Primary}\n        $destContext = New-AzureStorageContext -Environment AzureChinaCloud -StorageAccountName $storageAccountName -StorageAccountKey $storageaccountkey\n        \n        function uploadOozieFiles()\n        {       \n            Write-Host \"Copy workflow definition and HiveQL script file ...\" -ForegroundColor Green\n            Set-AzureStorageBlobContent -File $workflowDefinition -Container $containerName -Blob \"$destFolder/workflow.xml\" -Context $destContext\n            Set-AzureStorageBlobContent -File $hiveQLScript -Container $containerName -Blob \"$destFolder/useooziewf.hql\" -Context $destContext\n        }\n                \n        function prepareHiveDataFile()\n        {\n            Write-Host \"Make a copy of the sample.log file ... \" -ForegroundColor Green\n            Start-CopyAzureStorageBlob -SrcContainer $containerName -SrcBlob \"example/data/sample.log\" -Context $destContext -DestContainer $containerName -destBlob \"$destFolder/data/sample.log\" -DestContext $destContext\n        }\n                \n        function prepareSQLDatabase()\n        {\n            # SQL query string for creating log4jLogsCount table\n            $cmdCreateLog4jCountTable = \" CREATE TABLE [dbo].[$sqlDatabaseTableName](\n                    [Level] [nvarchar](10) NOT NULL,\n                    [Total] float,\n                CONSTRAINT [PK_$sqlDatabaseTableName] PRIMARY KEY CLUSTERED   \n                (\n                [Level] ASC\n                )\n                )\"\n                \n            #Create the log4jLogsCount table\n            Write-Host \"Create Log4jLogsCount table ...\" -ForegroundColor Green\n            $conn = New-Object System.Data.SqlClient.SqlConnection\n            $conn.ConnectionString = \"Data Source=$sqlDatabaseServer.devdatabase.chinacloudapi.cn;Initial Catalog=$sqlDatabaseName;User ID=$sqlDatabaseLogin;Password=$sqlDatabaseLoginPassword;Encrypt=true;Trusted_Connection=false;\"\n            $conn.open()\n            $cmd = New-Object System.Data.SqlClient.SqlCommand\n            $cmd.connection = $conn\n            $cmd.commandtext = $cmdCreateLog4jCountTable\n            $cmd.executenonquery()\n                \n            $conn.close()\n        }\n                \n        # upload workflow.xml, coordinator.xml, and ooziewf.hql\n        uploadOozieFiles;\n                \n        # make a copy of example/data/sample.log to example/data/log4j/sample.log\n        prepareHiveDataFile;\n        \n        # create log4jlogsCount table on SQL database\n        prepareSQLDatabase;\n\n4. 单击“运行脚本”或按 **F5** 键以运行该脚本。输出将类似于下面：\n\n    ![教程准备的输出结果][img-preparation-output]\n\n##运行 Oozie 项目\n\nAzure PowerShell 目前不提供任何用于定义 Oozie 作业的 cmdlet。你可以使用 **Invoke-RestMethod** cmdlet 来调用 Oozie Web 服务。Oozie Web 服务 API 是 HTTP REST JSON API。有关 Oozie Web 服务 API 的详细信息，请参阅 [Apache Oozie 4.0 文档][apache-oozie-400]（用于 HDInsight 版本 3.0）或 [Apache Oozie 3.3.2 文档][apache-oozie-332]（用于 HDInsight 版本 2.1）。\n\n**提交 Oozie 作业**\n\n1. 打开 Windows PowerShell ISE。（在 Windows 8 的“开始”屏幕上键入 **PowerShell_ISE**，然后单击“Windows PowerShell ISE”。有关详细信息，请参阅[在 Windows 8 和 Windows 上启动 Windows PowerShell][powershell-start]）。\n\n3. 将以下脚本复制到脚本窗格，然后设置前 10 个变量（跳过 $storageUri 变量）。\n\n        #HDInsight cluster variables\n        $clusterName = \"<HDInsightClusterName>\"\n        $clusterUsername = \"<HDInsightClusterUsername>\"\n        $clusterPassword = \"<HDInsightClusterUserPassword>\"\n        \n        #Azure Blob storage variables\n        $storageAccountName = \"<StorageAccountName>\"\n        $storageContainerName = \"<BlobContainerName>\"\n        $storageUri=\"wasb://$storageContainerName@$storageAccountName.blob.core.chinacloudapi.cn\"\n        \n        #Azure SQL database variables\n        $sqlDatabaseServer = \"<SQLDatabaseServerName>\"\n        $sqlDatabaseLogin = \"<SQLDatabaseLoginName>\"\n        $sqlDatabaseLoginPassword = \"<SQLDatabaseloginPassword>\"\n        $sqlDatabaseName = \"<SQLDatabaseName>\"  \n        \n        #Oozie WF variables\n        $oozieWFPath=\"$storageUri/tutorials/useoozie\"  # The default name is workflow.xml. And you don't need to specify the file name.\n        $waitTimeBetweenOozieJobStatusCheck=10\n        \n        #Hive action variables\n        $hiveScript = \"$storageUri/tutorials/useoozie/useooziewf.hql\"\n        $hiveTableName = \"log4jlogs\"\n        $hiveDataFolder = \"$storageUri/tutorials/useoozie/data\"\n        $hiveOutputFolder = \"$storageUri/tutorials/useoozie/output\"\n        \n        #Sqoop action variables\n        $sqlDatabaseConnectionString = \"jdbc:sqlserver://$sqlDatabaseServer.database.chinacloudapi.cn;user=$sqlDatabaseLogin@$sqlDatabaseServer;password=$sqlDatabaseLoginPassword;database=$sqlDatabaseName\"\n        $sqlDatabaseTableName = \"log4jLogsCount\"\n\n        $passwd = ConvertTo-SecureString $clusterPassword -AsPlainText -Force\n        $creds = New-Object System.Management.Automation.PSCredential ($clusterUsername, $passwd)\n\n\n    有关这些变量的详细说明，请参阅本教程中的[先决条件](#prerequisites)部分。\n\n3. 将以下内容追加到脚本。此脚本定义 Oozie 负载。\n        \n        #OoziePayload used for Oozie web service submission\n        $OoziePayload =  @\"\n        <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n        <configuration>\n        \n           <property>\n               <name>nameNode</name>\n               <value>$storageUrI</value>\n           </property>\n        \n           <property>\n               <name>jobTracker</name>\n               <value>jobtrackerhost:9010</value>\n           </property>\n        \n           <property>\n               <name>queueName</name>\n               <value>default</value>\n           </property>\n        \n           <property>\n               <name>oozie.use.system.libpath</name>\n               <value>true</value>\n           </property>\n        \n           <property>\n               <name>hiveScript</name>\n               <value>$hiveScript</value>\n           </property>\n        \n           <property>\n               <name>hiveTableName</name>\n               <value>$hiveTableName</value>\n           </property>\n        \n           <property>\n               <name>hiveDataFolder</name>\n               <value>$hiveDataFolder</value>\n           </property>\n        \n           <property>\n               <name>hiveOutputFolder</name>\n               <value>$hiveOutputFolder</value>\n           </property>\n        \n           <property>\n               <name>sqlDatabaseConnectionString</name>\n               <value>\";$sqlDatabaseConnectionString\";</value>\n           </property>\n        \n           <property>\n               <name>sqlDatabaseTableName</name>\n               <value>$SQLDatabaseTableName</value>\n           </property>\n        \n           <property>\n               <name>user.name</name>\n               <value>$clusterUsername</value>\n           </property>\n        \n           <property>\n               <name>oozie.wf.application.path</name>\n               <value>$oozieWFPath</value>\n           </property>\n        \n        </configuration>\n        \"@\n        \n4. 将以下内容追加到脚本。此脚本检查 Oozie Web 服务状态。\n            \n        Write-Host \"Checking Oozie server status...\" -ForegroundColor Green\n        $clusterUriStatus = \"https://$clusterName.azurehdinsight.cn:443/oozie/v2/admin/status\"\n        $response = Invoke-RestMethod -Method Get -Uri $clusterUriStatus -Credential $creds -OutVariable $OozieServerStatus \n        \n        $jsonResponse = ConvertFrom-Json (ConvertTo-Json -InputObject $response)\n        $oozieServerSatus = $jsonResponse[0].(\"systemMode\")\n        Write-Host \"Oozie server status is $oozieServerSatus...\"\n    \n5. 将以下内容追加到脚本。这部分创建并启动一项 Oozie 作业：\n\n        # create Oozie job\n        Write-Host \"Sending the following Payload to the cluster:\" -ForegroundColor Green\n        Write-Host \"`n--------`n$OoziePayload`n--------\"\n        $clusterUriCreateJob = \"https://$clusterName.azurehdinsight.cn:443/oozie/v2/jobs\"\n        $response = Invoke-RestMethod -Method Post -Uri $clusterUriCreateJob -Credential $creds -Body $OoziePayload -ContentType \"application/xml\" -OutVariable $OozieJobName #-debug\n    \n        $jsonResponse = ConvertFrom-Json (ConvertTo-Json -InputObject $response)\n        $oozieJobId = $jsonResponse[0].(\"id\")\n        Write-Host \"Oozie job id is $oozieJobId...\"\n    \n        # start Oozie job\n        Write-Host \"Starting the Oozie job $oozieJobId...\" -ForegroundColor Green\n        $clusterUriStartJob = \"https://$clusterName.azurehdinsight.cn:443/oozie/v2/job/\" + $oozieJobId + \"?action=start\"\n        $response = Invoke-RestMethod -Method Put -Uri $clusterUriStartJob -Credential $creds | Format-Table -HideTableHeaders #-debug\n        \n6. 将以下内容追加到脚本。此脚本检查 Oozie 作业状态。\n\n        # get job status\n        Write-Host \"Sleeping for $waitTimeBetweenOozieJobStatusCheck seconds until the job metadata is populated in the Oozie metastore...\" -ForegroundColor Green\n        Start-Sleep -Seconds $waitTimeBetweenOozieJobStatusCheck\n    \n        Write-Host \"Getting job status and waiting for the job to complete...\" -ForegroundColor Green\n        $clusterUriGetJobStatus = \"https://$clusterName.azurehdinsight.cn:443/oozie/v2/job/\" + $oozieJobId + \"?show=info\"\n        $response = Invoke-RestMethod -Method Get -Uri $clusterUriGetJobStatus -Credential $creds \n        $jsonResponse = ConvertFrom-Json (ConvertTo-Json -InputObject $response)\n        $JobStatus = $jsonResponse[0].(\"status\")\n    \n        while($JobStatus -notmatch \"SUCCEEDED|KILLED\")\n        {\n            Write-Host \"$(Get-Date -format 'G'): $oozieJobId is in $JobStatus state...waiting $waitTimeBetweenOozieJobStatusCheck seconds for the job to complete...\"\n            Start-Sleep -Seconds $waitTimeBetweenOozieJobStatusCheck\n            $response = Invoke-RestMethod -Method Get -Uri $clusterUriGetJobStatus -Credential $creds \n            $jsonResponse = ConvertFrom-Json (ConvertTo-Json -InputObject $response)\n            $JobStatus = $jsonResponse[0].(\"status\")\n        }\n    \n        Write-Host \"$(Get-Date -format 'G'): $oozieJobId is in $JobStatus state!\" -ForegroundColor Green\n\n7. 如果你的 HDinsight 群集是 2.1 版的，请将“https://$clusterName.azurehdinsight.cn:443/oozie/v2/”替换为“https://$clusterName.azurehdinsight.cn:443/oozie/v1/”。HDInsight 群集版本 2.1 不支持 Web 服务的版本 2。\n\n8. 单击“运行脚本”或按 **F5** 键以运行该脚本。输出将类似于下面：\n\n    ![教程运行工作流输出][img-runworkflow-output]\n\n8. 连接到 Azure SQL 数据库以查看导出的数据。\n\n**检查作业错误日志**\n\n若要对工作流进行故障排除，可从群集头节点找到 Oozie 日志文件，位置是 *C:\\\\apps\\\\dist\\\\oozie-3.3.2.1.3.2.0-05\\\\oozie-win-distro\\\\logs\\\\Oozie.log* 或 *C:\\\\apps\\\\dist\\\\oozie-4.0.0.2.0.7.0-1528\\\\oozie-win-distro\\\\logs\\\\Oozie.log*。有关 RDP 的信息，请参阅[在 HDInsight 中使用 Azure 管理门户管理 Hadoop 群集][hdinsight-admin-portal]。\n\n**重新运行教程**\n\n若要重新运行该工作流，必须删除以下内容：\n\n- Hive 脚本输出文件\n- log4jLogsCount 表中的数据\n\n这是你可以使用的一个示例 Windows PowerShell 脚本：\n\n    $storageAccountName = \"<AzureStorageAccountName>\"\n    $containerName = \"<ContainerName>\"\n    \n    #SQL database variables\n    $sqlDatabaseServer = \"<SQLDatabaseServerName>\"\n    $sqlDatabaseLogin = \"<SQLDatabaseLoginName>\"\n    $sqlDatabaseLoginPassword = \"<SQLDatabaseLoginPassword>\"\n    $sqlDatabaseName = \"<SQLDatabaseName>\"\n    $sqlDatabaseTableName = \"log4jLogsCount\"\n    \n    Write-host \"Delete the Hive script output file ...\" -ForegroundColor Green\n    $storageaccountkey = get-azurestoragekey $storageAccountName | %{$_.Primary}\n    $destContext = New-AzureStorageContext -Environment AzureChinaCloud -StorageAccountName $storageAccountName -StorageAccountKey $storageaccountkey\n    Remove-AzureStorageBlob -Context $destContext -Blob \"tutorials/useoozie/output/000000_0\" -Container $containerName\n    \n    Write-host \"Delete all the records from the log4jLogsCount table ...\" -ForegroundColor Green\n    $conn = New-Object System.Data.SqlClient.SqlConnection\n    $conn.ConnectionString = \"Data Source=$sqlDatabaseServer.database.chinacloudapi.cn;Initial Catalog=$sqlDatabaseName;User ID=$sqlDatabaseLogin;Password=$sqlDatabaseLoginPassword;Encrypt=true;Trusted_Connection=false;\"\n    $conn.open()\n    $cmd = New-Object System.Data.SqlClient.SqlCommand\n    $cmd.connection = $conn\n    $cmd.commandtext = \"delete from $sqlDatabaseTableName\"\n    $cmd.executenonquery()\n    \n    $conn.close()\n\n\n##后续步骤\n在本教程中，你已经学习了如何定义 Oozie 工作流，以及如何使用 Windows PowerShell 运行 Oozie 作业。若要了解更多信息，请参阅下列文章：\n\n- [将基于时间的 Oozie 协调器与 HDInsight 配合使用][hdinsight-oozie-coordinator-time]\n- [将 Hadoop 与 HDInsight 中的 Hive 配合使用以分析手机使用情况][hdinsight-get-started]\n- [HDInsight Emulator 入门][hdinsight-get-started-emulator]\n- [将 Azure Blob 存储与 HDInsight 配合使用][hdinsight-storage]\n- [使用 PowerShell 管理 HDInsight][hdinsight-admin-powershell]\n- [在 HDInsight 中上载 Hadoop 作业的数据][hdinsight-upload-data]\n- [将 Sqoop 与 HDInsight 中的 Hadoop 配合使用][hdinsight-use-sqoop]\n- [将 Hive 与 HDInsight 上的 Hadoop 配合使用][hdinsight-use-hive]\n- [将 Pig 与 HDInsight 上的 Hadoop 配合使用][hdinsight-use-pig]\n- [为 HDInsight 开发 C# Hadoop 流作业][hdinsight-develop-streaming-jobs]\n- [为 HDInsight 开发 Java MapReduce 程序][hdinsight-develop-mapreduce]\n\n\n[hdinsight-cmdlets-download]: http://go.microsoft.com/fwlink/?LinkID=325563\n\n\n\n\n[hdinsight-oozie-coordinator-time]: /documentation/articles/hdinsight-use-oozie-coordinator-time/\n[hdinsight-versions]: /documentation/articles/hdinsight-component-versioning-v1/\n[hdinsight-storage]: /documentation/articles/hdinsight-hadoop-use-blob-storage/\n[hdinsight-get-started]: /documentation/articles/hdinsight-hadoop-tutorial-get-started-windows-v1/\n[hdinsight-admin-portal]: /documentation/articles/hdinsight-administer-use-management-portal-v1/\n\n\n[hdinsight-use-sqoop]: /documentation/articles/hdinsight-use-sqoop/\n[hdinsight-provision]: /documentation/articles/hdinsight-provision-clusters-v1/\n[hdinsight-admin-powershell]: /documentation/articles/hdinsight-administer-use-powershell/\n[hdinsight-upload-data]: /documentation/articles/hdinsight-upload-data/\n[hdinsight-use-mapreduce]: /documentation/articles/hdinsight-use-mapreduce/\n[hdinsight-use-hive]: /documentation/articles/hdinsight-use-hive/\n[hdinsight-use-pig]: /documentation/articles/hdinsight-use-pig/\n[hdinsight-storage]: /documentation/articles/hdinsight-hadoop-use-blob-storage/\n[hdinsight-get-started-emulator]: /documentation/articles/hdinsight-hadoop-emulator-get-started/\n\n[hdinsight-develop-streaming-jobs]: /documentation/articles/hdinsight-hadoop-develop-deploy-streaming-jobs/\n[hdinsight-develop-mapreduce]: /documentation/articles/hdinsight-develop-deploy-java-mapreduce/\n\n[sqldatabase-create-configue]: /documentation/articles/sql-database-get-started/\n[sqldatabase-get-started]: /documentation/articles/sql-database-get-started/\n\n[azure-management-portal]: https://manage.windowsazure.cn/\n[azure-create-storageaccount]: /documentation/articles/storage-create-storage-account/\n\n[apache-hadoop]: http://hadoop.apache.org/\n[apache-oozie-400]: http://oozie.apache.org/docs/4.0.0/\n[apache-oozie-332]: http://oozie.apache.org/docs/3.3.2/\n\n[powershell-download]: /zh-cn/downloads/#cmd-line-tools\n[powershell-about-profiles]: https://technet.microsoft.com/zh-cn/library/hh847857.aspx\n[powershell-install-configure]: /documentation/articles/powershell-install-configure\n[powershell-start]: http://technet.microsoft.com/zh-cn/library/hh847889.aspx\n[powershell-script]: https://technet.microsoft.com/library/dn425048.aspx\n\n[cindygross-hive-tables]: http://blogs.msdn.com/b/cindygross/archive/2013/02/06/hdinsight-hive-internal-and-external-tables-intro.aspx\n\n[img-workflow-diagram]: ./media/hdinsight-use-oozie/HDI.UseOozie.Workflow.Diagram.png\n[img-preparation-output]: ./media/hdinsight-use-oozie/HDI.UseOozie.Preparation.Output1.png\n[img-runworkflow-output]: ./media/hdinsight-use-oozie/HDI.UseOozie.RunWF.Output.png\n\n[technetwiki-hive-error]: http://social.technet.microsoft.com/wiki/contents/articles/23047.hdinsight-hive-error-unable-to-rename.aspx\n\n<!---HONumber=Mooncake_0104_2016-->"
}