{
  "nodes": [
    {
      "content": "优化 Hive 查询以便在 HDInsight 中更快地执行 | Azure",
      "pos": [
        26,
        64
      ]
    },
    {
      "content": "了解如何在 HDInsight 中优化 Hive 查询",
      "pos": [
        82,
        109
      ]
    },
    {
      "content": "在 Hdinsight 中优化 Hadoop 的 Hive 查询",
      "pos": [
        315,
        347
      ]
    },
    {
      "content": "默认情况下，不会为了性能而优化 Hadoop 群集。本文介绍可对查询应用的几种最常见 Hive 性能优化方法。",
      "pos": [
        349,
        404
      ]
    },
    {
      "content": "向外缩放辅助节点",
      "pos": [
        408,
        416
      ]
    },
    {
      "content": "增加群集中的辅助节点数目，即可利用更多并行运行的映射器和化简器。在 HDInsight 中，可通过两种方式增加扩大的数目：",
      "pos": [
        418,
        479
      ]
    },
    {
      "pos": [
        483,
        648
      ],
      "content": "在预配时，可以使用 Azure 门户、Azure PowerShell 或跨平台命令行界面指定辅助节点的数目。有关详细信息，请参阅<bpt id=\"p1\">[</bpt>设置 HDInsight 群集<ept id=\"p1\">](/documentation/articles/hdinsight-provision-clusters-v1)</ept>。以下屏幕显示了 Azure 门户上的辅助节点配置："
    },
    {
      "content": "scaleout\\_1",
      "pos": [
        656,
        667
      ]
    },
    {
      "content": "在运行时，你也可以向外缩放群集，而无需重建群集。如下所示。",
      "pos": [
        707,
        736
      ]
    },
    {
      "content": "scaleout\\_1",
      "pos": [
        738,
        749
      ]
    },
    {
      "pos": [
        788,
        867
      ],
      "content": "有关 HDInsight 支持的不同虚拟机的详细信息，请参阅 <bpt id=\"p1\">[</bpt>HDInsight 定价<ept id=\"p1\">](/home/features/hdinsight/#price)</ept>。"
    },
    {
      "content": "启用 Tez",
      "pos": [
        871,
        877
      ]
    },
    {
      "pos": [
        879,
        950
      ],
      "content": "<bpt id=\"p1\">[</bpt>Apache Tez<ept id=\"p1\">](http://hortonworks.com/hadoop/tez/)</ept> 是 MapReduce 引擎的替代执行引擎："
    },
    {
      "content": "tez_1",
      "pos": [
        954,
        959
      ]
    },
    {
      "content": "Tez 速度更快，因为：",
      "pos": [
        994,
        1006
      ]
    },
    {
      "content": "在 MapReduce 引擎中以单个作业执行定向无圈图 (DAG)，表达的 DAG 要求每组映射器后接一组化简器。这会导致针对每个 Hive 查询运行多个 MapReduce 作业。Tez 没有这种局限性，它可以将复杂的 DAG 作为一个作业进行处理，因此将作业启动开销降到最低。",
      "pos": [
        1010,
        1150
      ]
    },
    {
      "pos": [
        1153,
        1270
      ],
      "content": "<bpt id=\"p1\">**</bpt>避免不必要的写入<ept id=\"p1\">**</ept>。由于要为 MapReduce 引擎的同一 Hive 查询运行多个作业，每个作业的输出将写入 HDFS 以用作暂存数据。而 Tez 最大程度地减少了对每个 Hive 查询运行的作业数，因此能够避免不必要的写入。"
    },
    {
      "pos": [
        1273,
        1335
      ],
      "content": "<bpt id=\"p1\">**</bpt>最大程度地降低启动延迟<ept id=\"p1\">**</ept>。Tez 可以减少需要启动的映射器数目，同时还能提高优化吞吐量，因此，更有利于最小化启动延迟。"
    },
    {
      "pos": [
        1338,
        1383
      ],
      "content": "<bpt id=\"p1\">**</bpt>重复使用容器<ept id=\"p1\">**</ept>。Tez 会尽可能地重复使用容器，以确保降低由于启动容器而产生的延迟。"
    },
    {
      "pos": [
        1386,
        1476
      ],
      "content": "<bpt id=\"p1\">**</bpt>连续优化技术<ept id=\"p1\">**</ept>。传统上，优化是在编译阶段完成的。但是，这可以提供有关输入的详细信息，以便在运行时更好地进行优化。Tez 使用连续优化技术，从而可以在运行时阶段进一步优化计划。"
    },
    {
      "pos": [
        1478,
        1533
      ],
      "content": "有关这些概念的详细信息，请单击<bpt id=\"p1\">[</bpt>此处<ept id=\"p1\">](http://hortonworks.com/hadoop/tez/)</ept>"
    },
    {
      "content": "你可以通过在查询的前面加上以下设置作为前缀，来执行 Tez 支持的任何 Hive 查询：",
      "pos": [
        1535,
        1579
      ]
    },
    {
      "content": "必须在预配时启用 Tez。以下 Azure PowerShell 脚本示例用于预配已启用 Tez 的 Hadoop 群集：",
      "pos": [
        1617,
        1678
      ]
    },
    {
      "content": "Hive 分区",
      "pos": [
        3057,
        3064
      ]
    },
    {
      "content": "I/O 操作是运行 Hive 查询的主要性能瓶颈。如果可以减少需要读取的数据量，即可改善性能。默认情况下，Hive 查询扫描整个 Hive 表。对于表扫描之类的查询，这非常有利；但是，对于只需扫描少量数据的查询（例如，使用筛选进行查询），这会产生不必要的开销。使用 Hive 分区，Hive 查询只需访问 Hive 表中必要的数据量。",
      "pos": [
        3066,
        3233
      ]
    },
    {
      "pos": [
        3235,
        3325
      ],
      "content": "Hive 分区的实现方法是将未经处理的数据刷新成新的目录，而每个分区区都有自己的目录 - 其中的分区由用户定义。下图说明如何根据<bpt id=\"p1\">*</bpt>年<ept id=\"p1\">*</ept>列来分区 Hive 表。每年都会创建新的目录。"
    },
    {
      "content": "partitioning",
      "pos": [
        3329,
        3341
      ]
    },
    {
      "content": "一些分区注意事项：",
      "pos": [
        3384,
        3393
      ]
    },
    {
      "pos": [
        3397,
        3473
      ],
      "content": "<bpt id=\"p1\">**</bpt>不要分区不足<ept id=\"p1\">**</ept> - 根据包含少量值的列进行分区可能会导致创建很少的分区。例如，根据性别（男性和女性）分区只会创建两个分区，最多只会将延迟降低一半。"
    },
    {
      "pos": [
        3477,
        3571
      ],
      "content": "<bpt id=\"p1\">**</bpt>不要过度分区<ept id=\"p1\">**</ept> - 另一种极端是，根据包含唯一值（例如 userid）的列进行分区会导致创建多个分区，从而给群集命名节点带来很大的压力，因为它必须处理大量的目录。这是另一种极端做法。"
    },
    {
      "pos": [
        3575,
        3663
      ],
      "content": "<bpt id=\"p1\">**</bpt>避免数据偏斜<ept id=\"p1\">**</ept> - 明智选择分区键，以便所有分区的大小均等。例如，根据<bpt id=\"p2\">*</bpt>州<ept id=\"p2\">*</ept>分区可能会导致“加利福尼亚州”的记录数几乎是“佛蒙特州”的 30 倍，因为两个州的人口有差异。"
    },
    {
      "pos": [
        3665,
        3697
      ],
      "content": "若要创建分区表，请使用 <bpt id=\"p1\">*</bpt>Partitioned By<ept id=\"p1\">*</ept> 子句："
    },
    {
      "content": "创建分区表后，可以创建静态分区或动态分区。",
      "pos": [
        4202,
        4223
      ]
    },
    {
      "pos": [
        4227,
        4288
      ],
      "content": "<bpt id=\"p1\">**</bpt>静态分区<ept id=\"p1\">**</ept>表示已在相应目录中创建了分片数据，你可以请求根据目录位置在 Hive 中手动分区。以下代码段对此做了演示。"
    },
    {
      "pos": [
        4673,
        4741
      ],
      "content": "<bpt id=\"p1\">**</bpt>动态分区<ept id=\"p1\">**</ept>表示你希望 Hive 自动为你创建分区。由于我们已经基于暂存表创建了分区表，我们需要做的就是将数据插入分区表，如下所示："
    },
    {
      "pos": [
        5479,
        5602
      ],
      "content": "有关更多详细信息，请参阅<bpt id=\"p1\">[</bpt>分区表<ept id=\"p1\">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-PartitionedTables)</ept>。"
    },
    {
      "content": "使用 ORCFile 格式",
      "pos": [
        5606,
        5619
      ]
    },
    {
      "content": "Hive 支持不同的文件格式。例如：",
      "pos": [
        5621,
        5639
      ]
    },
    {
      "pos": [
        5643,
        5668
      ],
      "content": "<bpt id=\"p1\">**</bpt>文本<ept id=\"p1\">**</ept>：这是默认的文件格式，适用于大多数情况"
    },
    {
      "pos": [
        5671,
        5689
      ],
      "content": "<bpt id=\"p1\">**</bpt>Avro<ept id=\"p1\">**</ept>：非常适合互操作方案"
    },
    {
      "pos": [
        5692,
        5717
      ],
      "content": "<bpt id=\"p1\">**</bpt>ORC/Parquet<ept id=\"p1\">**</ept>：最适合用于提高性能"
    },
    {
      "content": "ORC（优化行纵栏式）格式是存储 Hive 数据的高效方式。与其他格式相比，ORC 具有以下优点：",
      "pos": [
        5719,
        5768
      ]
    },
    {
      "content": "支持复杂类型（包括 DateTime）和复杂的半结构化类型",
      "pos": [
        5772,
        5801
      ]
    },
    {
      "content": "高达 70% 的压缩率",
      "pos": [
        5804,
        5815
      ]
    },
    {
      "content": "每隔 10,000 行编制索引一次并允许跳过行",
      "pos": [
        5818,
        5841
      ]
    },
    {
      "content": "大幅减少运行时执行时间",
      "pos": [
        5844,
        5855
      ]
    },
    {
      "pos": [
        5857,
        5898
      ],
      "content": "若要启用 ORC 格式，请先使用 <bpt id=\"p1\">*</bpt>Stored as ORC<ept id=\"p1\">*</ept> 子句创建一个表："
    },
    {
      "content": "接下来，从暂存表向 ORC 表插入数据。例如：",
      "pos": [
        6348,
        6371
      ]
    },
    {
      "pos": [
        7048,
        7140
      ],
      "content": "可在<bpt id=\"p1\">[</bpt>此处<ept id=\"p1\">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC)</ept>阅读有关 ORC 格式的详细信息。"
    },
    {
      "content": "向量化",
      "pos": [
        7144,
        7147
      ]
    },
    {
      "content": "向量化可让 Hive 以批的形式同时处理 1024 行，而不是一次处理一行。这意味着，简单的操作可以更快地完成，因为需要运行的内部代码更少。",
      "pos": [
        7149,
        7219
      ]
    },
    {
      "content": "若要启用向量化，请在 Hive 查询的前面加上以下设置作为前缀：",
      "pos": [
        7221,
        7253
      ]
    },
    {
      "pos": [
        7306,
        7403
      ],
      "content": "有关详细信息，请参阅<bpt id=\"p1\">[</bpt>向量化查询执行<ept id=\"p1\">](https://cwiki.apache.org/confluence/display/Hive/Vectorized+Query+Execution)</ept>。"
    },
    {
      "content": "其他优化方法",
      "pos": [
        7408,
        7414
      ]
    },
    {
      "content": "你还可以考虑使用其他一些高级优化方法，例如：",
      "pos": [
        7416,
        7438
      ]
    },
    {
      "pos": [
        7442,
        7477
      ],
      "content": "<bpt id=\"p1\">**</bpt>Hive 装桶：<ept id=\"p1\">**</ept>将大型数据集群集化或分段以优化查询性能的技术。"
    },
    {
      "pos": [
        7480,
        7670
      ],
      "content": "<bpt id=\"p1\">**</bpt>联接优化：<ept id=\"p1\">**</ept>Hive 的查询执行计划优化，可改善联接的效率并减少用户提示的需要。有关详细信息，请参阅<bpt id=\"p2\">[</bpt>联接优化<ept id=\"p2\">](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+JoinOptimization#LanguageManualJoinOptimization-JoinOptimization)</ept>。"
    },
    {
      "content": "增加化简器",
      "pos": [
        7675,
        7680
      ]
    },
    {
      "content": "<ph id=\"ph1\">&lt;a id=\"nextsteps\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>后续步骤",
      "pos": [
        7686,
        7712
      ]
    },
    {
      "content": "在本文中，你已学习了几种常见的 Hive 查询优化方法。若要了解更多信息，请参阅下列文章：",
      "pos": [
        7713,
        7758
      ]
    },
    {
      "content": "使用 HDInsight 中的 Hive 分析航班延误数据",
      "pos": [
        7763,
        7792
      ]
    },
    {
      "content": "使用 HDInsight 中 Hadoop上的 Hive 查询控制台分析传感器数据",
      "pos": [
        7858,
        7899
      ]
    }
  ],
  "content": "<properties\n   pageTitle=\"优化 Hive 查询以便在 HDInsight 中更快地执行 | Azure\"\n   description=\"了解如何在 HDInsight 中优化 Hive 查询\"\n   services=\"hdinsight\"\n   documentationCenter=\"\"\n   authors=\"rashimg\"\n   manager=\"mwinkle\"\n   editor=\"cgronlun\"/>\n\n<tags\n   ms.service=\"hdinsight\"\n   ms.date=\"07/28/2015\"\n   wacn.date=\"01/15/2016\"/>\n\n\n# 在 Hdinsight 中优化 Hadoop 的 Hive 查询\n\n默认情况下，不会为了性能而优化 Hadoop 群集。本文介绍可对查询应用的几种最常见 Hive 性能优化方法。\n\n##向外缩放辅助节点\n\n增加群集中的辅助节点数目，即可利用更多并行运行的映射器和化简器。在 HDInsight 中，可通过两种方式增加扩大的数目：\n\n- 在预配时，可以使用 Azure 门户、Azure PowerShell 或跨平台命令行界面指定辅助节点的数目。有关详细信息，请参阅[设置 HDInsight 群集](/documentation/articles/hdinsight-provision-clusters-v1)。以下屏幕显示了 Azure 门户上的辅助节点配置：\n\n    ![scaleout\\_1][image-hdi-optimize-hive-scaleout_1]\n- 在运行时，你也可以向外缩放群集，而无需重建群集。如下所示。![scaleout\\_1][image-hdi-optimize-hive-scaleout_2]\n\n有关 HDInsight 支持的不同虚拟机的详细信息，请参阅 [HDInsight 定价](/home/features/hdinsight/#price)。\n\n##启用 Tez\n\n[Apache Tez](http://hortonworks.com/hadoop/tez/) 是 MapReduce 引擎的替代执行引擎：\n\n![tez_1][image-hdi-optimize-hive-tez_1]\n\n\nTez 速度更快，因为：\n\n- 在 MapReduce 引擎中以单个作业执行定向无圈图 (DAG)，表达的 DAG 要求每组映射器后接一组化简器。这会导致针对每个 Hive 查询运行多个 MapReduce 作业。Tez 没有这种局限性，它可以将复杂的 DAG 作为一个作业进行处理，因此将作业启动开销降到最低。\n- **避免不必要的写入**。由于要为 MapReduce 引擎的同一 Hive 查询运行多个作业，每个作业的输出将写入 HDFS 以用作暂存数据。而 Tez 最大程度地减少了对每个 Hive 查询运行的作业数，因此能够避免不必要的写入。\n- **最大程度地降低启动延迟**。Tez 可以减少需要启动的映射器数目，同时还能提高优化吞吐量，因此，更有利于最小化启动延迟。\n- **重复使用容器**。Tez 会尽可能地重复使用容器，以确保降低由于启动容器而产生的延迟。\n- **连续优化技术**。传统上，优化是在编译阶段完成的。但是，这可以提供有关输入的详细信息，以便在运行时更好地进行优化。Tez 使用连续优化技术，从而可以在运行时阶段进一步优化计划。\n\n有关这些概念的详细信息，请单击[此处](http://hortonworks.com/hadoop/tez/)\n\n你可以通过在查询的前面加上以下设置作为前缀，来执行 Tez 支持的任何 Hive 查询：\n\n    set hive.execution.engine=tez;\n\n必须在预配时启用 Tez。以下 Azure PowerShell 脚本示例用于预配已启用 Tez 的 Hadoop 群集：\n\n\n    $clusterName = \"[HDInsightClusterName]\"\n    $location = \"[AzureDataCenter]\" #i.e. China North\n    $dataNodes = 32 # number of worker nodes in the cluster\n\n    $defaultStorageAccountName = \"[DefaultStorageAccountName]\"\n    $defaultStorageContainerName = \"[DefaultBlobContainerName]\"\n    $defaultStorageAccountKey = $defaultStorageAccountKey = Get-AzureStorageKey $defaultStorageAccountName.ToLower() | %{ $_.Primary }\n\n    $hdiUserName = \"[HTTPUserName]\"\n    $hdiPassword = \"[HTTPUserPassword]\"\n\n    $hdiSecurePassword = ConvertTo-SecureString $hdiPassword -AsPlainText -Force\n    $hdiCredential = New-Object System.Management.Automation.PSCredential($hdiUserName, $hdiSecurePassword)\n\n    $hiveConfig = new-object 'Microsoft.WindowsAzure.Management.HDInsight.Cmdlet.DataObjects.AzureHDInsightHiveConfiguration'\n    $hiveConfig.Configuration = @{ \"hive.execution.engine\"=\"tez\" }\n\n    New-AzureHDInsightClusterConfig -ClusterSizeInNodes $dataNodes -HeadNodeVMSize Standard_D14 -DataNodeVMSize Standard_D14 |\n    Set-AzureHDInsightDefaultStorage -StorageAccountName \"$defaultStorageAccountName.blob.core.chinacloudapi.cn\" -StorageAccountKey $defaultStorageAccountKey -StorageContainerName $defaultStorageContainerName |\n    Add-AzureHDInsightConfigValues -Hive $hiveConfig |\n    New-AzureHDInsightCluster -Name $clusterName -Location $location -Credential $hdiCredential\n\n## Hive 分区\n\nI/O 操作是运行 Hive 查询的主要性能瓶颈。如果可以减少需要读取的数据量，即可改善性能。默认情况下，Hive 查询扫描整个 Hive 表。对于表扫描之类的查询，这非常有利；但是，对于只需扫描少量数据的查询（例如，使用筛选进行查询），这会产生不必要的开销。使用 Hive 分区，Hive 查询只需访问 Hive 表中必要的数据量。\n\nHive 分区的实现方法是将未经处理的数据刷新成新的目录，而每个分区区都有自己的目录 - 其中的分区由用户定义。下图说明如何根据*年*列来分区 Hive 表。每年都会创建新的目录。\n\n![partitioning][image-hdi-optimize-hive-partitioning_1]\n\n一些分区注意事项：\n\n- **不要分区不足** - 根据包含少量值的列进行分区可能会导致创建很少的分区。例如，根据性别（男性和女性）分区只会创建两个分区，最多只会将延迟降低一半。\n\n- **不要过度分区** - 另一种极端是，根据包含唯一值（例如 userid）的列进行分区会导致创建多个分区，从而给群集命名节点带来很大的压力，因为它必须处理大量的目录。这是另一种极端做法。\n\n- **避免数据偏斜** - 明智选择分区键，以便所有分区的大小均等。例如，根据*州*分区可能会导致“加利福尼亚州”的记录数几乎是“佛蒙特州”的 30 倍，因为两个州的人口有差异。\n\n若要创建分区表，请使用 *Partitioned By* 子句：\n\n    CREATE TABLE lineitem_part\n        (L_ORDERKEY INT, L_PARTKEY INT, L_SUPPKEY INT,L_LINENUMBER INT,\n         L_QUANTITY DOUBLE, L_EXTENDEDPRICE DOUBLE, L_DISCOUNT DOUBLE,\n         L_TAX DOUBLE, L_RETURNFLAG STRING, L_LINESTATUS STRING,\n         L_SHIPDATE_PS STRING, L_COMMITDATE STRING, L_RECEIPTDATE        STRING, L_SHIPINSTRUCT STRING, L_SHIPMODE STRING,\n         L_COMMENT STRING)\n    PARTITIONED BY(L_SHIPDATE STRING)\n    ROW FORMAT DELIMITED FIELDS TERMINATED BY '\\t'\n    STORED AS TEXTFILE;\n\n创建分区表后，可以创建静态分区或动态分区。\n\n- **静态分区**表示已在相应目录中创建了分片数据，你可以请求根据目录位置在 Hive 中手动分区。以下代码段对此做了演示。\n\n        INSERT OVERWRITE TABLE lineitem_part\n        PARTITION (L_SHIPDATE = ‘5/23/1996 12:00:00 AM’)\n        SELECT * FROM lineitem \n        WHERE lineitem.L_SHIPDATE = ‘5/23/1996 12:00:00 AM’\n\n        ALTER TABLE lineitem_part ADD PARTITION (L_SHIPDATE = ‘5/23/1996 12:00:00 AM’))\n        LOCATION ‘wasb://sampledata@ignitedemo.blob.core.chinacloudapi.cn/partitions/5_23_1996/'\n\n- **动态分区**表示你希望 Hive 自动为你创建分区。由于我们已经基于暂存表创建了分区表，我们需要做的就是将数据插入分区表，如下所示：\n\n        SET hive.exec.dynamic.partition = true;\n        SET hive.exec.dynamic.partition.mode = nonstrict;\n        INSERT INTO TABLE lineitem_part\n        PARTITION (L_SHIPDATE)\n        SELECT L_ORDERKEY as L_ORDERKEY, L_PARTKEY as L_PARTKEY , \n             L_SUPPKEY as L_SUPPKEY, L_LINENUMBER as L_LINENUMBER,\n             L_QUANTITY as L_QUANTITY, L_EXTENDEDPRICE as L_EXTENDEDPRICE,\n             L_DISCOUNT as L_DISCOUNT, L_TAX as L_TAX, L_RETURNFLAG as       L_RETURNFLAG, L_LINESTATUS as L_LINESTATUS, L_SHIPDATE as       L_SHIPDATE_PS, L_COMMITDATE as L_COMMITDATE, L_RECEIPTDATE as   L_RECEIPTDATE, L_SHIPINSTRUCT as L_SHIPINSTRUCT, L_SHIPMODE as      L_SHIPMODE, L_COMMENT as L_COMMENT, L_SHIPDATE as L_SHIPDATE FROM lineitem;\n\n有关更多详细信息，请参阅[分区表](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-PartitionedTables)。\n\n##使用 ORCFile 格式\n\nHive 支持不同的文件格式。例如：\n\n- **文本**：这是默认的文件格式，适用于大多数情况\n- **Avro**：非常适合互操作方案\n- **ORC/Parquet**：最适合用于提高性能\n\nORC（优化行纵栏式）格式是存储 Hive 数据的高效方式。与其他格式相比，ORC 具有以下优点：\n\n- 支持复杂类型（包括 DateTime）和复杂的半结构化类型\n- 高达 70% 的压缩率\n- 每隔 10,000 行编制索引一次并允许跳过行\n- 大幅减少运行时执行时间\n\n若要启用 ORC 格式，请先使用 *Stored as ORC* 子句创建一个表：\n\n    CREATE TABLE lineitem_orc_part\n        (L_ORDERKEY INT, L_PARTKEY INT,L_SUPPKEY INT, L_LINENUMBER INT,\n         L_QUANTITY DOUBLE, L_EXTENDEDPRICE DOUBLE, L_DISCOUNT DOUBLE,\n         L_TAX DOUBLE, L_RETURNFLAG STRING, L_LINESTATUS STRING,\n         L_SHIPDATE_PS STRING, L_COMMITDATE STRING, L_RECEIPTDATE STRING,\n         L_SHIPINSTRUCT STRING, L_SHIPMODE STRING, L_COMMENT     STRING)\n    PARTITIONED BY(L_SHIPDATE STRING)\n    STORED AS ORC;\n\n接下来，从暂存表向 ORC 表插入数据。例如：\n\n    INSERT INTO TABLE lineitem_orc\n    SELECT L_ORDERKEY as L_ORDERKEY, \n           L_PARTKEY as L_PARTKEY , \n           L_SUPPKEY as L_SUPPKEY,\n           L_LINENUMBER as L_LINENUMBER,\n           L_QUANTITY as L_QUANTITY, \n           L_EXTENDEDPRICE as L_EXTENDEDPRICE,\n           L_DISCOUNT as L_DISCOUNT,\n           L_TAX as L_TAX,\n           L_RETURNFLAG as L_RETURNFLAG,\n           L_LINESTATUS as L_LINESTATUS,\n           L_SHIPDATE as L_SHIPDATE,\n           L_COMMITDATE as L_COMMITDATE,\n           L_RECEIPTDATE as L_RECEIPTDATE, \n           L_SHIPINSTRUCT as L_SHIPINSTRUCT,\n           L_SHIPMODE as L_SHIPMODE,\n           L_COMMENT as L_COMMENT\n    FROM lineitem;\n\n可在[此处](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+ORC)阅读有关 ORC 格式的详细信息。\n\n##向量化\n\n向量化可让 Hive 以批的形式同时处理 1024 行，而不是一次处理一行。这意味着，简单的操作可以更快地完成，因为需要运行的内部代码更少。\n\n若要启用向量化，请在 Hive 查询的前面加上以下设置作为前缀：\n\n    set hive.vectorized.execution.enabled = true;\n\n有关详细信息，请参阅[向量化查询执行](https://cwiki.apache.org/confluence/display/Hive/Vectorized+Query+Execution)。\n\n\n##其他优化方法\n\n你还可以考虑使用其他一些高级优化方法，例如：\n\n- **Hive 装桶：**将大型数据集群集化或分段以优化查询性能的技术。\n- **联接优化：**Hive 的查询执行计划优化，可改善联接的效率并减少用户提示的需要。有关详细信息，请参阅[联接优化](https://cwiki.apache.org/confluence/display/Hive/LanguageManual+JoinOptimization#LanguageManualJoinOptimization-JoinOptimization)。\n- **增加化简器**\n\n##<a id=\"nextsteps\"></a>后续步骤\n在本文中，你已学习了几种常见的 Hive 查询优化方法。若要了解更多信息，请参阅下列文章：\n\n- [使用 HDInsight 中的 Hive 分析航班延误数据](/documentation/articles/hdinsight-analyze-flight-delay-data)\n- [使用 HDInsight 中 Hadoop上的 Hive 查询控制台分析传感器数据](/documentation/articles/hdinsight-hive-analyze-sensor-data)\n\n\n[image-hdi-optimize-hive-scaleout_1]: ./media/hdinsight-hadoop-optimize-hive-query-v1/scaleout_1.png\n[image-hdi-optimize-hive-scaleout_2]: ./media/hdinsight-hadoop-optimize-hive-query-v1/scaleout_2.png\n[image-hdi-optimize-hive-tez_1]: ./media/hdinsight-hadoop-optimize-hive-query-v1/tez_1.png\n[image-hdi-optimize-hive-partitioning_1]: ./media/hdinsight-hadoop-optimize-hive-query-v1/partitioning_1.png\n\n<!---HONumber=71-->"
}