{
  "nodes": [
    {
      "content": "使用 HDInsight 进行脚本操作开发 | Azure",
      "pos": [
        27,
        56
      ]
    },
    {
      "content": "了解如何使用脚本操作自定义 Hadoop 群集。",
      "pos": [
        75,
        99
      ]
    },
    {
      "content": "为 HDInsight 开发脚本操作脚本",
      "pos": [
        336,
        356
      ]
    },
    {
      "pos": [
        358,
        490
      ],
      "content": "了解如何为 HDInsight 编写脚本操作脚本。有关如何使用脚本操作脚本的信息，请参阅<bpt id=\"p1\">[</bpt>使用脚本操作自定义 HDInsight 群集<ept id=\"p1\">](/documentation/articles/hdinsight-hadoop-customize-cluster-v1)</ept>。"
    },
    {
      "content": "脚本操作可用于安装运行在 Hadoop 群集上的其他软件，或更改安装在群集上的应用程序的配置。脚本操作是在部署 HDInsight 群集时运行在群集节点上的脚本，这些脚本在群集中的节点完成 HDInsight 配置后执行。脚本操作根据系统管理员帐户权限执行，提供对群集节点的完全访问权限。每个群集可能都提供有要按指定顺序执行的脚本操作的列表。",
      "pos": [
        492,
        663
      ]
    },
    {
      "pos": [
        667,
        691
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>如果你遇到以下错误消息："
    },
    {
      "pos": [
        694,
        1118
      ],
      "content": "<p>`System.Management.Automation.CommandNotFoundException; ExceptionMessage : The term 'Save-HDIFile' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was included, verify that the path is correct and try again.`\n<p>这是因为你没有包括帮助器方法。请参阅[自定义脚本的帮助器方法](/documentation/articles/hdinsight-hadoop-script-actions#helper-methods-for-custom-scripts)。",
      "leadings": [
        "",
        "> "
      ],
      "nodes": [
        {
          "content": "这是因为你没有包括帮助器方法。请参阅<bpt id=\"p1\">[</bpt><ept id=\"p1\">自定义脚本的帮助器方法](/documentation/articles/hdinsight-hadoop-script-actions#helper-methods-for-custom-scripts)</ept>。",
          "pos": [
            299,
            422
          ]
        }
      ]
    },
    {
      "content": "示例脚本",
      "pos": [
        1123,
        1127
      ]
    },
    {
      "content": "在 Windows 操作系统上预配 HDInsight 群集时，脚本操作为 Azure PowerShell 脚本。以下是有关配置站点配置文件的示例脚本：",
      "pos": [
        1129,
        1206
      ]
    },
    {
      "content": "该脚本采用四个参数，即配置文件名称、要修改的属性、要设置的值以及说明。例如：",
      "pos": [
        2705,
        2743
      ]
    },
    {
      "content": "这些参数会在 hive-site.xml 文件中将 hive.metastore.client.socket.timeout 值设置为 90。默认值为 60 秒。",
      "pos": [
        2805,
        2886
      ]
    },
    {
      "pos": [
        2888,
        3069
      ],
      "content": "也可以在 <bpt id=\"p1\">[</bpt>https://hditutorialdata.blob.core.windows.net/customizecluster/editSiteConfig.ps1<ept id=\"p1\">](https://hditutorialdata.blob.core.windows.net/customizecluster/editSiteConfig.ps1)</ept> 上找到该示例脚本。"
    },
    {
      "content": "HDInsight 提供了多个脚本用于在 HDInsight 群集上安装附加组件：",
      "pos": [
        3071,
        3112
      ]
    },
    {
      "content": "Name",
      "pos": [
        3114,
        3118
      ]
    },
    {
      "content": "脚本",
      "pos": [
        3121,
        3123
      ]
    },
    {
      "content": "安装 R",
      "pos": [
        3140,
        3144
      ]
    },
    {
      "pos": [
        3149,
        3282
      ],
      "content": "https://hdiconfigactions.blob.core.windows.net/rconfigactionv02/r-installer-v02.ps1。请参阅<bpt id=\"p1\">[</bpt>在 HDInsight 群集上安装并使用 R<ept id=\"p1\">][hdinsight-r-scripts]</ept>。"
    },
    {
      "content": "安装 Solr",
      "pos": [
        3285,
        3292
      ]
    },
    {
      "pos": [
        3297,
        3476
      ],
      "content": "https://hdiconfigactions.blob.core.windows.net/solrconfigactionv01/solr-installer-v01.ps1。请参阅<bpt id=\"p1\">[</bpt>在 HDInsight 群集上安装并使用 Solr<ept id=\"p1\">](/documentation/articles/hdinsight-hadoop-solr-install-v1)</ept>。"
    },
    {
      "pos": [
        3477,
        3492
      ],
      "content": "- <bpt id=\"p1\">**</bpt>安装 Giraph<ept id=\"p1\">**</ept>"
    },
    {
      "pos": [
        3495,
        3682
      ],
      "content": "https://hdiconfigactions.blob.core.windows.net/giraphconfigactionv01/giraph-installer-v01.ps1。请参阅<bpt id=\"p1\">[</bpt>在 HDInsight 群集上安装并使用 Giraph<ept id=\"p1\">](/documentation/articles/hdinsight-hadoop-giraph-install-v1)</ept>。"
    },
    {
      "pos": [
        3684,
        3810
      ],
      "content": "脚本操作可以通过 Azure 管理门户、Azure PowerShell 或 HDInsight .NET SDK 来部署。有关详细信息，请参阅<bpt id=\"p1\">[</bpt>使用脚本操作自定义 HDInsight 群集<ept id=\"p1\">][hdinsight-cluster-customize]</ept>。"
    },
    {
      "pos": [
        3814,
        3961
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>示例脚本仅适用于 HDInsight 群集 3.1 或更高版本。有关 HDInsight 群集版本的详细信息，请参阅 <bpt id=\"p1\">[</bpt>HDInsight 群集版本<ept id=\"p1\">](/documentation/articles/hdinsight-component-versioning-v1)</ept>。"
    },
    {
      "pos": [
        3969,
        4029
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"helper-methods-for-custom-scripts\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph> 自定义脚本的帮助器方法"
    },
    {
      "pos": [
        4031,
        4284
      ],
      "content": "脚本操作帮助器方法是可以在编写自定义脚本时使用的实用工具。这些方法在 <bpt id=\"p1\">[</bpt>https://hdiconfigactions.blob.core.windows.net/configactionmodulev05/HDInsightUtilities-v05.psm1<ept id=\"p1\">](https://hdiconfigactions.blob.core.windows.net/configactionmodulev05/HDInsightUtilities-v05.psm1)</ept> 中定义，可以使用以下语法包括在你的脚本中："
    },
    {
      "content": "以下是通过此脚本提供的帮助器方法：",
      "pos": [
        4965,
        4982
      ]
    },
    {
      "content": "帮助器方法",
      "pos": [
        4984,
        4989
      ]
    },
    {
      "content": "说明",
      "pos": [
        4992,
        4994
      ]
    },
    {
      "content": "Save-HDIFile",
      "pos": [
        5026,
        5038
      ]
    },
    {
      "content": "将文件从指定的统一资源标识符 (URI) 下载到本地磁盘上与分配到群集的 Azure VM 节点关联的位置。",
      "pos": [
        5043,
        5097
      ]
    },
    {
      "content": "Expand-HDIZippedFile",
      "pos": [
        5100,
        5120
      ]
    },
    {
      "content": "解压缩已压缩的文件。",
      "pos": [
        5125,
        5135
      ]
    },
    {
      "content": "Invoke-HDICmdScript",
      "pos": [
        5138,
        5157
      ]
    },
    {
      "content": "从 cmd.exe 运行脚本。",
      "pos": [
        5162,
        5177
      ]
    },
    {
      "content": "Write-HDILog",
      "pos": [
        5180,
        5192
      ]
    },
    {
      "content": "从用于脚本操作的自定义脚本编写输出。",
      "pos": [
        5197,
        5215
      ]
    },
    {
      "content": "Get-Services",
      "pos": [
        5218,
        5230
      ]
    },
    {
      "content": "获取在执行脚本的计算机上运行的服务的列表。",
      "pos": [
        5235,
        5256
      ]
    },
    {
      "content": "Get-Service",
      "pos": [
        5259,
        5270
      ]
    },
    {
      "content": "在特定服务名称作为输入的情况下，获取执行脚本的计算机上的特定服务的详细信息（服务名称、进程 ID、状态等）。",
      "pos": [
        5275,
        5329
      ]
    },
    {
      "content": "Get-HDIServices",
      "pos": [
        5332,
        5347
      ]
    },
    {
      "content": "获取执行脚本的计算机上运行的 HDInsight 服务的列表。",
      "pos": [
        5352,
        5383
      ]
    },
    {
      "content": "Get-HDIService",
      "pos": [
        5386,
        5400
      ]
    },
    {
      "content": "在特定 HDInsight 服务名称作为输入的情况下，获取执行脚本的计算机上的特定服务的详细信息（服务名称、进程 ID、状态等）。",
      "pos": [
        5405,
        5470
      ]
    },
    {
      "content": "Get-ServicesRunning",
      "pos": [
        5473,
        5492
      ]
    },
    {
      "content": "获取执行脚本的计算机上运行的服务的列表。",
      "pos": [
        5497,
        5517
      ]
    },
    {
      "content": "Get-ServiceRunning",
      "pos": [
        5520,
        5538
      ]
    },
    {
      "content": "检查特定服务（按名称）是否在执行脚本的计算机上运行。",
      "pos": [
        5543,
        5569
      ]
    },
    {
      "content": "Get-HDIServicesRunning",
      "pos": [
        5572,
        5594
      ]
    },
    {
      "content": "获取执行脚本的计算机上运行的 HDInsight 服务的列表。",
      "pos": [
        5599,
        5630
      ]
    },
    {
      "content": "Get-HDIServiceRunning",
      "pos": [
        5633,
        5654
      ]
    },
    {
      "content": "检查特定 HDInsight 服务（按名称）是否在执行脚本的计算机上运行。",
      "pos": [
        5659,
        5696
      ]
    },
    {
      "content": "Get-HDIHadoopVersion",
      "pos": [
        5699,
        5719
      ]
    },
    {
      "content": "获取在执行脚本的计算机上安装的 Hadoop 的版本。",
      "pos": [
        5724,
        5751
      ]
    },
    {
      "content": "Test-IsHDIHeadNode",
      "pos": [
        5754,
        5772
      ]
    },
    {
      "content": "检查执行脚本的计算机是否为头节点。",
      "pos": [
        5777,
        5794
      ]
    },
    {
      "content": "Test-IsActiveHDIHeadNode",
      "pos": [
        5797,
        5821
      ]
    },
    {
      "content": "检查执行脚本的计算机是否为活动头节点。",
      "pos": [
        5826,
        5845
      ]
    },
    {
      "content": "Test-IsHDIDataNode",
      "pos": [
        5848,
        5866
      ]
    },
    {
      "content": "检查执行脚本的计算机是否为数据节点。",
      "pos": [
        5871,
        5889
      ]
    },
    {
      "content": "Edit-HDIConfigFile",
      "pos": [
        5892,
        5910
      ]
    },
    {
      "content": "编辑配置文件 hive-site.xml、core-site.xml、hdfs-site.xml、mapred-site.xml 或 yarn-site.xml。",
      "pos": [
        5915,
        5996
      ]
    },
    {
      "content": "脚本开发最佳做法",
      "pos": [
        6002,
        6010
      ]
    },
    {
      "content": "在针对 HDInsight 群集开发自定义脚本时，有些最佳做法要铭记于心：",
      "pos": [
        6012,
        6049
      ]
    },
    {
      "content": "检查 Hadoop 版本",
      "pos": [
        6053,
        6065
      ]
    },
    {
      "pos": [
        6071,
        6202
      ],
      "content": "只有 HDInsight 3.1 (Hadoop 2.4) 及其更高版本才支持使用脚本操作在群集上安装自定义组件。在自定义脚本中，你必须使用 <bpt id=\"p1\">**</bpt>Get-HDIHadoopVersion<ept id=\"p1\">**</ept> 帮助器方法检查 Hadoop 版本，然后才能继续在脚本中执行其他任务。"
    },
    {
      "content": "提供指向脚本资源的可靠链接",
      "pos": [
        6207,
        6220
      ]
    },
    {
      "content": "用户应确保自定义群集过程中使用的所有脚本和其他项目在群集的整个生存期内都必须一直可用，并且这些文件的版本在此期间也不会发生更改。如果需要为群集中的节点重新制作映像，则需要用到这些资源。最佳做法是，下载用户控制的存储帐户中的所有内容并将其存档。这可能是默认存储帐户，也可能是在部署自定义群集时指定的其他任何存储帐户。例如，在文档提供的 R 自定义群集示例中，我们已为此存储帐户中的资源创建了本地副本：https://hdiconfigactions.blob.core.windows.net/。",
      "pos": [
        6226,
        6473
      ]
    },
    {
      "content": "确保群集自定义脚本是幂等的",
      "pos": [
        6478,
        6491
      ]
    },
    {
      "content": "你必须预期在群集的生存期内将对 HDInsight 群集的节点重新制作映像。只要对群集重新制作映像，就会运行群集自定义脚本。在某种意义上讲，此脚本必须设计为幂等的，即重新制作映像时，该脚本应确保将群集返回到在初次创建群集时首次运行脚本后所处的相同自定义状态。例如，如果自定义脚本在其首次运行时在 D:\\\\AppLocation 上安装了应用程序，则在随后每次运行时，重新制作映像后，该脚本应检查应用程序是否在 D:\\\\AppLocation 位置存在，然后才能继续在该脚本中执行其他步骤。",
      "pos": [
        6497,
        6741
      ]
    },
    {
      "content": "在最佳位置安装自定义组件",
      "pos": [
        6746,
        6758
      ]
    },
    {
      "content": "在对群集节点重新制作映像时，可以对 C:\\\\ 资源驱动器和 D:\\\\ 系统驱动器重新格式化，这会导致已安装在这些驱动器上的数据和应用程序丢失。如果群集中的 Azure 虚拟机 (VM) 节点发生故障，被新节点所取代，则也会发生这种情况。你可以在 D:\\\\ 驱动器上安装组件，也可以在群集上的 C:\\\\apps 位置中进行安装。C:\\\\ 驱动器上的其他所有位置都将保留。指定要使用群集自定义脚本将应用程序或库安装到的位置。",
      "pos": [
        6764,
        6974
      ]
    },
    {
      "content": "确保群集体系结构的高可用性",
      "pos": [
        6979,
        6992
      ]
    },
    {
      "content": "HDInsight 具有实现高可用性的主-被体系结构，在该结构中，一个头节点处于主动模式（HDInsight 服务正在运行），而另一头节点处于备用模式（HDInsight 服务未在运行）。如果 HDInsight 服务中断，则节点会在主动和被动模式之间切换。如果使用脚本操作在两个头节点上安装服务以实现高可用性，请注意，HDInsight 故障转移机制无法对这些用户安装的服务执行自动故障转移。因此，用户在 HDInsight 头节点上安装的服务如果预期具有高可用性，则必须具有自己的故障转移机制，无论是在主-被模式还是在主-主模式下。",
      "pos": [
        6998,
        7266
      ]
    },
    {
      "pos": [
        7272,
        7549
      ],
      "content": "如果将头节点角色指定为 <bpt id=\"p1\">*</bpt>ClusterRoleCollection<ept id=\"p1\">*</ept> 参数（记录在下面的<bpt id=\"p2\">[</bpt>如何运行脚本操作<ept id=\"p2\">](#runScriptAction)</ept>部分中）中的值，则 HDInsight 脚本操作命令会在两个头节点上运行。因此，设计自定义脚本时，请确保你的脚本知道此设置。如果在两个头节点上安装并启动相同服务，并且这两个服务以相互争用结束，则你不会遇到问题。另请注意，数据将在重新制作映像期间丢失，因此，通过脚本操作安装的软件必须能够灵活应对此类事件。应用程序应设计使用分布在很多节点上的高可用数据。请注意，有 1/5 之多的群集节点可以同时重新制作映像。"
    },
    {
      "content": "配置自定义组件以使用 Azure Blob 存储",
      "pos": [
        7554,
        7578
      ]
    },
    {
      "content": "你在群集节点上安装的自定义组件可能具有使用 Hadoop 分布式文件系统 (HDFS) 存储的默认配置。你应该更改该配置以改用 Azure Blob 存储。在对群集重新制作映像时，HDFS 文件系统将会进行格式化，因此，你可能会丢失存储在此处的所有数据。改用 Azure Blob 存储可确保将保留你的数据。",
      "pos": [
        7584,
        7738
      ]
    },
    {
      "content": "常见使用模式",
      "pos": [
        7743,
        7749
      ]
    },
    {
      "content": "本部分提供有关实现你在编写自己的自定义脚本时可能遇到的一些常见使用模式的指导。",
      "pos": [
        7751,
        7790
      ]
    },
    {
      "content": "配置环境变量",
      "pos": [
        7796,
        7802
      ]
    },
    {
      "content": "通常，在脚本操作开发中，你将需要设置环境变量。例如，最可能的情况是，从外部站点下载二进制文件，将其安装在群集上，并将其安装位置添加到你的“PATH”环境变量。以下代码段向你介绍如何在自定义脚本中设置环境变量。",
      "pos": [
        7804,
        7908
      ]
    },
    {
      "pos": [
        8076,
        8202
      ],
      "content": "此语句将环境变量 <bpt id=\"p1\">**</bpt>MDS\\_RUNNER\\_CUSTOM\\_CLUSTER<ept id=\"p1\">**</ept> 设置为值“true”，同时将此变量的作用域设置为计算机范围。有时，在相应的作用域（计算机或用户）内设置环境变量很重要。有关设置环境变量的详细信息，请参考<bpt id=\"p2\">[</bpt>此处<ept id=\"p2\">][1]</ept>。"
    },
    {
      "content": "访问存储自定义脚本的位置",
      "pos": [
        8208,
        8220
      ]
    },
    {
      "content": "用于自定义群集的脚本需要位于群集的默认存储帐户中，或其他任何存储帐户的公共只读容器中。如果你的脚本访问位于其他位置的资源，则这些资源需要具有公共可访问性（至少是公共只读性）。例如，你可能需要访问文件，并使用 SaveFile-HDI 命令保存该文件。",
      "pos": [
        8222,
        8347
      ]
    },
    {
      "content": "在此示例中，你必须确保存储帐户“somestorageaccount”中的容器“somecontainer”可公开访问。否则，该脚本将引发“未找到”异常并失败。",
      "pos": [
        8547,
        8627
      ]
    },
    {
      "content": "将参数传递给 Add-AzureHDInsightScriptAction cmdlet",
      "pos": [
        8633,
        8677
      ]
    },
    {
      "content": "若要将多个参数传递给 Add-AzureHDInsightScriptAction cmdlet，你需要将字符串值的格式设置为包含脚本的所有参数。例如：",
      "pos": [
        8679,
        8755
      ]
    },
    {
      "content": "或",
      "pos": [
        8852,
        8853
      ]
    },
    {
      "content": "群集部署失败引发异常",
      "pos": [
        8969,
        8979
      ]
    },
    {
      "content": "如果要获取群集自定义未按预期成功执行的正确通知，则必须引发异常，并且群集设置失败。例如，你可能需要处理文件（如果存在），并应对文件不存在的错误情况。这将确保脚本正确存在，并且群集的状态也已知正确。以下代码段提供如何实现此目标的示例：",
      "pos": [
        8981,
        9097
      ]
    },
    {
      "content": "在此代码段中，如果文件不存在，则会导致脚本在列显错误消息后实际正常退出的状态，而群集将进入运行中状态（前提是它“成功”完成了群集自定义进程）。如果你要准确知道群集自定义操作由于缺少文件而未按预期成功完成，就更适合引发异常并使群集自定义步骤失败。若要达到这个目的，你必须改用以下示例代码段。",
      "pos": [
        9272,
        9416
      ]
    },
    {
      "content": "有关部署脚本操作的清单",
      "pos": [
        9596,
        9607
      ]
    },
    {
      "content": "下面是我们在准备部署这些脚本时执行的步骤：",
      "pos": [
        9608,
        9629
      ]
    },
    {
      "content": "将包含自定义脚本的文件放置在群集节点在部署期间可访问的位置中。这可能是在部署群集时指定的任何默认或其他存储帐户，或任何其他可公共访问的存储容器。",
      "pos": [
        9634,
        9706
      ]
    },
    {
      "content": "向脚本中添加检查，以确保这些脚本可以幂等方式执行，从而使脚本可在同一节点上多次执行。",
      "pos": [
        9710,
        9752
      ]
    },
    {
      "pos": [
        9756,
        9841
      ],
      "content": "使用 <bpt id=\"p1\">**</bpt>Write-Output<ept id=\"p1\">**</ept> Azure PowerShell cmdlet 输出到 STDOUT 以及 STDERR。请勿使用 <bpt id=\"p2\">**</bpt>Write-Host<ept id=\"p2\">**</ept>。"
    },
    {
      "content": "使用临时文件夹，例如 $env:TEMP，来保留脚本使用的下载文件，并在执行脚本后将其清除。",
      "pos": [
        9845,
        9891
      ]
    },
    {
      "content": "仅在 D:\\\\ 或 C:\\\\apps 上安装自定义软件。不应使用 C: 驱动器上的其他位置，因为这些位置已保留。请注意，在 C: 驱动器上 C:\\\\apps 文件夹外安装文件可能会导致在对节点重新制作映像时设置失败。",
      "pos": [
        9895,
        10003
      ]
    },
    {
      "content": "如果 OS 级设置或 Hadoop 服务配置文件发生更改，则你可能需要重新启动 HDInsight 服务，使其可以选取任何 OS 级设置，例如脚本中设置的环境变量。",
      "pos": [
        10007,
        10089
      ]
    },
    {
      "content": "使用 HDInsight 模拟器测试自定义脚本",
      "pos": [
        10096,
        10119
      ]
    },
    {
      "content": "若要在 HDInsight 脚本操作命令中使用自定义脚本前对其进行测试，一个直截了当的方法是在 HDInsight 模拟器上运行它。你可以在本地或 Azure 基础结构即服务 (IaaS) Windows Server 2012 R2 VM 或本地计算机上安装 HDInsight 模拟器，并观察脚本的行为是否正确。请注意，Windows Server 2012 R2 VM 是 HDInsight 用于其节点的相同 VM。",
      "pos": [
        10121,
        10333
      ]
    },
    {
      "content": "本部分概述在本地使用 HDInsight 模拟器进行测试的过程，但是使用 VM 的过程类似。",
      "pos": [
        10335,
        10381
      ]
    },
    {
      "pos": [
        10383,
        10538
      ],
      "content": "<bpt id=\"p1\">**</bpt>安装 HDInsight 模拟器<ept id=\"p1\">**</ept> - 若要在本地运行脚本操作，你必须安装有 HDInsight 模拟器。有关如何安装该模拟器的说明，请参阅 <bpt id=\"p2\">[</bpt>HDInsight 模拟器入门<ept id=\"p2\">](/documentation/articles/hdinsight-hadoop-emulator-get-started)</ept>。"
    },
    {
      "pos": [
        10540,
        10650
      ],
      "content": "<bpt id=\"p1\">**</bpt>设置 Azure PowerShell 的执行策略<ept id=\"p1\">**</ept> - 打开 Azure PowerShell 并运行（以管理员身份）以下命令，以将执行策略设置为 <bpt id=\"p2\">*</bpt>LocalMachine<ept id=\"p2\">*</ept> 和 <bpt id=\"p3\">*</bpt>Unrestricted<ept id=\"p3\">*</ept>："
    },
    {
      "content": "我们要求此策略不受限制，因为脚本未签名。",
      "pos": [
        10710,
        10730
      ]
    },
    {
      "pos": [
        10732,
        10774
      ],
      "content": "<bpt id=\"p1\">**</bpt>下载脚本操作<ept id=\"p1\">**</ept>，你要将该脚本操作运行到本地目标。以下示例脚本可从以下位置下载："
    },
    {
      "pos": [
        10778,
        10867
      ],
      "content": "<bpt id=\"p1\">**</bpt>R<ept id=\"p1\">**</ept>。https://hdiconfigactions.blob.core.windows.net/rconfigactionv02/r-installer-v02.ps1"
    },
    {
      "pos": [
        10870,
        10968
      ],
      "content": "<bpt id=\"p1\">**</bpt>Solr<ept id=\"p1\">**</ept>。https://hdiconfigactions.blob.core.windows.net/solrconfigactionv01/solr-installer-v01.ps1"
    },
    {
      "pos": [
        10971,
        11075
      ],
      "content": "<bpt id=\"p1\">**</bpt>Giraph<ept id=\"p1\">**</ept>。https://hdiconfigactions.blob.core.windows.net/giraphconfigactionv01/giraph-installer-v01.ps1"
    },
    {
      "pos": [
        11077,
        11145
      ],
      "content": "<bpt id=\"p1\">**</bpt>运行脚本操作<ept id=\"p1\">**</ept> - 在管理员模式下打开新的 Azure PowerShell 窗口，并从保存 R 安装脚本的本地位置运行这些脚本。"
    },
    {
      "content": "用法示例",
      "pos": [
        11149,
        11153
      ]
    },
    {
      "content": "当你使用 R 群集时，所需的数据文件可能不存在于 HDInsight 模拟器中。因此，你可能需要将包含数据的相关 .txt 文件上载到 HDFS 中的路径，然后使用该路径访问数据。例如：",
      "pos": [
        11158,
        11251
      ]
    },
    {
      "content": "val file = sc.textFile(\"/example/data/gutenberg/davinci.txt\")",
      "pos": [
        11257,
        11318
      ]
    },
    {
      "content": "请注意，在某些情况下，自定义脚本实际上可能依赖于 HDInsight 组件，例如检测某些 Hadoop 服务是否启动。在这种情况下，你将需要在实际的 HDInsight 群集上部署自定义脚本以对其进行测试。",
      "pos": [
        11321,
        11424
      ]
    },
    {
      "pos": [
        11429,
        11467
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"runScriptAction\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph> 调试自定义脚本"
    },
    {
      "pos": [
        11469,
        11838
      ],
      "content": "脚本错误日志随同其他输出一起存储在创建群集时为该群集指定的默认存储帐户中。这些日志存储在名为 <bpt id=\"p1\">*</bpt>u&lt;\\\\cluster-name-fragment&gt;&lt;\\\\time-stamp&gt;setuplog<ept id=\"p1\">*</ept> 的表中。这些是包含所有节点（头节点和从节点）中的记录的聚合日志，脚本在群集中的这些节点上运行。若要查看日志，一个简单方法是使用 HDInsight Tools for Visual Studio。若要安装这些工具，请参阅<bpt id=\"p2\">[</bpt>开始使用适用于 HDInsight 的 Visual Studio Hadoop 工具<ept id=\"p2\">](/documentation/articles/hdinsight-hadoop-visual-studio-tools-get-started#install-hdinsight-tools-for-visual-studio)</ept>"
    },
    {
      "content": "使用 Visual Studio 查看日志的步骤",
      "pos": [
        11842,
        11866
      ]
    },
    {
      "content": "打开 Visual Studio。",
      "pos": [
        11873,
        11890
      ]
    },
    {
      "content": "单击“视图”，然后单击“服务器资源管理器”。",
      "pos": [
        11894,
        11916
      ]
    },
    {
      "content": "右键单击“Azure”，单击“连接到 Azure 订阅”，然后输入你的凭据。",
      "pos": [
        11920,
        11958
      ]
    },
    {
      "content": "依次展开“存储”、用作默认文件系统的 Azure 存储帐户、“表”，然后双击表名。",
      "pos": [
        11962,
        12003
      ]
    },
    {
      "pos": [
        12006,
        12135
      ],
      "content": "你还可以远程连接到群集节点，以查看 STDOUT 和 STDERR 中的自定义脚本。每个节点上的日志仅特定于该节点，并记录到 <bpt id=\"p1\">**</bpt>C:\\\\HDInsightLogs\\\\DeploymentAgent.log<ept id=\"p1\">**</ept> 中。这些日志文件会记录自定义脚本中的所有输出。"
    },
    {
      "content": "如果执行失败，则描述该情况的输出也将包含在此日志文件中。这些日志中提供的信息应该对调试可能出现的脚本问题有所帮助。",
      "pos": [
        12137,
        12194
      ]
    },
    {
      "content": "另请参阅",
      "pos": [
        12200,
        12204
      ]
    },
    {
      "content": "使用脚本操作自定义 HDInsight 群集",
      "pos": [
        12209,
        12231
      ]
    },
    {
      "content": "在 HDInsight 群集上安装并使用 R",
      "pos": [
        12265,
        12287
      ]
    },
    {
      "content": "在 HDInsight 群集上安装并使用 Solr",
      "pos": [
        12313,
        12338
      ]
    },
    {
      "content": "在 HDInsight 群集上安装并使用 Giraph",
      "pos": [
        12401,
        12428
      ]
    }
  ],
  "content": "<properties\n    pageTitle=\"使用 HDInsight 进行脚本操作开发 | Azure\"\n    description=\"了解如何使用脚本操作自定义 Hadoop 群集。\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    tags=\"azure-portal\"\n    authors=\"mumian\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.date=\"11/09/2015\"\n    wacn.date=\"01/15/2016\"/>\n\n# 为 HDInsight 开发脚本操作脚本\n\n了解如何为 HDInsight 编写脚本操作脚本。有关如何使用脚本操作脚本的信息，请参阅[使用脚本操作自定义 HDInsight 群集](/documentation/articles/hdinsight-hadoop-customize-cluster-v1)。\n\n脚本操作可用于安装运行在 Hadoop 群集上的其他软件，或更改安装在群集上的应用程序的配置。脚本操作是在部署 HDInsight 群集时运行在群集节点上的脚本，这些脚本在群集中的节点完成 HDInsight 配置后执行。脚本操作根据系统管理员帐户权限执行，提供对群集节点的完全访问权限。每个群集可能都提供有要按指定顺序执行的脚本操作的列表。\n\n> [AZURE.NOTE]如果你遇到以下错误消息：\n> <p>`System.Management.Automation.CommandNotFoundException; ExceptionMessage : The term 'Save-HDIFile' is not recognized as the name of a cmdlet, function, script file, or operable program. Check the spelling of the name, or if a path was included, verify that the path is correct and try again.`\n> <p>这是因为你没有包括帮助器方法。请参阅[自定义脚本的帮助器方法](/documentation/articles/hdinsight-hadoop-script-actions#helper-methods-for-custom-scripts)。\n\n## 示例脚本\n\n在 Windows 操作系统上预配 HDInsight 群集时，脚本操作为 Azure PowerShell 脚本。以下是有关配置站点配置文件的示例脚本：\n\n    param (\n        [parameter(Mandatory)][string] $ConfigFileName,\n        [parameter(Mandatory)][string] $Name,\n        [parameter(Mandatory)][string] $Value,\n        [parameter()][string] $Description\n    )\n\n    if (!$Description) {\n        $Description = \"\"\n    }\n\n    $hdiConfigFiles = @{\n        \"hive-site.xml\" = \"$env:HIVE_HOME\\conf\\hive-site.xml\";\n        \"core-site.xml\" = \"$env:HADOOP_HOME\\etc\\hadoop\\core-site.xml\";\n        \"hdfs-site.xml\" = \"$env:HADOOP_HOME\\etc\\hadoop\\hdfs-site.xml\";\n        \"mapred-site.xml\" = \"$env:HADOOP_HOME\\etc\\hadoop\\mapred-site.xml\";\n        \"yarn-site.xml\" = \"$env:HADOOP_HOME\\etc\\hadoop\\yarn-site.xml\"\n    }\n\n    if (!($hdiConfigFiles[$ConfigFileName])) {\n        Write-HDILog \"Unable to configure $ConfigFileName because it is not part of the HDI configuration files.\"\n        return\n    }\n\n    [xml]$configFile = Get-Content $hdiConfigFiles[$ConfigFileName]\n\n    $existingproperty = $configFile.configuration.property | where {$_.Name -eq $Name}\n\n    if ($existingproperty) {\n        $existingproperty.Value = $Value\n        $existingproperty.Description = $Description\n    } else {\n        $newproperty = @($configFile.configuration.property)[0].Clone()\n        $newproperty.Name = $Name\n        $newproperty.Value = $Value\n        $newproperty.Description = $Description\n        $configFile.configuration.AppendChild($newproperty)\n    }\n\n    $configFile.Save($hdiConfigFiles[$ConfigFileName])\n\n    Write-HDILog \"$configFileName has been configured.\"\n\n该脚本采用四个参数，即配置文件名称、要修改的属性、要设置的值以及说明。例如：\n\n    hive-site.xml hive.metastore.client.socket.timeout 90 \n\n这些参数会在 hive-site.xml 文件中将 hive.metastore.client.socket.timeout 值设置为 90。默认值为 60 秒。\n\n也可以在 [https://hditutorialdata.blob.core.windows.net/customizecluster/editSiteConfig.ps1](https://hditutorialdata.blob.core.windows.net/customizecluster/editSiteConfig.ps1) 上找到该示例脚本。\n\nHDInsight 提供了多个脚本用于在 HDInsight 群集上安装附加组件：\n\nName | 脚本\n----- | -----\n**安装 R** | https://hdiconfigactions.blob.core.windows.net/rconfigactionv02/r-installer-v02.ps1。请参阅[在 HDInsight 群集上安装并使用 R][hdinsight-r-scripts]。\n**安装 Solr** | https://hdiconfigactions.blob.core.windows.net/solrconfigactionv01/solr-installer-v01.ps1。请参阅[在 HDInsight 群集上安装并使用 Solr](/documentation/articles/hdinsight-hadoop-solr-install-v1)。\n- **安装 Giraph** | https://hdiconfigactions.blob.core.windows.net/giraphconfigactionv01/giraph-installer-v01.ps1。请参阅[在 HDInsight 群集上安装并使用 Giraph](/documentation/articles/hdinsight-hadoop-giraph-install-v1)。\n\n脚本操作可以通过 Azure 管理门户、Azure PowerShell 或 HDInsight .NET SDK 来部署。有关详细信息，请参阅[使用脚本操作自定义 HDInsight 群集][hdinsight-cluster-customize]。\n\n> [AZURE.NOTE]示例脚本仅适用于 HDInsight 群集 3.1 或更高版本。有关 HDInsight 群集版本的详细信息，请参阅 [HDInsight 群集版本](/documentation/articles/hdinsight-component-versioning-v1)。\n\n\n\n\n\n##<a name=\"helper-methods-for-custom-scripts\"></a> 自定义脚本的帮助器方法\n\n脚本操作帮助器方法是可以在编写自定义脚本时使用的实用工具。这些方法在 [https://hdiconfigactions.blob.core.windows.net/configactionmodulev05/HDInsightUtilities-v05.psm1](https://hdiconfigactions.blob.core.windows.net/configactionmodulev05/HDInsightUtilities-v05.psm1) 中定义，可以使用以下语法包括在你的脚本中：\n\n    # Download config action module from a well-known directory.\n    $CONFIGACTIONURI = \"https://hdiconfigactions.blob.core.windows.net/configactionmodulev05/HDInsightUtilities-v05.psm1\";\n    $CONFIGACTIONMODULE = \"C:\\apps\\dist\\HDInsightUtilities.psm1\";\n    $webclient = New-Object System.Net.WebClient;\n    $webclient.DownloadFile($CONFIGACTIONURI, $CONFIGACTIONMODULE);\n    \n    # (TIP) Import config action helper method module to make writing config action easy.\n    if (Test-Path ($CONFIGACTIONMODULE))\n    { \n        Import-Module $CONFIGACTIONMODULE;\n    } \n    else\n    {\n        Write-Output \"Failed to load HDInsightUtilities module, exiting ...\";\n        exit;\n    }\n\n以下是通过此脚本提供的帮助器方法：\n\n帮助器方法 | 说明\n-------------- | -----------\n**Save-HDIFile** | 将文件从指定的统一资源标识符 (URI) 下载到本地磁盘上与分配到群集的 Azure VM 节点关联的位置。\n**Expand-HDIZippedFile** | 解压缩已压缩的文件。\n**Invoke-HDICmdScript** | 从 cmd.exe 运行脚本。\n**Write-HDILog** | 从用于脚本操作的自定义脚本编写输出。\n**Get-Services** | 获取在执行脚本的计算机上运行的服务的列表。\n**Get-Service** | 在特定服务名称作为输入的情况下，获取执行脚本的计算机上的特定服务的详细信息（服务名称、进程 ID、状态等）。\n**Get-HDIServices** | 获取执行脚本的计算机上运行的 HDInsight 服务的列表。\n**Get-HDIService** | 在特定 HDInsight 服务名称作为输入的情况下，获取执行脚本的计算机上的特定服务的详细信息（服务名称、进程 ID、状态等）。\n**Get-ServicesRunning** | 获取执行脚本的计算机上运行的服务的列表。\n**Get-ServiceRunning** | 检查特定服务（按名称）是否在执行脚本的计算机上运行。\n**Get-HDIServicesRunning** | 获取执行脚本的计算机上运行的 HDInsight 服务的列表。\n**Get-HDIServiceRunning** | 检查特定 HDInsight 服务（按名称）是否在执行脚本的计算机上运行。\n**Get-HDIHadoopVersion** | 获取在执行脚本的计算机上安装的 Hadoop 的版本。\n**Test-IsHDIHeadNode** | 检查执行脚本的计算机是否为头节点。\n**Test-IsActiveHDIHeadNode** | 检查执行脚本的计算机是否为活动头节点。\n**Test-IsHDIDataNode** | 检查执行脚本的计算机是否为数据节点。\n**Edit-HDIConfigFile** | 编辑配置文件 hive-site.xml、core-site.xml、hdfs-site.xml、mapred-site.xml 或 yarn-site.xml。\n\n\n## 脚本开发最佳做法\n\n在针对 HDInsight 群集开发自定义脚本时，有些最佳做法要铭记于心：\n\n- 检查 Hadoop 版本\n\n    只有 HDInsight 3.1 (Hadoop 2.4) 及其更高版本才支持使用脚本操作在群集上安装自定义组件。在自定义脚本中，你必须使用 **Get-HDIHadoopVersion** 帮助器方法检查 Hadoop 版本，然后才能继续在脚本中执行其他任务。\n\n\n- 提供指向脚本资源的可靠链接\n\n    用户应确保自定义群集过程中使用的所有脚本和其他项目在群集的整个生存期内都必须一直可用，并且这些文件的版本在此期间也不会发生更改。如果需要为群集中的节点重新制作映像，则需要用到这些资源。最佳做法是，下载用户控制的存储帐户中的所有内容并将其存档。这可能是默认存储帐户，也可能是在部署自定义群集时指定的其他任何存储帐户。例如，在文档提供的 R 自定义群集示例中，我们已为此存储帐户中的资源创建了本地副本：https://hdiconfigactions.blob.core.windows.net/。\n\n\n- 确保群集自定义脚本是幂等的\n\n    你必须预期在群集的生存期内将对 HDInsight 群集的节点重新制作映像。只要对群集重新制作映像，就会运行群集自定义脚本。在某种意义上讲，此脚本必须设计为幂等的，即重新制作映像时，该脚本应确保将群集返回到在初次创建群集时首次运行脚本后所处的相同自定义状态。例如，如果自定义脚本在其首次运行时在 D:\\\\AppLocation 上安装了应用程序，则在随后每次运行时，重新制作映像后，该脚本应检查应用程序是否在 D:\\\\AppLocation 位置存在，然后才能继续在该脚本中执行其他步骤。\n\n\n- 在最佳位置安装自定义组件\n\n    在对群集节点重新制作映像时，可以对 C:\\\\ 资源驱动器和 D:\\\\ 系统驱动器重新格式化，这会导致已安装在这些驱动器上的数据和应用程序丢失。如果群集中的 Azure 虚拟机 (VM) 节点发生故障，被新节点所取代，则也会发生这种情况。你可以在 D:\\\\ 驱动器上安装组件，也可以在群集上的 C:\\\\apps 位置中进行安装。C:\\\\ 驱动器上的其他所有位置都将保留。指定要使用群集自定义脚本将应用程序或库安装到的位置。\n\n\n- 确保群集体系结构的高可用性\n\n    HDInsight 具有实现高可用性的主-被体系结构，在该结构中，一个头节点处于主动模式（HDInsight 服务正在运行），而另一头节点处于备用模式（HDInsight 服务未在运行）。如果 HDInsight 服务中断，则节点会在主动和被动模式之间切换。如果使用脚本操作在两个头节点上安装服务以实现高可用性，请注意，HDInsight 故障转移机制无法对这些用户安装的服务执行自动故障转移。因此，用户在 HDInsight 头节点上安装的服务如果预期具有高可用性，则必须具有自己的故障转移机制，无论是在主-被模式还是在主-主模式下。\n\n    如果将头节点角色指定为 *ClusterRoleCollection* 参数（记录在下面的[如何运行脚本操作](#runScriptAction)部分中）中的值，则 HDInsight 脚本操作命令会在两个头节点上运行。因此，设计自定义脚本时，请确保你的脚本知道此设置。如果在两个头节点上安装并启动相同服务，并且这两个服务以相互争用结束，则你不会遇到问题。另请注意，数据将在重新制作映像期间丢失，因此，通过脚本操作安装的软件必须能够灵活应对此类事件。应用程序应设计使用分布在很多节点上的高可用数据。请注意，有 1/5 之多的群集节点可以同时重新制作映像。\n\n\n- 配置自定义组件以使用 Azure Blob 存储\n\n    你在群集节点上安装的自定义组件可能具有使用 Hadoop 分布式文件系统 (HDFS) 存储的默认配置。你应该更改该配置以改用 Azure Blob 存储。在对群集重新制作映像时，HDFS 文件系统将会进行格式化，因此，你可能会丢失存储在此处的所有数据。改用 Azure Blob 存储可确保将保留你的数据。\n\n## 常见使用模式\n\n本部分提供有关实现你在编写自己的自定义脚本时可能遇到的一些常见使用模式的指导。\n\n### 配置环境变量\n\n通常，在脚本操作开发中，你将需要设置环境变量。例如，最可能的情况是，从外部站点下载二进制文件，将其安装在群集上，并将其安装位置添加到你的“PATH”环境变量。以下代码段向你介绍如何在自定义脚本中设置环境变量。\n\n    Write-HDILog \"Starting environment variable setting at: $(Get-Date)\";\n    [Environment]::SetEnvironmentVariable('MDS_RUNNER_CUSTOM_CLUSTER', 'true', 'Machine');\n\n此语句将环境变量 **MDS\\_RUNNER\\_CUSTOM\\_CLUSTER** 设置为值“true”，同时将此变量的作用域设置为计算机范围。有时，在相应的作用域（计算机或用户）内设置环境变量很重要。有关设置环境变量的详细信息，请参考[此处][1]。\n\n### 访问存储自定义脚本的位置\n\n用于自定义群集的脚本需要位于群集的默认存储帐户中，或其他任何存储帐户的公共只读容器中。如果你的脚本访问位于其他位置的资源，则这些资源需要具有公共可访问性（至少是公共只读性）。例如，你可能需要访问文件，并使用 SaveFile-HDI 命令保存该文件。\n\n    Save-HDIFile -SrcUri 'https://somestorageaccount.blob.core.chinacloudapi.cn/somecontainer/some-file.jar' -DestFile 'C:\\apps\\dist\\hadoop-2.4.0.2.1.9.0-2196\\share\\hadoop\\mapreduce\\some-file.jar'\n\n在此示例中，你必须确保存储帐户“somestorageaccount”中的容器“somecontainer”可公开访问。否则，该脚本将引发“未找到”异常并失败。\n\n### 将参数传递给 Add-AzureHDInsightScriptAction cmdlet\n\n若要将多个参数传递给 Add-AzureHDInsightScriptAction cmdlet，你需要将字符串值的格式设置为包含脚本的所有参数。例如：\n\n    \"-CertifcateUri wasb:///abc.pfx -CertificatePassword 123456 -InstallFolderName MyFolder\"\n \n或\n\n    $parameters = '-Parameters \"{0};{1};{2}\"' -f $CertificateName,$certUriWithSasToken,$CertificatePassword\n\n\n### 群集部署失败引发异常\n\n如果要获取群集自定义未按预期成功执行的正确通知，则必须引发异常，并且群集设置失败。例如，你可能需要处理文件（如果存在），并应对文件不存在的错误情况。这将确保脚本正确存在，并且群集的状态也已知正确。以下代码段提供如何实现此目标的示例：\n\n    If(Test-Path($SomePath)) {\n        #Process file in some way\n    } else {\n        # File does not exist; handle error case\n        # Print error message\n    exit\n    }\n\n在此代码段中，如果文件不存在，则会导致脚本在列显错误消息后实际正常退出的状态，而群集将进入运行中状态（前提是它“成功”完成了群集自定义进程）。如果你要准确知道群集自定义操作由于缺少文件而未按预期成功完成，就更适合引发异常并使群集自定义步骤失败。若要达到这个目的，你必须改用以下示例代码段。\n\n    If(Test-Path($SomePath)) {\n        #Process file in some way\n    } else {\n        # File does not exist; handle error case\n        # Print error message\n    throw\n    }\n\n\n## 有关部署脚本操作的清单\n下面是我们在准备部署这些脚本时执行的步骤：\n\n1. 将包含自定义脚本的文件放置在群集节点在部署期间可访问的位置中。这可能是在部署群集时指定的任何默认或其他存储帐户，或任何其他可公共访问的存储容器。\n2. 向脚本中添加检查，以确保这些脚本可以幂等方式执行，从而使脚本可在同一节点上多次执行。\n3. 使用 **Write-Output** Azure PowerShell cmdlet 输出到 STDOUT 以及 STDERR。请勿使用 **Write-Host**。\n4. 使用临时文件夹，例如 $env:TEMP，来保留脚本使用的下载文件，并在执行脚本后将其清除。\n5. 仅在 D:\\\\ 或 C:\\\\apps 上安装自定义软件。不应使用 C: 驱动器上的其他位置，因为这些位置已保留。请注意，在 C: 驱动器上 C:\\\\apps 文件夹外安装文件可能会导致在对节点重新制作映像时设置失败。\n6. 如果 OS 级设置或 Hadoop 服务配置文件发生更改，则你可能需要重新启动 HDInsight 服务，使其可以选取任何 OS 级设置，例如脚本中设置的环境变量。\n\n\n\n## 使用 HDInsight 模拟器测试自定义脚本\n\n若要在 HDInsight 脚本操作命令中使用自定义脚本前对其进行测试，一个直截了当的方法是在 HDInsight 模拟器上运行它。你可以在本地或 Azure 基础结构即服务 (IaaS) Windows Server 2012 R2 VM 或本地计算机上安装 HDInsight 模拟器，并观察脚本的行为是否正确。请注意，Windows Server 2012 R2 VM 是 HDInsight 用于其节点的相同 VM。\n\n本部分概述在本地使用 HDInsight 模拟器进行测试的过程，但是使用 VM 的过程类似。\n\n**安装 HDInsight 模拟器** - 若要在本地运行脚本操作，你必须安装有 HDInsight 模拟器。有关如何安装该模拟器的说明，请参阅 [HDInsight 模拟器入门](/documentation/articles/hdinsight-hadoop-emulator-get-started)。\n\n**设置 Azure PowerShell 的执行策略** - 打开 Azure PowerShell 并运行（以管理员身份）以下命令，以将执行策略设置为 *LocalMachine* 和 *Unrestricted*：\n\n    Set-ExecutionPolicy Unrestricted –Scope LocalMachine\n\n我们要求此策略不受限制，因为脚本未签名。\n\n**下载脚本操作**，你要将该脚本操作运行到本地目标。以下示例脚本可从以下位置下载：\n\n* **R**。https://hdiconfigactions.blob.core.windows.net/rconfigactionv02/r-installer-v02.ps1\n* **Solr**。https://hdiconfigactions.blob.core.windows.net/solrconfigactionv01/solr-installer-v01.ps1\n* **Giraph**。https://hdiconfigactions.blob.core.windows.net/giraphconfigactionv01/giraph-installer-v01.ps1\n\n**运行脚本操作** - 在管理员模式下打开新的 Azure PowerShell 窗口，并从保存 R 安装脚本的本地位置运行这些脚本。\n\n**用法示例**\n- 当你使用 R 群集时，所需的数据文件可能不存在于 HDInsight 模拟器中。因此，你可能需要将包含数据的相关 .txt 文件上载到 HDFS 中的路径，然后使用该路径访问数据。例如：\n\n    val file = sc.textFile(\"/example/data/gutenberg/davinci.txt\")\n\n\n请注意，在某些情况下，自定义脚本实际上可能依赖于 HDInsight 组件，例如检测某些 Hadoop 服务是否启动。在这种情况下，你将需要在实际的 HDInsight 群集上部署自定义脚本以对其进行测试。\n\n\n##<a name=\"runScriptAction\"></a> 调试自定义脚本\n\n脚本错误日志随同其他输出一起存储在创建群集时为该群集指定的默认存储帐户中。这些日志存储在名为 *u<\\\\cluster-name-fragment><\\\\time-stamp>setuplog* 的表中。这些是包含所有节点（头节点和从节点）中的记录的聚合日志，脚本在群集中的这些节点上运行。若要查看日志，一个简单方法是使用 HDInsight Tools for Visual Studio。若要安装这些工具，请参阅[开始使用适用于 HDInsight 的 Visual Studio Hadoop 工具](/documentation/articles/hdinsight-hadoop-visual-studio-tools-get-started#install-hdinsight-tools-for-visual-studio)\n\n**使用 Visual Studio 查看日志的步骤**\n\n1. 打开 Visual Studio。\n2. 单击“视图”，然后单击“服务器资源管理器”。\n3. 右键单击“Azure”，单击“连接到 Azure 订阅”，然后输入你的凭据。\n4. 依次展开“存储”、用作默认文件系统的 Azure 存储帐户、“表”，然后双击表名。\n\n\n你还可以远程连接到群集节点，以查看 STDOUT 和 STDERR 中的自定义脚本。每个节点上的日志仅特定于该节点，并记录到 **C:\\\\HDInsightLogs\\\\DeploymentAgent.log** 中。这些日志文件会记录自定义脚本中的所有输出。\n\n如果执行失败，则描述该情况的输出也将包含在此日志文件中。这些日志中提供的信息应该对调试可能出现的脚本问题有所帮助。\n\n\n## 另请参阅\n\n- [使用脚本操作自定义 HDInsight 群集][hdinsight-cluster-customize]\n- [在 HDInsight 群集上安装并使用 R][hdinsight-r-scripts]\n- [在 HDInsight 群集上安装并使用 Solr](/documentation/articles/hdinsight-hadoop-solr-install-v1)\n- [在 HDInsight 群集上安装并使用 Giraph](/documentation/articles/hdinsight-hadoop-giraph-install-v1)\n\n[hdinsight-provision]: /documentation/articles/hdinsight-provision-clusters-v1\n[hdinsight-cluster-customize]: /documentation/articles/hdinsight-hadoop-customize-cluster-v1\n[hdinsight-r-scripts]: /documentation/articles/hdinsight-hadoop-r-scripts\n[powershell-install-configure]: /documentation/articles/powershell-install-configure/\n\n<!--Reference links in article-->\n[1]: https://msdn.microsoft.com/zh-cn/library/96xafkes(v=vs.110).aspx\n\n<!---HONumber=Mooncake_1207_2015-->"
}