{
  "nodes": [
    {
      "content": "使用 Apache Storm 接收消息",
      "pos": [
        3,
        23
      ]
    },
    {
      "pos": [
        25,
        266
      ],
      "content": "<bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Apache Storm<ept id=\"p2\">**</ept><ept id=\"p1\">](https://storm.incubator.apache.org)</ept> 是一个分布式实时计算系统，它简化了对未绑定的数据流进行可靠处理的过程。本节演示如何使用事件中心 Storm 喷口从事件中心接收事件。使用 Apache Storm，可以在承载于不同节点的多个进程间拆分事件。事件中心与 Storm 集成后，通过使用风暴的 Zookeeper 安装以透明方式对事件使用进度执行检查点操作、管理持久检查点以及从事件中心并行接收，简化了事件使用。"
    },
    {
      "pos": [
        268,
        298
      ],
      "content": "有关事件中心接收模式的详细信息，请参阅<bpt id=\"p1\">[</bpt>事件中心概述<ept id=\"p1\">][]</ept>。"
    },
    {
      "pos": [
        300,
        350
      ],
      "content": "本教程使用安装的 <bpt id=\"p1\">[</bpt>HDInsight Storm<ept id=\"p1\">][]</ept>，其中随附了现成可用的事件中心 Spout。"
    },
    {
      "pos": [
        355,
        463
      ],
      "content": "请按照 <bpt id=\"p1\">[</bpt>HDInsight Storm - 入门<ept id=\"p1\">](/documentation/articles/hdinsight-storm-overview)</ept>过程创建新 HDInsight 群集，并通过远程桌面连接该群集。"
    },
    {
      "pos": [
        468,
        596
      ],
      "content": "将 <ph id=\"ph1\">`%STORM_HOME%\\examples\\eventhubspout\\eventhubs-storm-spout-0.9-jar-with-dependencies.jar`</ph> 文件复制到本地开发环境。其中包含 events-storm-spout。"
    },
    {
      "content": "使用以下命令将程序包安装到本地 Maven 存储中。这样，在后面的步骤中，您便可以在 Storm 项目中将它添加为引用。",
      "pos": [
        601,
        661
      ]
    },
    {
      "content": "在 Eclipse 中创建一个新的 Maven 项目（依次单击“文件”、“新建”、“项目”）。",
      "pos": [
        865,
        912
      ]
    },
    {
      "content": "选择“使用默认工作区位置”，然后单击“下一步”",
      "pos": [
        930,
        953
      ]
    },
    {
      "pos": [
        958,
        1011
      ],
      "content": "选择 <bpt id=\"p1\">**</bpt>maven-archetype-quickstart<ept id=\"p1\">**</ept> archetype，然后单击“下一步”"
    },
    {
      "pos": [
        1016,
        1056
      ],
      "content": "插入 <bpt id=\"p1\">**</bpt>GroupId<ept id=\"p1\">**</ept> 和 <bpt id=\"p2\">**</bpt>ArtifactId<ept id=\"p2\">**</ept>，然后单击“完成”"
    },
    {
      "pos": [
        1061,
        1104
      ],
      "content": "在 <bpt id=\"p1\">**</bpt>pom.xml<ept id=\"p1\">**</ept> 中的 <ph id=\"ph1\">`&lt;dependency&gt;`</ph> 节点内添加以下依赖项。"
    },
    {
      "pos": [
        2116,
        2180
      ],
      "content": "在 <bpt id=\"p1\">**</bpt>src<ept id=\"p1\">**</ept> 文件夹中，创建一个名为 <bpt id=\"p2\">**</bpt>Config.properties<ept id=\"p2\">**</ept> 的文件，并复制以下内容，从而替换以下值："
    },
    {
      "pos": [
        2693,
        2802
      ],
      "content": "<bpt id=\"p1\">**</bpt>eventhub.receiver.credits<ept id=\"p1\">**</ept> 的值决定在被发布到 Storm 管道之前先进行批处理的事件的数量。为了简单起见，本示例将此值设置为 10。在生产中，通常应将它设置为较高的值，例如 1024。"
    },
    {
      "pos": [
        2808,
        2838
      ],
      "content": "使用以下代码创建名为 <bpt id=\"p1\">**</bpt>LoggerBolt<ept id=\"p1\">**</ept> 的新类："
    },
    {
      "pos": [
        4099,
        4183
      ],
      "content": "此 Storm 螺栓记录接收到的事件的内容。在存储服务中，它可以轻松扩展为存储元组。<bpt id=\"p1\">[</bpt><ept id=\"p1\">HDInsight 传感器分析教程]</ept>同样使用这种方法将数据存储到 HBase 中。"
    },
    {
      "pos": [
        4189,
        4221
      ],
      "content": "使用以下代码创建一个名为 <bpt id=\"p1\">**</bpt>LogTopology<ept id=\"p1\">**</ept> 的类："
    },
    {
      "content": "此类创建新事件中心喷管，并使用配置文件中的属性对它进行实例化。请务必注意：此示例创建喷管的数量与事件中心中分区的数量相同，以便使用该事件中心允许的最大并行度。",
      "pos": [
        9291,
        9370
      ]
    }
  ],
  "content": "## 使用 Apache Storm 接收消息\n\n[**Apache Storm**](https://storm.incubator.apache.org) 是一个分布式实时计算系统，它简化了对未绑定的数据流进行可靠处理的过程。本节演示如何使用事件中心 Storm 喷口从事件中心接收事件。使用 Apache Storm，可以在承载于不同节点的多个进程间拆分事件。事件中心与 Storm 集成后，通过使用风暴的 Zookeeper 安装以透明方式对事件使用进度执行检查点操作、管理持久检查点以及从事件中心并行接收，简化了事件使用。\n\n有关事件中心接收模式的详细信息，请参阅[事件中心概述][]。\n\n本教程使用安装的 [HDInsight Storm][]，其中随附了现成可用的事件中心 Spout。\n\n1. 请按照 [HDInsight Storm - 入门](/documentation/articles/hdinsight-storm-overview)过程创建新 HDInsight 群集，并通过远程桌面连接该群集。\n\n2. 将 `%STORM_HOME%\\examples\\eventhubspout\\eventhubs-storm-spout-0.9-jar-with-dependencies.jar` 文件复制到本地开发环境。其中包含 events-storm-spout。\n\n3. 使用以下命令将程序包安装到本地 Maven 存储中。这样，在后面的步骤中，您便可以在 Storm 项目中将它添加为引用。\n\n        mvn install:install-file -Dfile=target\\eventhubs-storm-spout-0.9-jar-with-dependencies.jar -DgroupId=com.microsoft.eventhubs -DartifactId=eventhubs-storm-spout -Dversion=0.9 -Dpackaging=jar\n\n4. 在 Eclipse 中创建一个新的 Maven 项目（依次单击“文件”、“新建”、“项目”）。\n\n    ![][12]\n\n5. 选择“使用默认工作区位置”，然后单击“下一步”\n\n6. 选择 **maven-archetype-quickstart** archetype，然后单击“下一步”\n\n7. 插入 **GroupId** 和 **ArtifactId**，然后单击“完成”\n\n8. 在 **pom.xml** 中的 `<dependency>` 节点内添加以下依赖项。\n\n        <dependency>\n            <groupId>org.apache.storm</groupId>\n            <artifactId>storm-core</artifactId>\n            <version>0.9.2-incubating</version>\n            <scope>provided</scope>\n        </dependency>\n        <dependency>\n            <groupId>com.microsoft.eventhubs</groupId>\n            <artifactId>eventhubs-storm-spout</artifactId>\n            <version>0.9</version>\n        </dependency>\n        <dependency>\n            <groupId>com.netflix.curator</groupId>\n            <artifactId>curator-framework</artifactId>\n            <version>1.3.3</version>\n            <exclusions>\n                <exclusion>\n                    <groupId>log4j</groupId>\n                    <artifactId>log4j</artifactId>\n                </exclusion>\n                <exclusion>\n                    <groupId>org.slf4j</groupId>\n                    <artifactId>slf4j-log4j12</artifactId>\n                </exclusion>\n            </exclusions>\n            <scope>provided</scope>\n        </dependency>\n\n9. 在 **src** 文件夹中，创建一个名为 **Config.properties** 的文件，并复制以下内容，从而替换以下值：\n\n        eventhubspout.username = ReceiveRule\n        \n        eventhubspout.password = {receive rule key}\n        \n        eventhubspout.namespace = ioteventhub-ns\n        \n        eventhubspout.entitypath = {event hub name}\n        \n        eventhubspout.partitions.count = 16\n        \n        # if not provided, will use storm's zookeeper settings\n        # zookeeper.connectionstring=localhost:2181\n        \n        eventhubspout.checkpoint.interval = 10\n        \n        eventhub.receiver.credits = 10\n\n    **eventhub.receiver.credits** 的值决定在被发布到 Storm 管道之前先进行批处理的事件的数量。为了简单起见，本示例将此值设置为 10。在生产中，通常应将它设置为较高的值，例如 1024。\n\n10. 使用以下代码创建名为 **LoggerBolt** 的新类：\n\n        import java.util.Map;\n        import org.slf4j.Logger;\n        import org.slf4j.LoggerFactory;\n        import backtype.storm.task.OutputCollector;\n        import backtype.storm.task.TopologyContext;\n        import backtype.storm.topology.OutputFieldsDeclarer;\n        import backtype.storm.topology.base.BaseRichBolt;\n        import backtype.storm.tuple.Tuple;\n        \n        public class LoggerBolt extends BaseRichBolt {\n            private OutputCollector collector;\n            private static final Logger logger = LoggerFactory\n                      .getLogger(LoggerBolt.class);\n        \n            @Override\n            public void execute(Tuple tuple) {              \n                String value = tuple.getString(0);\n                logger.info(\"Tuple value: \" + value);\n                \n                collector.ack(tuple);\n            }\n        \n            @Override\n            public void prepare(Map map, TopologyContext context, OutputCollector collector) {\n                this.collector = collector;\n                this.count = 0;\n            }\n        \n            @Override\n            public void declareOutputFields(OutputFieldsDeclarer declarer) {\n                // no output fields\n            }\n        \n        }\n\n    此 Storm 螺栓记录接收到的事件的内容。在存储服务中，它可以轻松扩展为存储元组。[HDInsight 传感器分析教程]同样使用这种方法将数据存储到 HBase 中。\n\n11. 使用以下代码创建一个名为 **LogTopology** 的类：\n\n        import java.io.FileReader;\n        import java.util.Properties;\n        import backtype.storm.Config;\n        import backtype.storm.LocalCluster;\n        import backtype.storm.StormSubmitter;\n        import backtype.storm.generated.StormTopology;\n        import backtype.storm.topology.TopologyBuilder;\n        import com.microsoft.eventhubs.samples.EventCount;\n        import com.microsoft.eventhubs.spout.EventHubSpout;\n        import com.microsoft.eventhubs.spout.EventHubSpoutConfig;\n        \n        public class LogTopology {\n            protected EventHubSpoutConfig spoutConfig;\n            protected int numWorkers;\n        \n            protected void readEHConfig(String[] args) throws Exception {\n                Properties properties = new Properties();\n                if (args.length > 1) {\n                    properties.load(new FileReader(args[1]));\n                } else {\n                    properties.load(EventCount.class.getClassLoader()\n                            .getResourceAsStream(\"Config.properties\"));\n                }\n        \n                String username = properties.getProperty(\"eventhubspout.username\");\n                String password = properties.getProperty(\"eventhubspout.password\");\n                String namespaceName = properties\n                        .getProperty(\"eventhubspout.namespace\");\n                String entityPath = properties.getProperty(\"eventhubspout.entitypath\");\n                String zkEndpointAddress = properties\n                        .getProperty(\"zookeeper.connectionstring\"); // opt\n                int partitionCount = Integer.parseInt(properties\n                        .getProperty(\"eventhubspout.partitions.count\"));\n                int checkpointIntervalInSeconds = Integer.parseInt(properties\n                        .getProperty(\"eventhubspout.checkpoint.interval\"));\n                int receiverCredits = Integer.parseInt(properties\n                        .getProperty(\"eventhub.receiver.credits\")); // prefetch count\n                                                                    // (opt)\n                System.out.println(\"Eventhub spout config: \");\n                System.out.println(\"  partition count: \" + partitionCount);\n                System.out.println(\"  checkpoint interval: \"\n                        + checkpointIntervalInSeconds);\n                System.out.println(\"  receiver credits: \" + receiverCredits);\n        \n                spoutConfig = new EventHubSpoutConfig(username, password,\n                        namespaceName, entityPath, partitionCount, zkEndpointAddress,\n                        checkpointIntervalInSeconds, receiverCredits);\n        \n                // set the number of workers to be the same as partition number.\n                // the idea is to have a spout and a logger bolt co-exist in one\n                // worker to avoid shuffling messages across workers in storm cluster.\n                numWorkers = spoutConfig.getPartitionCount();\n        \n                if (args.length > 0) {\n                    // set topology name so that sample Trident topology can use it as\n                    // stream name.\n                    spoutConfig.setTopologyName(args[0]);\n                }\n            }\n        \n            protected StormTopology buildTopology() {\n                TopologyBuilder topologyBuilder = new TopologyBuilder();\n        \n                EventHubSpout eventHubSpout = new EventHubSpout(spoutConfig);\n                topologyBuilder.setSpout(\"EventHubsSpout\", eventHubSpout,\n                        spoutConfig.getPartitionCount()).setNumTasks(\n                        spoutConfig.getPartitionCount());\n                topologyBuilder\n                        .setBolt(\"LoggerBolt\", new LoggerBolt(),\n                                spoutConfig.getPartitionCount())\n                        .localOrShuffleGrouping(\"EventHubsSpout\")\n                        .setNumTasks(spoutConfig.getPartitionCount());\n                return topologyBuilder.createTopology();\n            }\n        \n            protected void runScenario(String[] args) throws Exception {\n                boolean runLocal = true;\n                readEHConfig(args);\n                StormTopology topology = buildTopology();\n                Config config = new Config();\n                config.setDebug(false);\n        \n                if (runLocal) {\n                    config.setMaxTaskParallelism(2);\n                    LocalCluster localCluster = new LocalCluster();\n                    localCluster.submitTopology(\"test\", config, topology);\n                    Thread.sleep(5000000);\n                    localCluster.shutdown();\n                } else {\n                    config.setNumWorkers(numWorkers);\n                    StormSubmitter.submitTopology(args[0], config, topology);\n                }\n            }\n        \n            public static void main(String[] args) throws Exception {\n                LogTopology topology = new LogTopology();\n                topology.runScenario(args);\n            }\n        }\n\n\n    此类创建新事件中心喷管，并使用配置文件中的属性对它进行实例化。请务必注意：此示例创建喷管的数量与事件中心中分区的数量相同，以便使用该事件中心允许的最大并行度。\n\n<!-- Links -->\n[事件中心概述]: /documentation/articles/event-hubs-overview\n[HDInsight Storm]: /documentation/articles/hdinsight-storm-overview\n[HDInsight 传感器分析教程]: /documentation/articles/hdinsight-storm-sensor-data-analysis\n\n<!-- Images -->\n\n[12]: ./media/service-bus-event-hubs-getstarted/create-storm1.png\n[13]: ./media/service-bus-event-hubs-getstarted/create-eph-csharp1.png\n[14]: ./media/service-bus-event-hubs-getstarted/create-sender-csharp1.png\n\n<!---HONumber=Mooncake_0104_2016-->"
}