{
  "nodes": [
    {
      "content": "使用 Microsoft Avro Library 序列化数据 | Azure",
      "pos": [
        27,
        66
      ]
    },
    {
      "content": "了解 Azure HDInsight 如何使用 Avro 来序列化大数据。",
      "pos": [
        85,
        122
      ]
    },
    {
      "content": "使用 Microsoft Avro Library 序列化 Hadoop 中的数据",
      "pos": [
        361,
        402
      ]
    },
    {
      "pos": [
        404,
        590
      ],
      "content": "本主题演示如何使用 <ph id=\"ph1\">&lt;a href=\"https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library\" target=\"_blank\"&gt;</ph>Microsoft Avro Library<ph id=\"ph2\">&lt;/a&gt;</ph> 将对象及其他数据结构序列化为流，以便将它们持久保存到内存、数据库或文件中，同时还演示如何对这些流进行反序列化以恢复原始对象。"
    },
    {
      "pos": [
        592,
        661
      ],
      "content": "[AZURE.INCLUDE <bpt id=\"p1\">[</bpt>仅适用于 Windows<ept id=\"p1\">](../includes/hdinsight-windows-only.md)</ept>]"
    },
    {
      "content": "<ph id=\"ph1\">&lt;a name=\"apacheAvro\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Apache Avro",
      "pos": [
        665,
        701
      ]
    },
    {
      "content": "<ph id=\"ph1\">&lt;a href=\"https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library\" target=\"_blank\"&gt;</ph>Microsoft Avro Library<ph id=\"ph2\">&lt;/a&gt;</ph> 针对 Microsoft.NET 环境实现了 Apache Avro 数据序列化系统。Apache Avro 为序列化提供了一种紧凑的二进制数据交换格式。它使用 <ph id=\"ph3\">&lt;a href=\"http://www.json.org\" target=\"_blank\"&gt;</ph>JSON<ph id=\"ph4\">&lt;/a&gt;</ph> 定义与语言无关的架构，以支持语言互操作性。以一种语言序列化的数据可以用另一种语言读取。目前支持 C、C++、C#、Java、PHP、Python 和 Ruby。有关格式的详细信息可以在 <ph id=\"ph5\">&lt;a href=\"http://avro.apache.org/docs/current/spec.html\" target=\"_blank\"&gt;</ph>Apache Avro 规范<ph id=\"ph6\">&lt;/a&gt;</ph>中找到。请注意，Microsoft Avro Library 的当前版本不支持此规范的远程过程调用 (RPC) 部分。",
      "pos": [
        702,
        1194
      ]
    },
    {
      "content": "Avro 系统中的对象的序列化表示形式由两部分组成：架构和实际值。Avro 架构使用 JSON 描述已序列化数据的与语言无关的数据模型。它与数据的二进制表示形式并排显示。将架构与二进制表示形式分离，使写入每个对象时没有针对值的开销，从而实现快速序列化和较小的表示形式。",
      "pos": [
        1196,
        1330
      ]
    },
    {
      "content": "<ph id=\"ph1\">&lt;a name=\"hadoopScenario\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Hadoop 应用场景",
      "pos": [
        1334,
        1374
      ]
    },
    {
      "content": "Apache Avro 序列化格式广泛应用于 Azure HDInsight 及其他 Apache Hadoop 环境中。Avro 提供了简便的方法来表示 Hadoop MapReduce 作业内的复杂数据结构。Avro 文件（Avro 对象容器文件）格式已设计为支持分布式 MapReduce 编程模型。实现分布的关键功能是文件是“可拆分的”，也就是说，用户可以在文件中搜寻任一点，然后即可从某一特定块开始读取。",
      "pos": [
        1375,
        1582
      ]
    },
    {
      "content": "<ph id=\"ph1\">&lt;a name=\"serializationMAL\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>Microsoft Avro Library 中的序列化",
      "pos": [
        1586,
        1645
      ]
    },
    {
      "content": ".NET Library for Avro 支持通过两种方式序列化对象：",
      "pos": [
        1646,
        1682
      ]
    },
    {
      "pos": [
        1686,
        1734
      ],
      "content": "<bpt id=\"p1\">**</bpt>反射<ept id=\"p1\">**</ept> - 自动从要序列化的 .NET 类型的数据协定特性生成这些类型的 JSON 架构。"
    },
    {
      "pos": [
        1737,
        1899
      ],
      "content": "<bpt id=\"p1\">**</bpt>通用记录<ept id=\"p1\">**</ept> - 当没有 .NET 类型可以用来描述要序列化的数据的架构时，系统会在以 <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>AvroRecord<ept id=\"p3\">**</ept><ept id=\"p2\">](http://msdn.microsoft.com/zh-cn/library/microsoft.hadoop.avro.avrorecord.aspx)</ept> 类表示的记录中显式指定 JSON 架构。"
    },
    {
      "content": "当流的写入器和读取器都知道数据架构时，可以发送没有架构的数据。在未使用 Avro 对象容器文件的情况下，架构将存储在文件中。可以指定其他参数，例如用于数据压缩的编解码器。这些情况将在下面的代码示例中进一步详述和说明。",
      "pos": [
        1901,
        2009
      ]
    },
    {
      "pos": [
        2014,
        2058
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"prerequisites\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph> 安装 Avro Library"
    },
    {
      "content": "以下是安装此库之前所需具备的先决条件：",
      "pos": [
        2060,
        2079
      ]
    },
    {
      "pos": [
        2083,
        2195
      ],
      "content": "<ph id=\"ph1\">&lt;a href=\"http://www.microsoft.com/download/details.aspx?id=17851\" target=\"_blank\"&gt;</ph>Microsoft .NET Framework 4<ph id=\"ph2\">&lt;/a&gt;</ph>"
    },
    {
      "pos": [
        2198,
        2293
      ],
      "content": "<ph id=\"ph1\">&lt;a href=\"http://james.newtonking.com/json\" target=\"_blank\"&gt;</ph>Newtonsoft Json.NET<ph id=\"ph2\">&lt;/a&gt;</ph>（6.0.4 或更高版本）"
    },
    {
      "content": "请注意，Newtonsoft.Json.dll 依赖项已随着 Microsoft Avro Library 的安装自动下载。下一部分将提供此操作的相关过程。",
      "pos": [
        2295,
        2373
      ]
    },
    {
      "content": "Microsoft Avro Library 以 NuGet 包发行，你可以使用以下过程在 Visual Studio 中安装 NuGet 程序包：",
      "pos": [
        2376,
        2450
      ]
    },
    {
      "content": "选择“项目”选项卡-&gt;“管理 NuGet 包...”",
      "pos": [
        2455,
        2481
      ]
    },
    {
      "content": "在“联机搜索”框中，搜索“Microsoft.Hadoop.Avro”。",
      "pos": [
        2485,
        2521
      ]
    },
    {
      "content": "单击“Azure HDInsight Avro Library”旁边的“安装”按钮。",
      "pos": [
        2525,
        2567
      ]
    },
    {
      "content": "请注意，Newtonsoft.Json.dll (&gt;= 6.0.4) 依赖项也将随 Microsoft Avro Library 一起自动下载。",
      "pos": [
        2569,
        2641
      ]
    },
    {
      "pos": [
        2643,
        2778
      ],
      "content": "你可能需要浏览 <ph id=\"ph1\">&lt;a href=\"https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library\" target=\"_blank\"&gt;</ph>Microsoft Avro Library 主页<ph id=\"ph2\">&lt;/a&gt;</ph>以阅读最新的发行说明。"
    },
    {
      "pos": [
        2781,
        2929
      ],
      "content": "<ph id=\"ph1\">&lt;a href=\"https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library\" target=\"_blank\"&gt;</ph>Microsoft Avro Library 主页<ph id=\"ph2\">&lt;/a&gt;</ph>中提供了 Microsoft Avro Library 源代码。"
    },
    {
      "pos": [
        2933,
        2977
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"compiling\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>使用 Avro Library 编译架构"
    },
    {
      "content": "Microsoft Avro Library 包含代码生成实用工具，可让你自动根据先前定义的 JSON 架构来创建 C# 类型。代码生成实用工具不是以二进制可执行文件的形式分发的，但你可使用以下过程轻松生成：",
      "pos": [
        2979,
        3083
      ]
    },
    {
      "pos": [
        3088,
        3246
      ],
      "content": "从 <ph id=\"ph1\">&lt;a href=\"http://hadoopsdk.codeplex.com/SourceControl/latest\" target=\"_blank\"&gt;</ph>Microsoft .NET SDK For Hadoop<ph id=\"ph2\">&lt;/a&gt;</ph> 下载包含最新版 HDInsight SDK 源代码的 ZIP 文件。（单击“下载”图标。）"
    },
    {
      "content": "将 HDInsight SDK 解压缩到已安装 .NET Framework 4.0 并连接到 Internet 的计算机上的目录，以下载必要的依赖项 NuGet 包。下面我们假设源代码已解压缩到 C:\\\\SDK。",
      "pos": [
        3251,
        3358
      ]
    },
    {
      "content": "转到文件夹 C:\\\\SDK\\\\src\\\\Microsoft.Hadoop.Avro.Tools 并运行 build.bat。（此文件将从 .NET Framework 的 32 位分发版调用 MSBuild。如果你想要使用 64 位版本，请编辑 build.bat 文件注释后的列。） 确保生成成功。（在某些系统上，MSBuild 可能生成警告。只要没有生成错误，这些警告就不影响实用工具。）",
      "pos": [
        3363,
        3559
      ]
    },
    {
      "content": "编译的实用工具位于 C:\\\\SDK\\\\Bin\\\\Unsigned\\\\Release\\\\Microsoft.Hadoop.Avro.Tools 中。",
      "pos": [
        3564,
        3637
      ]
    },
    {
      "pos": [
        3640,
        3718
      ],
      "content": "若要熟悉命令行语法，请从代码生成实用工具所在的文件夹运行以下命令：<ph id=\"ph1\">`Microsoft.Hadoop.Avro.Tools help /c:codegen`</ph>"
    },
    {
      "content": "若要测试实用工具，你可以从随着源代码提供的示例 JSON 架构文件生成 C# 类。运行以下命令：",
      "pos": [
        3720,
        3768
      ]
    },
    {
      "content": "这应该在当前目录中生成两个 C# 文件：SensorData.cs 和 Location.cs。",
      "pos": [
        3890,
        3938
      ]
    },
    {
      "content": "若要了解代码生成实用工具在转换 JSON 架构为 C# 类型时使用的逻辑，请参阅 C:\\\\SDK\\\\src\\\\Microsoft.Hadoop.Avro.Tools\\\\Doc 中的 GenerationVerification.feature 文件。",
      "pos": [
        3940,
        4065
      ]
    },
    {
      "content": "请注意，该命名空间是使用上一个段落中提及的文件中所描述的逻辑，从 JSON 架构中提取。从架构提取的命名空间，将比实用工具命令行中使用 /n 参数提供的设置具有优先权。如果你想要重写架构中包含的命名空间，请确保使用 /nf 参数。例如，若要将所有命名空间从 SampleJSONSchema.avsc 更改为 my.own.nspace，请运行以下命令：",
      "pos": [
        4067,
        4244
      ]
    },
    {
      "content": "<ph id=\"ph1\">&lt;a name=\"samples\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph> 示例",
      "pos": [
        4387,
        4412
      ]
    },
    {
      "content": "本主题中提供的六个示例演示了 Microsoft Avro Library 所支持的不同方案。Microsoft Avro Library 设计为可处理任何流。在这些示例中，为保持简单性和一致性，是使用内存流（而不是文件流或数据库）来操作数据的。在生产环境中所采取的方法将取决于实际的方案要求、数据源和卷、性能限制及其他因素。",
      "pos": [
        4413,
        4576
      ]
    },
    {
      "content": "前两个示例显示如何使用反射和通用记录将数据序列化到内存流缓冲区，以及如何进行反序列化。这两个方案假设在读取器和写入器之间共享架构。",
      "pos": [
        4578,
        4643
      ]
    },
    {
      "content": "第三和第四个示例说明如何使用 Avro 对象容器文件，将数据序列化与反序列化。当数据存储在 Avro 容器文件中时，其架构始终随之一起存储，因为必须共享架构才能进行反序列化。",
      "pos": [
        4645,
        4732
      ]
    },
    {
      "pos": [
        4734,
        4826
      ],
      "content": "包含前四个示例的样例可以从 <ph id=\"ph1\">&lt;a href=\"https://github.com/Azure-Samples\" target=\"_blank\"&gt;</ph>Azure 代码示例<ph id=\"ph2\">&lt;/a&gt;</ph>站点下载。"
    },
    {
      "pos": [
        4828,
        4954
      ],
      "content": "第五个示例演示如何将自定义压缩编解码器用于 Avro 对象容器文件。包含此示例代码的样例可以从 <ph id=\"ph1\">&lt;a href=\"https://github.com/Azure-Samples\" target=\"_blank\"&gt;</ph>Azure 代码示例<ph id=\"ph2\">&lt;/a&gt;</ph>站点下载。"
    },
    {
      "pos": [
        4956,
        5122
      ],
      "content": "第六个示例显示如何使用 Avro 序列化来上载数据到 Azure Blob 存储，然后使用具有 HDInsight (Hadoop) 群集的 Hive 加以分析。可以从 <ph id=\"ph1\">&lt;a href=\"https://github.com/Azure-Samples\" target=\"_blank\"&gt;</ph>Azure 代码示例<ph id=\"ph2\">&lt;/a&gt;</ph>站点下载该示例。"
    },
    {
      "content": "以下是本主题所讨论的六个示例的链接：",
      "pos": [
        5124,
        5142
      ]
    },
    {
      "pos": [
        5147,
        5216
      ],
      "content": "<ph id=\"ph1\">&lt;a href=\"#Scenario1\"&gt;</ph><bpt id=\"p1\">**</bpt>通过反射进行序列化<ept id=\"p1\">**</ept><ph id=\"ph2\">&lt;/a&gt;</ph> - 自动从数据协定特性生成要序列化的类型的 JSON 架构。"
    },
    {
      "pos": [
        5220,
        5299
      ],
      "content": "<ph id=\"ph1\">&lt;a href=\"#Scenario2\"&gt;</ph><bpt id=\"p1\">**</bpt>通过通用记录进行序列化<ept id=\"p1\">**</ept><ph id=\"ph2\">&lt;/a&gt;</ph> - 当没有可用于反射的 .NET 类型时，在记录中显式指定 JSON 架构。"
    },
    {
      "pos": [
        5303,
        5388
      ],
      "content": "<ph id=\"ph1\">&lt;a href=\"#Scenario3\"&gt;</ph><bpt id=\"p1\">**</bpt>使用对象容器文件与反射进行序列化<ept id=\"p1\">**</ept><ph id=\"ph2\">&lt;/a&gt;</ph> - JSON 架构自动生成并使用 Avro 对象容器文件随着序列化的数据共享。"
    },
    {
      "pos": [
        5392,
        5487
      ],
      "content": "<ph id=\"ph1\">&lt;a href=\"#Scenario4\"&gt;</ph><bpt id=\"p1\">**</bpt>使用对象容器文件与通用记录进行序列化<ept id=\"p1\">**</ept><ph id=\"ph2\">&lt;/a&gt;</ph> - JSON 架构是在序列化前显式指定的，并使用 Avro 对象容器文件随着序列化的数据共享。"
    },
    {
      "pos": [
        5491,
        5601
      ],
      "content": "<ph id=\"ph1\">&lt;a href=\"#Scenario5\"&gt;</ph><bpt id=\"p1\">**</bpt>使用对象容器文件和自定义压缩编解码器进行序列化<ept id=\"p1\">**</ept><ph id=\"ph2\">&lt;/a&gt;</ph> - 该示例演示如何使用 Deflate 数据压缩编解码器的自定义 .NET 实现，来创建 Avro 对象容器文件。"
    },
    {
      "pos": [
        5605,
        5753
      ],
      "content": "<ph id=\"ph1\">&lt;a href=\"#Scenario6\"&gt;</ph><bpt id=\"p1\">**</bpt>使用 Avro 来上载 Azure HDInsight 服务的数据<ept id=\"p1\">**</ept><ph id=\"ph2\">&lt;/a&gt;</ph> - 该示例演示 Avro 序列化如何与 HDInsight 服务交互。要运行此示例，你必须具备有效的 Azure 订阅并且可以访问 Azure HDInsight 群集。"
    },
    {
      "pos": [
        5758,
        5796
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"Scenario1\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>示例 1：通过反射进行序列化"
    },
    {
      "pos": [
        5798,
        5981
      ],
      "content": "Microsoft Avro Library 可以使用反射从要序列化的 C# 对象的数据协定特性自动生成类型的 JSON 架构。Microsoft Avro Library 将创建一个 <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>IAvroSeralizer<ph id=\"ph1\">&lt;T&gt;</ph><ept id=\"p2\">**</ept><ept id=\"p1\">](http://msdn.microsoft.com/zh-cn/library/dn627341.aspx)</ept> 以标识要序列化的字段。"
    },
    {
      "pos": [
        5983,
        6099
      ],
      "content": "在此示例中，将对象（具有成员 <bpt id=\"p1\">**</bpt>Location<ept id=\"p1\">**</ept> 结构的 <bpt id=\"p2\">**</bpt>SensorData<ept id=\"p2\">**</ept> 类）序列化到内存流，继而又将此流反序列化。然后，将结果与初始实例进行比较，以确认恢复的 <bpt id=\"p3\">**</bpt>SensorData<ept id=\"p3\">**</ept> 对象与原始对象相同。"
    },
    {
      "pos": [
        6101,
        6254
      ],
      "content": "此示例中的架构假定在读取器与写入器之间共享，因此无需采用 Avro 对象容器格式。有关在架构必须与数据一起共享时，如何使用反射和对象容器格式将数据序列化到内存缓冲区，以及如何对内存缓冲区中的数据进行反序列化的示例，请参阅<ph id=\"ph1\">&lt;a href=\"#Scenario3\"&gt;</ph>使用对象容器文件通过反射进行序列化<ph id=\"ph2\">&lt;/a&gt;</ph>。"
    },
    {
      "pos": [
        10582,
        10622
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"Scenario2\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>示例 2：通过通用记录进行序列化"
    },
    {
      "content": "当数据无法使用具有数据协定的 .NET 类表示而导致不能使用反射时，可以在通用记录中显式指定 JSON 架构。此方法通常比使用反射要慢。在这种情况下，数据架构也可能是动态的，因为在编译之前它是未知的。以逗号分隔值 (CSV) 文件表示的数据（在运行时转换为 Avro 格式之前，其架构一直是未知的）是这种动态方案的一个示例。",
      "pos": [
        10624,
        10786
      ]
    },
    {
      "pos": [
        10788,
        10967
      ],
      "content": "此示例演示如何创建 <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>AvroRecord<ept id=\"p2\">**</ept><ept id=\"p1\">](http://msdn.microsoft.com/zh-cn/library/microsoft.hadoop.avro.avrorecord.aspx)</ept> 并使用它显式指定 JSON 架构，如何为其填充数据，然后对其进行序列化和反序列化。然后，将结果与初始实例进行比较，以确认恢复的记录与原始记录相同。"
    },
    {
      "pos": [
        10969,
        11130
      ],
      "content": "此示例中的架构假定在读取器与写入器之间共享，因此无需采用 Avro 对象容器格式。有关在架构必须包含在已序列化的数据中时，如何使用通用记录和对象容器格式将数据序列化到内存缓冲区，以及对内存缓冲区中的数据进行反序列化的示例，请参阅<ph id=\"ph1\">&lt;a href=\"#Scenario4\"&gt;</ph>使用对象容器文件通过通用记录进行序列化<ph id=\"ph2\">&lt;/a&gt;</ph>示例。"
    },
    {
      "pos": [
        16136,
        16188
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"Scenario3\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>示例 3：使用对象容器文件进行序列化与使用反射进行序列化"
    },
    {
      "pos": [
        16190,
        16435
      ],
      "content": "此示例与<ph id=\"ph1\">&lt;a href=\"#Scenario1\"&gt;</ph>第一个示例<ph id=\"ph2\">&lt;/a&gt;</ph>中使用反射隐式指定架构的方案类似。除了本示例假设要将架构反序列化的读取器不知道架构以外。要序列化的 <bpt id=\"p1\">**</bpt>SensorData<ept id=\"p1\">**</ept> 对象及其隐式指定的架构存储在由 <bpt id=\"p2\">[</bpt><bpt id=\"p3\">**</bpt>AvroContainer<ept id=\"p3\">**</ept><ept id=\"p2\">](http://msdn.microsoft.com/zh-cn/library/microsoft.hadoop.avro.container.avrocontainer.aspx)</ept> 类表示的 Avro 对象容器文件中。"
    },
    {
      "pos": [
        16437,
        16664
      ],
      "content": "在此示例中，数据使用 <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>SequentialWriter<ph id=\"ph1\">&lt;SensorData&gt;</ph><ept id=\"p2\">**</ept><ept id=\"p1\">](http://msdn.microsoft.com/zh-cn/library/dn627340.aspx)</ept> 进行序列化，使用 <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>SequentialReader<ph id=\"ph2\">&lt;SensorData&gt;</ph><ept id=\"p4\">**</ept><ept id=\"p3\">](http://msdn.microsoft.com/zh-cn/library/dn627340.aspx)</ept> 进行反序列化。然后，将结果与初始实例比较，以确保相同。"
    },
    {
      "pos": [
        16666,
        16849
      ],
      "content": "对象容器文件中的数据是通过 .NET Framework 4 中的默认 <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>Deflate<ept id=\"p2\">**</ept><ept id=\"p1\">][deflate-100]</ept> 压缩编解码器压缩的。请参阅本主题中的<ph id=\"ph1\">&lt;a href=\"#Scenario5\"&gt;</ph>第五个示例<ph id=\"ph2\">&lt;/a&gt;</ph>，了解如何使用 .NET Framework 4.5 中提供的更新的 <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>Deflate<ept id=\"p4\">**</ept><ept id=\"p3\">][deflate-110]</ept> 压缩编解码器高级版。"
    },
    {
      "pos": [
        26222,
        26276
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"Scenario4\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>示例 4：使用对象容器文件进行序列化与使用通用记录进行序列化"
    },
    {
      "pos": [
        26278,
        26360
      ],
      "content": "此示例与<ph id=\"ph1\">&lt;a href=\"#Scenario2\"&gt;</ph>第二个示例<ph id=\"ph2\">&lt;/a&gt;</ph>中使用 JSON 显式指定架构的方案类似。除了本示例假设要将架构反序列化的读取器不知道架构以外。"
    },
    {
      "pos": [
        26362,
        26799
      ],
      "content": "测试数据集将通过显式定义的 JSON 架构收集到 <bpt id=\"p1\">[</bpt><bpt id=\"p2\">**</bpt>AvroRecord<ept id=\"p2\">**</ept><ept id=\"p1\">](http://msdn.microsoft.com/zh-cn/library/microsoft.hadoop.avro.avrorecord.aspx)</ept> 对象列表中，然后存储在由 <bpt id=\"p3\">[</bpt><bpt id=\"p4\">**</bpt>AvroContainer<ept id=\"p4\">**</ept><ept id=\"p3\">](http://msdn.microsoft.com/zh-cn/library/microsoft.hadoop.avro.container.avrocontainer.aspx)</ept> 类表示的对象容器文件中。此容器文件将创建一个写入器，该写入器用于将未压缩的数据序列化到内存流，然后将该内存流保存到文件中。指定不要压缩此数据的是创建读取器时所用的 <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>Codex.Null<ept id=\"p6\">**</ept><ept id=\"p5\">](http://msdn.microsoft.com/zh-cn/library/microsoft.hadoop.avro.container.codec.null.aspx)</ept> 参数。"
    },
    {
      "content": "然后，从文件中读取数据，并将数据反序列化为对象的集合。将此集合与 Avro 记录的初始列表进行比较，以确认它们相同。",
      "pos": [
        26801,
        26859
      ]
    },
    {
      "pos": [
        37979,
        38032
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"Scenario5\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>示例 5：使用对象容器文件通过自定义压缩编解码器进行序列化"
    },
    {
      "pos": [
        38034,
        38133
      ],
      "content": "第五个示例演示如何将自定义压缩编解码器用于 Avro 对象容器文件。包含此示例代码的样例可以从 <bpt id=\"p1\">[</bpt>Azure 代码示例<ept id=\"p1\">](https://github.com/Azure-Samples)</ept>站点下载。"
    },
    {
      "pos": [
        38135,
        38495
      ],
      "content": "<bpt id=\"p1\">[</bpt>Avro 规范<ept id=\"p1\">](http://avro.apache.org/docs/current/spec.html#Required+Codecs)</ept>允许使用可选的压缩编解码器（除了 <bpt id=\"p2\">**</bpt>Null<ept id=\"p2\">**</ept> 和 <bpt id=\"p3\">**</bpt>Deflate<ept id=\"p3\">**</ept> 默认压缩编解码器外）。此示例未完全实现类似 Snappy（在 <bpt id=\"p4\">[</bpt>Avro 规范<ept id=\"p4\">](http://avro.apache.org/docs/current/spec.html#snappy)</ept>中作为支持的可选编解码器提及）的新编解码器。它演示如何使用 <bpt id=\"p5\">[</bpt><bpt id=\"p6\">**</bpt>Deflate<ept id=\"p6\">**</ept><ept id=\"p5\">][deflate-110]</ept> 编解码器的 .NET Framework 4.5 实现，后者基于 <bpt id=\"p7\">[</bpt>zlib<ept id=\"p7\">](http://zlib.net/)</ept> 压缩库提供比默认的 .NET Framework 4.0 版本更好的压缩算法。"
    },
    {
      "pos": [
        57311,
        57372
      ],
      "content": "<ph id=\"ph1\">&lt;a name=\"Scenario6\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>示例 6：使用 Avro 上载 Azure HDInsight 服务的数据"
    },
    {
      "pos": [
        57374,
        57478
      ],
      "content": "第六个示例演示与 Azure HDInsight 服务交互相关的一些编程技巧。包含此示例代码的样例可以从 <bpt id=\"p1\">[</bpt>Azure 代码示例<ept id=\"p1\">](https://github.com/Azure-Samples)</ept>站点下载。"
    },
    {
      "content": "该示例将执行以下操作：",
      "pos": [
        57480,
        57491
      ]
    },
    {
      "content": "连接到现有的 HDInsight 服务群集。",
      "pos": [
        57495,
        57517
      ]
    },
    {
      "pos": [
        57520,
        57763
      ],
      "content": "序列化多个 CSV 文件并将结果上载到 Azure Blob 存储。（CSV 文件随着示例一起分发，而且代表 <bpt id=\"p1\">[</bpt>Infochimps<ept id=\"p1\">](http://www.infochimps.com/)</ept> 在 1970 年到 2010 年期间提取自 AMEX 股票的历史记录数据。该示例将读取 CSV 文件数据、将记录转换为 <bpt id=\"p2\">**</bpt>Stock<ept id=\"p2\">**</ept> 类的实例，然后使用反射序列化这些实例。Stock 类型定义是使用 Microsoft Avro Library 代码生成实用工具从 JSON 架构创建的。"
    },
    {
      "pos": [
        57766,
        57814
      ],
      "content": "在 Hive 中创建名为 <bpt id=\"p1\">**</bpt>Stocks<ept id=\"p1\">**</ept> 的新外部表，并将它链接到前一个步骤中上载的数据。"
    },
    {
      "pos": [
        57817,
        57844
      ],
      "content": "使用 Hive 对 <bpt id=\"p1\">**</bpt>Stocks<ept id=\"p1\">**</ept> 表执行查询。"
    },
    {
      "content": "此外，该示例将在执行主要操作之前和之后执行清理过程。在清理期间，将删除所有相关的 Azure Blob 数据和文件夹，并删除 Hive 表。你也可以从示例命令行调用清理过程。",
      "pos": [
        57846,
        57933
      ]
    },
    {
      "content": "该示例要求满足以下先决条件：",
      "pos": [
        57935,
        57949
      ]
    },
    {
      "content": "有效的 Azure 订阅及其订阅 ID。",
      "pos": [
        57953,
        57973
      ]
    },
    {
      "content": "包含相应私钥的订阅管理证书。该证书应安装在用于运行示例的计算机上的当前用户私用存储中。",
      "pos": [
        57976,
        58019
      ]
    },
    {
      "content": "活动的 HDInsight 群集。",
      "pos": [
        58022,
        58039
      ]
    },
    {
      "content": "在先前的必要条件中链接到 HDInsight 群集的 Azure 存储帐户，以及相应的主要或辅助访问密钥。",
      "pos": [
        58042,
        58095
      ]
    },
    {
      "content": "运行示例之前，必要条件中的所有信息均应输入到示例配置文件中。要运行此操作有两个可行的方式：",
      "pos": [
        58097,
        58142
      ]
    },
    {
      "content": "编辑示例根目录中的 app.config 文件，然后生成示例，或",
      "pos": [
        58146,
        58178
      ]
    },
    {
      "content": "先生成示例，然后在生成目录中编辑 AvroHDISample.exe.config",
      "pos": [
        58181,
        58222
      ]
    },
    {
      "content": "在这两个情况下，所有编辑均应该在 <bpt id=\"p1\">**</bpt><ph id=\"ph1\">&lt;appSettings&gt;</ph><ept id=\"p1\">**</ept> 设置节中完成。请遵循文件中的注释。",
      "pos": [
        58224,
        58276
      ]
    },
    {
      "content": "执行以下命令从命令行运行该示例（其中，包含该示例的 .zip 文件假设已解压缩到 C:\\\\AvroHDISample；如果不是，请使用相关的文件路径）：",
      "pos": [
        58277,
        58353
      ]
    },
    {
      "content": "若要清理群集，请运行以下命令：",
      "pos": [
        58400,
        58415
      ]
    }
  ],
  "content": "<properties\n    pageTitle=\"使用 Microsoft Avro Library 序列化数据 | Azure\"\n    description=\"了解 Azure HDInsight 如何使用 Avro 来序列化大数据。\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    tags=\"azure-portal\"\n    authors=\"mumian\" \n    manager=\"paulettm\"\n    editor=\"cgronlun\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.date=\"02/04/2015\"\n    wacn.date=\"03/17/2016\"/>\n\n\n# 使用 Microsoft Avro Library 序列化 Hadoop 中的数据\n\n本主题演示如何使用 <a href=\"https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library\" target=\"_blank\">Microsoft Avro Library</a> 将对象及其他数据结构序列化为流，以便将它们持久保存到内存、数据库或文件中，同时还演示如何对这些流进行反序列化以恢复原始对象。\n\n[AZURE.INCLUDE [仅适用于 Windows](../includes/hdinsight-windows-only.md)]\n\n##<a name=\"apacheAvro\"></a>Apache Avro\n<a href=\"https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library\" target=\"_blank\">Microsoft Avro Library</a> 针对 Microsoft.NET 环境实现了 Apache Avro 数据序列化系统。Apache Avro 为序列化提供了一种紧凑的二进制数据交换格式。它使用 <a href=\"http://www.json.org\" target=\"_blank\">JSON</a> 定义与语言无关的架构，以支持语言互操作性。以一种语言序列化的数据可以用另一种语言读取。目前支持 C、C++、C#、Java、PHP、Python 和 Ruby。有关格式的详细信息可以在 <a href=\"http://avro.apache.org/docs/current/spec.html\" target=\"_blank\">Apache Avro 规范</a>中找到。请注意，Microsoft Avro Library 的当前版本不支持此规范的远程过程调用 (RPC) 部分。\n\nAvro 系统中的对象的序列化表示形式由两部分组成：架构和实际值。Avro 架构使用 JSON 描述已序列化数据的与语言无关的数据模型。它与数据的二进制表示形式并排显示。将架构与二进制表示形式分离，使写入每个对象时没有针对值的开销，从而实现快速序列化和较小的表示形式。\n\n##<a name=\"hadoopScenario\"></a>Hadoop 应用场景\nApache Avro 序列化格式广泛应用于 Azure HDInsight 及其他 Apache Hadoop 环境中。Avro 提供了简便的方法来表示 Hadoop MapReduce 作业内的复杂数据结构。Avro 文件（Avro 对象容器文件）格式已设计为支持分布式 MapReduce 编程模型。实现分布的关键功能是文件是“可拆分的”，也就是说，用户可以在文件中搜寻任一点，然后即可从某一特定块开始读取。\n\n##<a name=\"serializationMAL\"></a>Microsoft Avro Library 中的序列化\n.NET Library for Avro 支持通过两种方式序列化对象：\n\n- **反射** - 自动从要序列化的 .NET 类型的数据协定特性生成这些类型的 JSON 架构。\n- **通用记录** - 当没有 .NET 类型可以用来描述要序列化的数据的架构时，系统会在以 [**AvroRecord**](http://msdn.microsoft.com/zh-cn/library/microsoft.hadoop.avro.avrorecord.aspx) 类表示的记录中显式指定 JSON 架构。\n\n当流的写入器和读取器都知道数据架构时，可以发送没有架构的数据。在未使用 Avro 对象容器文件的情况下，架构将存储在文件中。可以指定其他参数，例如用于数据压缩的编解码器。这些情况将在下面的代码示例中进一步详述和说明。\n\n\n##<a name=\"prerequisites\"></a> 安装 Avro Library\n\n以下是安装此库之前所需具备的先决条件：\n\n- <a href=\"http://www.microsoft.com/download/details.aspx?id=17851\" target=\"_blank\">Microsoft .NET Framework 4</a>\n- <a href=\"http://james.newtonking.com/json\" target=\"_blank\">Newtonsoft Json.NET</a>（6.0.4 或更高版本）\n\n请注意，Newtonsoft.Json.dll 依赖项已随着 Microsoft Avro Library 的安装自动下载。下一部分将提供此操作的相关过程。\n\n\nMicrosoft Avro Library 以 NuGet 包发行，你可以使用以下过程在 Visual Studio 中安装 NuGet 程序包：\n\n1. 选择“项目”选项卡->“管理 NuGet 包...”\n2. 在“联机搜索”框中，搜索“Microsoft.Hadoop.Avro”。\n3. 单击“Azure HDInsight Avro Library”旁边的“安装”按钮。\n\n请注意，Newtonsoft.Json.dll (>= 6.0.4) 依赖项也将随 Microsoft Avro Library 一起自动下载。\n\n你可能需要浏览 <a href=\"https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library\" target=\"_blank\">Microsoft Avro Library 主页</a>以阅读最新的发行说明。\n\n\n<a href=\"https://hadoopsdk.codeplex.com/wikipage?title=Avro%20Library\" target=\"_blank\">Microsoft Avro Library 主页</a>中提供了 Microsoft Avro Library 源代码。\n\n##<a name=\"compiling\"></a>使用 Avro Library 编译架构\n\nMicrosoft Avro Library 包含代码生成实用工具，可让你自动根据先前定义的 JSON 架构来创建 C# 类型。代码生成实用工具不是以二进制可执行文件的形式分发的，但你可使用以下过程轻松生成：\n\n1. 从 <a href=\"http://hadoopsdk.codeplex.com/SourceControl/latest\" target=\"_blank\">Microsoft .NET SDK For Hadoop</a> 下载包含最新版 HDInsight SDK 源代码的 ZIP 文件。（单击“下载”图标。）\n\n2. 将 HDInsight SDK 解压缩到已安装 .NET Framework 4.0 并连接到 Internet 的计算机上的目录，以下载必要的依赖项 NuGet 包。下面我们假设源代码已解压缩到 C:\\\\SDK。\n\n3. 转到文件夹 C:\\\\SDK\\\\src\\\\Microsoft.Hadoop.Avro.Tools 并运行 build.bat。（此文件将从 .NET Framework 的 32 位分发版调用 MSBuild。如果你想要使用 64 位版本，请编辑 build.bat 文件注释后的列。） 确保生成成功。（在某些系统上，MSBuild 可能生成警告。只要没有生成错误，这些警告就不影响实用工具。）\n\n4. 编译的实用工具位于 C:\\\\SDK\\\\Bin\\\\Unsigned\\\\Release\\\\Microsoft.Hadoop.Avro.Tools 中。\n\n\n若要熟悉命令行语法，请从代码生成实用工具所在的文件夹运行以下命令：`Microsoft.Hadoop.Avro.Tools help /c:codegen`\n\n若要测试实用工具，你可以从随着源代码提供的示例 JSON 架构文件生成 C# 类。运行以下命令：\n\n    Microsoft.Hadoop.Avro.Tools codegen /i:C:\\SDK\\src\\Microsoft.Hadoop.Avro.Tools\\SampleJSON\\SampleJSONSchema.avsc /o:\n\n这应该在当前目录中生成两个 C# 文件：SensorData.cs 和 Location.cs。\n\n若要了解代码生成实用工具在转换 JSON 架构为 C# 类型时使用的逻辑，请参阅 C:\\\\SDK\\\\src\\\\Microsoft.Hadoop.Avro.Tools\\\\Doc 中的 GenerationVerification.feature 文件。\n\n请注意，该命名空间是使用上一个段落中提及的文件中所描述的逻辑，从 JSON 架构中提取。从架构提取的命名空间，将比实用工具命令行中使用 /n 参数提供的设置具有优先权。如果你想要重写架构中包含的命名空间，请确保使用 /nf 参数。例如，若要将所有命名空间从 SampleJSONSchema.avsc 更改为 my.own.nspace，请运行以下命令：\n\n    Microsoft.Hadoop.Avro.Tools codegen /i:C:\\SDK\\src\\Microsoft.Hadoop.Avro.Tools\\SampleJSON\\SampleJSONSchema.avsc /o:. /nf:my.own.nspace\n\n##<a name=\"samples\"></a> 示例\n本主题中提供的六个示例演示了 Microsoft Avro Library 所支持的不同方案。Microsoft Avro Library 设计为可处理任何流。在这些示例中，为保持简单性和一致性，是使用内存流（而不是文件流或数据库）来操作数据的。在生产环境中所采取的方法将取决于实际的方案要求、数据源和卷、性能限制及其他因素。\n\n前两个示例显示如何使用反射和通用记录将数据序列化到内存流缓冲区，以及如何进行反序列化。这两个方案假设在读取器和写入器之间共享架构。\n\n第三和第四个示例说明如何使用 Avro 对象容器文件，将数据序列化与反序列化。当数据存储在 Avro 容器文件中时，其架构始终随之一起存储，因为必须共享架构才能进行反序列化。\n\n包含前四个示例的样例可以从 <a href=\"https://github.com/Azure-Samples\" target=\"_blank\">Azure 代码示例</a>站点下载。\n\n第五个示例演示如何将自定义压缩编解码器用于 Avro 对象容器文件。包含此示例代码的样例可以从 <a href=\"https://github.com/Azure-Samples\" target=\"_blank\">Azure 代码示例</a>站点下载。\n\n第六个示例显示如何使用 Avro 序列化来上载数据到 Azure Blob 存储，然后使用具有 HDInsight (Hadoop) 群集的 Hive 加以分析。可以从 <a href=\"https://github.com/Azure-Samples\" target=\"_blank\">Azure 代码示例</a>站点下载该示例。\n\n以下是本主题所讨论的六个示例的链接：\n\n * <a href=\"#Scenario1\">**通过反射进行序列化**</a> - 自动从数据协定特性生成要序列化的类型的 JSON 架构。\n * <a href=\"#Scenario2\">**通过通用记录进行序列化**</a> - 当没有可用于反射的 .NET 类型时，在记录中显式指定 JSON 架构。\n * <a href=\"#Scenario3\">**使用对象容器文件与反射进行序列化**</a> - JSON 架构自动生成并使用 Avro 对象容器文件随着序列化的数据共享。\n * <a href=\"#Scenario4\">**使用对象容器文件与通用记录进行序列化**</a> - JSON 架构是在序列化前显式指定的，并使用 Avro 对象容器文件随着序列化的数据共享。\n * <a href=\"#Scenario5\">**使用对象容器文件和自定义压缩编解码器进行序列化**</a> - 该示例演示如何使用 Deflate 数据压缩编解码器的自定义 .NET 实现，来创建 Avro 对象容器文件。\n * <a href=\"#Scenario6\">**使用 Avro 来上载 Azure HDInsight 服务的数据**</a> - 该示例演示 Avro 序列化如何与 HDInsight 服务交互。要运行此示例，你必须具备有效的 Azure 订阅并且可以访问 Azure HDInsight 群集。\n\n###<a name=\"Scenario1\"></a>示例 1：通过反射进行序列化\n\nMicrosoft Avro Library 可以使用反射从要序列化的 C# 对象的数据协定特性自动生成类型的 JSON 架构。Microsoft Avro Library 将创建一个 [**IAvroSeralizer<T>**](http://msdn.microsoft.com/zh-cn/library/dn627341.aspx) 以标识要序列化的字段。\n\n在此示例中，将对象（具有成员 **Location** 结构的 **SensorData** 类）序列化到内存流，继而又将此流反序列化。然后，将结果与初始实例进行比较，以确认恢复的 **SensorData** 对象与原始对象相同。\n\n此示例中的架构假定在读取器与写入器之间共享，因此无需采用 Avro 对象容器格式。有关在架构必须与数据一起共享时，如何使用反射和对象容器格式将数据序列化到内存缓冲区，以及如何对内存缓冲区中的数据进行反序列化的示例，请参阅<a href=\"#Scenario3\">使用对象容器文件通过反射进行序列化</a>。\n\n    namespace Microsoft.Hadoop.Avro.Sample\n    {\n        using System;\n        using System.Collections.Generic;\n        using System.IO;\n        using System.Linq;\n        using System.Runtime.Serialization;\n        using Microsoft.Hadoop.Avro.Container;\n        using Microsoft.Hadoop.Avro;\n\n        //Sample class used in serialization samples\n        [DataContract(Name = \"SensorDataValue\", Namespace = \"Sensors\")]\n        internal class SensorData\n        {\n            [DataMember(Name = \"Location\")]\n            public Location Position { get; set; }\n\n            [DataMember(Name = \"Value\")]\n            public byte[] Value { get; set; }\n        }\n\n        //Sample struct used in serialization samples\n        [DataContract]\n        internal struct Location\n        {\n            [DataMember]\n            public int Floor { get; set; }\n\n            [DataMember]\n            public int Room { get; set; }\n        }\n\n        //This class contains all methods demonstrating\n        //the usage of Microsoft Avro Library\n        public class AvroSample\n        {\n\n            //Serialize and deserialize sample data set represented as an object using reflection.\n            //No explicit schema definition is required - schema of serialized objects is automatically built.\n            public void SerializeDeserializeObjectUsingReflection()\n            {\n\n                Console.WriteLine(\"SERIALIZATION USING REFLECTION\\n\");\n                Console.WriteLine(\"Serializing Sample Data Set...\");\n\n                //Create a new AvroSerializer instance and specify a custom serialization strategy AvroDataContractResolver\n                //for serializing only properties attributed with DataContract/DateMember\n                var avroSerializer = AvroSerializer.Create<SensorData>();\n\n                //Create a memory stream buffer\n                using (var buffer = new MemoryStream())\n                {\n                    //Create a data set by using sample class and struct\n                    var expected = new SensorData { Value = new byte[] { 1, 2, 3, 4, 5 }, Position = new Location { Room = 243, Floor = 1 } };\n\n                    //Serialize the data to the specified stream\n                    avroSerializer.Serialize(buffer, expected);\n\n\n                    Console.WriteLine(\"Deserializing Sample Data Set...\");\n\n                    //Prepare the stream for deserializing the data\n                    buffer.Seek(0, SeekOrigin.Begin);\n\n                    //Deserialize data from the stream and cast it to the same type used for serialization\n                    var actual = avroSerializer.Deserialize(buffer);\n\n                    Console.WriteLine(\"Comparing Initial and Deserialized Data Sets...\");\n\n                    //Finally, verify that deserialized data matches the original one\n                    bool isEqual = this.Equal(expected, actual);\n\n                    Console.WriteLine(\"Result of Data Set Identity Comparison is {0}\", isEqual);\n\n                }\n            }\n\n            //\n            //Helper methods\n            //\n\n            //Comparing two SensorData objects\n            private bool Equal(SensorData left, SensorData right)\n            {\n                return left.Position.Equals(right.Position) && left.Value.SequenceEqual(right.Value);\n            }\n\n\n\n            static void Main()\n            {\n\n                string sectionDivider = \"---------------------------------------- \";\n\n                //Create an instance of AvroSample Class and invoke methods\n                //illustrating different serializing approaches\n                AvroSample Sample = new AvroSample();\n\n                //Serialization to memory using reflection\n                Sample.SerializeDeserializeObjectUsingReflection();\n\n                Console.WriteLine(sectionDivider);\n                Console.WriteLine(\"Press any key to exit.\");\n                Console.Read();\n            }\n        }\n    }\n    // The example is expected to display the following output:\n    // SERIALIZATION USING REFLECTION\n    //\n    // Serializing Sample Data Set...\n    // Deserializing Sample Data Set...\n    // Comparing Initial and Deserialized Data Sets...\n    // Result of Data Set Identity Comparison is True\n    // ----------------------------------------\n    // Press any key to exit.\n\n\n###<a name=\"Scenario2\"></a>示例 2：通过通用记录进行序列化\n\n当数据无法使用具有数据协定的 .NET 类表示而导致不能使用反射时，可以在通用记录中显式指定 JSON 架构。此方法通常比使用反射要慢。在这种情况下，数据架构也可能是动态的，因为在编译之前它是未知的。以逗号分隔值 (CSV) 文件表示的数据（在运行时转换为 Avro 格式之前，其架构一直是未知的）是这种动态方案的一个示例。\n\n此示例演示如何创建 [**AvroRecord**](http://msdn.microsoft.com/zh-cn/library/microsoft.hadoop.avro.avrorecord.aspx) 并使用它显式指定 JSON 架构，如何为其填充数据，然后对其进行序列化和反序列化。然后，将结果与初始实例进行比较，以确认恢复的记录与原始记录相同。\n\n此示例中的架构假定在读取器与写入器之间共享，因此无需采用 Avro 对象容器格式。有关在架构必须包含在已序列化的数据中时，如何使用通用记录和对象容器格式将数据序列化到内存缓冲区，以及对内存缓冲区中的数据进行反序列化的示例，请参阅<a href=\"#Scenario4\">使用对象容器文件通过通用记录进行序列化</a>示例。\n\n\n    namespace Microsoft.Hadoop.Avro.Sample\n    {\n    using System;\n    using System.Collections.Generic;\n    using System.IO;\n    using System.Linq;\n    using System.Runtime.Serialization;\n    using Microsoft.Hadoop.Avro.Container;\n    using Microsoft.Hadoop.Avro.Schema;\n    using Microsoft.Hadoop.Avro;\n\n    //This class contains all methods demonstrating\n    //the usage of Microsoft Avro Library\n    public class AvroSample\n    {\n\n        //Serialize and deserialize sample data set by using a generic record.\n        //A generic record is a special class with the schema explicitly defined in JSON.\n        //All serialized data should be mapped to the fields of the generic record,\n        //which in turn will be then serialized.\n        public void SerializeDeserializeObjectUsingGenericRecords()\n        {\n            Console.WriteLine(\"SERIALIZATION USING GENERIC RECORD\\n\");\n            Console.WriteLine(\"Defining the Schema and creating Sample Data Set...\");\n\n            //Define the schema in JSON\n            const string Schema = @\"{\n                                \"\"type\"\":\"\"record\"\",\n                                \"\"name\"\":\"\"Microsoft.Hadoop.Avro.Specifications.SensorData\"\",\n                                \"\"fields\"\":\n                                    [\n                                        {\n                                            \"\"name\"\":\"\"Location\"\",\n                                            \"\"type\"\":\n                                                {\n                                                    \"\"type\"\":\"\"record\"\",\n                                                    \"\"name\"\":\"\"Microsoft.Hadoop.Avro.Specifications.Location\"\",\n                                                    \"\"fields\"\":\n                                                        [\n                                                            { \"\"name\"\":\"\"Floor\"\", \"\"type\"\":\"\"int\"\" },\n                                                            { \"\"name\"\":\"\"Room\"\", \"\"type\"\":\"\"int\"\" }\n                                                        ]\n                                                }\n                                        },\n                                        { \"\"name\"\":\"\"Value\"\", \"\"type\"\":\"\"bytes\"\" }\n                                    ]\n                            }\";\n\n            //Create a generic serializer based on the schema\n            var serializer = AvroSerializer.CreateGeneric(Schema);\n            var rootSchema = serializer.WriterSchema as RecordSchema;\n\n            //Create a memory stream buffer\n            using (var stream = new MemoryStream())\n            {\n                //Create a generic record to represent the data\n                dynamic location = new AvroRecord(rootSchema.GetField(\"Location\").TypeSchema);\n                location.Floor = 1;\n                location.Room = 243;\n\n                dynamic expected = new AvroRecord(serializer.WriterSchema);\n                expected.Location = location;\n                expected.Value = new byte[] { 1, 2, 3, 4, 5 };\n\n                Console.WriteLine(\"Serializing Sample Data Set...\");\n\n                //Serialize the data\n                serializer.Serialize(stream, expected);\n\n                stream.Seek(0, SeekOrigin.Begin);\n\n                Console.WriteLine(\"Deserializing Sample Data Set...\");\n\n                //Deserialize the data into a generic record\n                dynamic actual = serializer.Deserialize(stream);\n\n                Console.WriteLine(\"Comparing Initial and Deserialized Data Sets...\");\n\n                //Finally, verify the results\n                bool isEqual = expected.Location.Floor.Equals(actual.Location.Floor);\n                isEqual = isEqual && expected.Location.Room.Equals(actual.Location.Room);\n                isEqual = isEqual && ((byte[])expected.Value).SequenceEqual((byte[])actual.Value);\n                Console.WriteLine(\"Result of Data Set Identity Comparison is {0}\", isEqual);\n            }\n        }\n\n        static void Main()\n        {\n\n            string sectionDivider = \"---------------------------------------- \";\n\n            //Create an instance of AvroSample class and invoke methods\n            //illustrating different serializing approaches\n            AvroSample Sample = new AvroSample();\n\n            //Serialization to memory using generic record\n            Sample.SerializeDeserializeObjectUsingGenericRecords();\n\n            Console.WriteLine(sectionDivider);\n            Console.WriteLine(\"Press any key to exit.\");\n            Console.Read();\n        }\n    }\n    }\n    // The example is expected to display the following output:\n    // SERIALIZATION USING GENERIC RECORD\n    //\n    // Defining the Schema and creating Sample Data Set...\n    // Serializing Sample Data Set...\n    // Deserializing Sample Data Set...\n    // Comparing Initial and Deserialized Data Sets...\n    // Result of Data Set Identity Comparison is True\n    // ----------------------------------------\n    // Press any key to exit.\n\n\n###<a name=\"Scenario3\"></a>示例 3：使用对象容器文件进行序列化与使用反射进行序列化\n\n此示例与<a href=\"#Scenario1\">第一个示例</a>中使用反射隐式指定架构的方案类似。除了本示例假设要将架构反序列化的读取器不知道架构以外。要序列化的 **SensorData** 对象及其隐式指定的架构存储在由 [**AvroContainer**](http://msdn.microsoft.com/zh-cn/library/microsoft.hadoop.avro.container.avrocontainer.aspx) 类表示的 Avro 对象容器文件中。\n\n在此示例中，数据使用 [**SequentialWriter<SensorData>**](http://msdn.microsoft.com/zh-cn/library/dn627340.aspx) 进行序列化，使用 [**SequentialReader<SensorData>**](http://msdn.microsoft.com/zh-cn/library/dn627340.aspx) 进行反序列化。然后，将结果与初始实例比较，以确保相同。\n\n对象容器文件中的数据是通过 .NET Framework 4 中的默认 [**Deflate**][deflate-100] 压缩编解码器压缩的。请参阅本主题中的<a href=\"#Scenario5\">第五个示例</a>，了解如何使用 .NET Framework 4.5 中提供的更新的 [**Deflate**][deflate-110] 压缩编解码器高级版。\n\n    namespace Microsoft.Hadoop.Avro.Sample\n    {\n        using System;\n        using System.Collections.Generic;\n        using System.IO;\n        using System.Linq;\n        using System.Runtime.Serialization;\n        using Microsoft.Hadoop.Avro.Container;\n        using Microsoft.Hadoop.Avro;\n\n        //Sample class used in serialization samples\n        [DataContract(Name = \"SensorDataValue\", Namespace = \"Sensors\")]\n        internal class SensorData\n        {\n            [DataMember(Name = \"Location\")]\n            public Location Position { get; set; }\n\n            [DataMember(Name = \"Value\")]\n            public byte[] Value { get; set; }\n        }\n\n        //Sample struct used in serialization samples\n        [DataContract]\n        internal struct Location\n        {\n            [DataMember]\n            public int Floor { get; set; }\n\n            [DataMember]\n            public int Room { get; set; }\n        }\n\n        //This class contains all methods demonstrating\n        //the usage of Microsoft Avro Library\n        public class AvroSample\n        {\n\n            //Serializes and deserializes the sample data set by using reflection and Avro object container files.\n            //Serialized data is compressed with the Deflate codec.\n            public void SerializeDeserializeUsingObjectContainersReflection()\n            {\n\n                Console.WriteLine(\"SERIALIZATION USING REFLECTION AND AVRO OBJECT CONTAINER FILES\\n\");\n\n                //Path for Avro object container file\n                string path = \"AvroSampleReflectionDeflate.avro\";\n\n                //Create a data set by using sample class and struct\n                var testData = new List<SensorData>\n                        {\n                            new SensorData { Value = new byte[] { 1, 2, 3, 4, 5 }, Position = new Location { Room = 243, Floor = 1 } },\n                            new SensorData { Value = new byte[] { 6, 7, 8, 9 }, Position = new Location { Room = 244, Floor = 1 } }\n                        };\n\n                //Serializing and saving data to file.\n                //Creating a memory stream buffer.\n                using (var buffer = new MemoryStream())\n                {\n                    Console.WriteLine(\"Serializing Sample Data Set...\");\n\n                    //Create a SequentialWriter instance for type SensorData, which can serialize a sequence of SensorData objects to stream.\n                    //Data will be compressed using the Deflate codec.\n                    using (var w = AvroContainer.CreateWriter<SensorData>(buffer, Codec.Deflate))\n                    {\n                        using (var writer = new SequentialWriter<SensorData>(w, 24))\n                        {\n                            // Serialize the data to stream by using the sequential writer\n                            testData.ForEach(writer.Write);\n                        }\n                    }\n\n                    //Save stream to file\n                    Console.WriteLine(\"Saving serialized data to file...\");\n                    if (!WriteFile(buffer, path))\n                    {\n                        Console.WriteLine(\"Error during file operation. Quitting method\");\n                        return;\n                    }\n                }\n\n                //Reading and deserializing data.\n                //Creating a memory stream buffer.\n                using (var buffer = new MemoryStream())\n                {\n                    Console.WriteLine(\"Reading data from file...\");\n\n                    //Reading data from object container file\n                    if (!ReadFile(buffer, path))\n                    {\n                        Console.WriteLine(\"Error during file operation. Quitting method\");\n                        return;\n                    }\n\n                    Console.WriteLine(\"Deserializing Sample Data Set...\");\n\n                    //Prepare the stream for deserializing the data\n                    buffer.Seek(0, SeekOrigin.Begin);\n\n                    //Create a SequentialReader instance for type SensorData, which will deserialize all serialized objects from the given stream.\n                    //It allows iterating over the deserialized objects because it implements the IEnumerable<T> interface.\n                    using (var reader = new SequentialReader<SensorData>(\n                        AvroContainer.CreateReader<SensorData>(buffer, true)))\n                    {\n                        var results = reader.Objects;\n\n                        //Finally, verify that deserialized data matches the original one\n                        Console.WriteLine(\"Comparing Initial and Deserialized Data Sets...\");\n                        int count = 1;\n                        var pairs = testData.Zip(results, (serialized, deserialized) => new { expected = serialized, actual = deserialized });\n                        foreach (var pair in pairs)\n                        {\n                            bool isEqual = this.Equal(pair.expected, pair.actual);\n                            Console.WriteLine(\"For Pair {0} result of Data Set Identity Comparison is {1}\", count, isEqual);\n                            count++;\n                        }\n                    }\n                }\n\n                //Delete the file\n                RemoveFile(path);\n            }\n\n            //\n            //Helper methods\n            //\n\n            //Comparing two SensorData objects\n            private bool Equal(SensorData left, SensorData right)\n            {\n                return left.Position.Equals(right.Position) && left.Value.SequenceEqual(right.Value);\n            }\n\n            //Saving memory stream to a new file with the given path\n            private bool WriteFile(MemoryStream InputStream, string path)\n            {\n                if (!File.Exists(path))\n                {\n                    try\n                    {\n                        using (FileStream fs = File.Create(path))\n                        {\n                            InputStream.Seek(0, SeekOrigin.Begin);\n                            InputStream.CopyTo(fs);\n                        }\n                        return true;\n                    }\n                    catch (Exception e)\n                    {\n                        Console.WriteLine(\"The following exception was thrown during creation and writing to the file \"{0}\"\", path);\n                        Console.WriteLine(e.Message);\n                        return false;\n                    }\n                }\n                else\n                {\n                    Console.WriteLine(\"Can not create file \"{0}\". File already exists\", path);\n                    return false;\n\n                }\n            }\n\n            //Reading a file content by using the given path to a memory stream\n            private bool ReadFile(MemoryStream OutputStream, string path)\n            {\n                try\n                {\n                    using (FileStream fs = File.Open(path, FileMode.Open))\n                    {\n                        fs.CopyTo(OutputStream);\n                    }\n                    return true;\n                }\n                catch (Exception e)\n                {\n                    Console.WriteLine(\"The following exception was thrown during reading from the file \"{0}\"\", path);\n                    Console.WriteLine(e.Message);\n                    return false;\n                }\n            }\n\n            //Deleting file by using given path\n            private void RemoveFile(string path)\n            {\n                if (File.Exists(path))\n                {\n                    try\n                    {\n                        File.Delete(path);\n                    }\n                    catch (Exception e)\n                    {\n                        Console.WriteLine(\"The following exception was thrown during deleting the file \"{0}\"\", path);\n                        Console.WriteLine(e.Message);\n                    }\n                }\n                else\n                {\n                    Console.WriteLine(\"Can not delete file \"{0}\". File does not exist\", path);\n                }\n            }\n\n            static void Main()\n            {\n\n                string sectionDivider = \"---------------------------------------- \";\n\n                //Create an instance of AvroSample class and invoke methods\n                //illustrating different serializing approaches\n                AvroSample Sample = new AvroSample();\n\n                //Serialization using reflection to Avro object container file\n                Sample.SerializeDeserializeUsingObjectContainersReflection();\n\n                Console.WriteLine(sectionDivider);\n                Console.WriteLine(\"Press any key to exit.\");\n                Console.Read();\n            }\n        }\n    }\n    // The example is expected to display the following output:\n    // SERIALIZATION USING REFLECTION AND AVRO OBJECT CONTAINER FILES\n    //\n    // Serializing Sample Data Set...\n    // Saving serialized data to file...\n    // Reading data from file...\n    // Deserializing Sample Data Set...\n    // Comparing Initial and Deserialized Data Sets...\n    // For Pair 1 result of Data Set Identity Comparison is True\n    // For Pair 2 result of Data Set Identity Comparison is True\n    // ----------------------------------------\n    // Press any key to exit.\n\n\n###<a name=\"Scenario4\"></a>示例 4：使用对象容器文件进行序列化与使用通用记录进行序列化\n\n此示例与<a href=\"#Scenario2\">第二个示例</a>中使用 JSON 显式指定架构的方案类似。除了本示例假设要将架构反序列化的读取器不知道架构以外。\n\n测试数据集将通过显式定义的 JSON 架构收集到 [**AvroRecord**](http://msdn.microsoft.com/zh-cn/library/microsoft.hadoop.avro.avrorecord.aspx) 对象列表中，然后存储在由 [**AvroContainer**](http://msdn.microsoft.com/zh-cn/library/microsoft.hadoop.avro.container.avrocontainer.aspx) 类表示的对象容器文件中。此容器文件将创建一个写入器，该写入器用于将未压缩的数据序列化到内存流，然后将该内存流保存到文件中。指定不要压缩此数据的是创建读取器时所用的 [**Codex.Null**](http://msdn.microsoft.com/zh-cn/library/microsoft.hadoop.avro.container.codec.null.aspx) 参数。\n\n然后，从文件中读取数据，并将数据反序列化为对象的集合。将此集合与 Avro 记录的初始列表进行比较，以确认它们相同。\n\n\n    namespace Microsoft.Hadoop.Avro.Sample\n    {\n        using System;\n        using System.Collections.Generic;\n        using System.IO;\n        using System.Linq;\n        using System.Runtime.Serialization;\n        using Microsoft.Hadoop.Avro.Container;\n        using Microsoft.Hadoop.Avro.Schema;\n        using Microsoft.Hadoop.Avro;\n\n        //This class contains all methods demonstrating\n        //the usage of Microsoft Avro Library\n        public class AvroSample\n        {\n\n            //Serializes and deserializes a sample data set by using a generic record and Avro object container files.\n            //Serialized data is not compressed.\n            public void SerializeDeserializeUsingObjectContainersGenericRecord()\n            {\n                Console.WriteLine(\"SERIALIZATION USING GENERIC RECORD AND AVRO OBJECT CONTAINER FILES\\n\");\n\n                //Path for Avro object container file\n                string path = \"AvroSampleGenericRecordNullCodec.avro\";\n\n                Console.WriteLine(\"Defining the Schema and creating Sample Data Set...\");\n\n                //Define the schema in JSON\n                const string Schema = @\"{\n                                \"\"type\"\":\"\"record\"\",\n                                \"\"name\"\":\"\"Microsoft.Hadoop.Avro.Specifications.SensorData\"\",\n                                \"\"fields\"\":\n                                    [\n                                        {\n                                            \"\"name\"\":\"\"Location\"\",\n                                            \"\"type\"\":\n                                                {\n                                                    \"\"type\"\":\"\"record\"\",\n                                                    \"\"name\"\":\"\"Microsoft.Hadoop.Avro.Specifications.Location\"\",\n                                                    \"\"fields\"\":\n                                                        [\n                                                            { \"\"name\"\":\"\"Floor\"\", \"\"type\"\":\"\"int\"\" },\n                                                            { \"\"name\"\":\"\"Room\"\", \"\"type\"\":\"\"int\"\" }\n                                                        ]\n                                                }\n                                        },\n                                        { \"\"name\"\":\"\"Value\"\", \"\"type\"\":\"\"bytes\"\" }\n                                    ]\n                            }\";\n\n                //Create a generic serializer based on the schema\n                var serializer = AvroSerializer.CreateGeneric(Schema);\n                var rootSchema = serializer.WriterSchema as RecordSchema;\n\n                //Create a generic record to represent the data\n                var testData = new List<AvroRecord>();\n\n                dynamic expected1 = new AvroRecord(rootSchema);\n                dynamic location1 = new AvroRecord(rootSchema.GetField(\"Location\").TypeSchema);\n                location1.Floor = 1;\n                location1.Room = 243;\n                expected1.Location = location1;\n                expected1.Value = new byte[] { 1, 2, 3, 4, 5 };\n                testData.Add(expected1);\n\n                dynamic expected2 = new AvroRecord(rootSchema);\n                dynamic location2 = new AvroRecord(rootSchema.GetField(\"Location\").TypeSchema);\n                location2.Floor = 1;\n                location2.Room = 244;\n                expected2.Location = location2;\n                expected2.Value = new byte[] { 6, 7, 8, 9 };\n                testData.Add(expected2);\n\n                //Serializing and saving data to file.\n                //Create a MemoryStream buffer.\n                using (var buffer = new MemoryStream())\n                {\n                    Console.WriteLine(\"Serializing Sample Data Set...\");\n\n                    //Create a SequentialWriter instance for type SensorData, which can serialize a sequence of SensorData objects to stream.\n                    //Data will not be compressed (Null compression codec).\n                    using (var writer = AvroContainer.CreateGenericWriter(Schema, buffer, Codec.Null))\n                    {\n                        using (var streamWriter = new SequentialWriter<object>(writer, 24))\n                        {\n                            // Serialize the data to stream by using the sequential writer\n                            testData.ForEach(streamWriter.Write);\n                        }\n                    }\n\n                    Console.WriteLine(\"Saving serialized data to file...\");\n\n                    //Save stream to file\n                    if (!WriteFile(buffer, path))\n                    {\n                        Console.WriteLine(\"Error during file operation. Quitting method\");\n                        return;\n                    }\n                }\n\n                //Reading and deserializing the data.\n                //Create a memory stream buffer.\n                using (var buffer = new MemoryStream())\n                {\n                    Console.WriteLine(\"Reading data from file...\");\n\n                    //Reading data from object container file\n                    if (!ReadFile(buffer, path))\n                    {\n                        Console.WriteLine(\"Error during file operation. Quitting method\");\n                        return;\n                    }\n\n                    Console.WriteLine(\"Deserializing Sample Data Set...\");\n\n                    //Prepare the stream for deserializing the data\n                    buffer.Seek(0, SeekOrigin.Begin);\n\n                    //Create a SequentialReader instance for type SensorData, which will deserialize all serialized objects from the given stream.\n                    //It allows iterating over the deserialized objects because it implements the IEnumerable<T> interface.\n                    using (var reader = AvroContainer.CreateGenericReader(buffer))\n                    {\n                        using (var streamReader = new SequentialReader<object>(reader))\n                        {\n                            var results = streamReader.Objects;\n\n                            Console.WriteLine(\"Comparing Initial and Deserialized Data Sets...\");\n\n                            //Finally, verify the results\n                            var pairs = testData.Zip(results, (serialized, deserialized) => new { expected = (dynamic)serialized, actual = (dynamic)deserialized });\n                            int count = 1;\n                            foreach (var pair in pairs)\n                            {\n                                bool isEqual = pair.expected.Location.Floor.Equals(pair.actual.Location.Floor);\n                                isEqual = isEqual && pair.expected.Location.Room.Equals(pair.actual.Location.Room);\n                                isEqual = isEqual && ((byte[])pair.expected.Value).SequenceEqual((byte[])pair.actual.Value);\n                                Console.WriteLine(\"For Pair {0} result of Data Set Identity Comparison is {1}\", count, isEqual.ToString());\n                                count++;\n                            }\n                        }\n                    }\n                }\n\n                //Delete the file\n                RemoveFile(path);\n            }\n\n            //\n            //Helper methods\n            //\n\n            //Saving memory stream to a new file with the given path\n            private bool WriteFile(MemoryStream InputStream, string path)\n            {\n                if (!File.Exists(path))\n                {\n                    try\n                    {\n                        using (FileStream fs = File.Create(path))\n                        {\n                            InputStream.Seek(0, SeekOrigin.Begin);\n                            InputStream.CopyTo(fs);\n                        }\n                        return true;\n                    }\n                    catch (Exception e)\n                    {\n                        Console.WriteLine(\"The following exception was thrown during creation and writing to the file \"{0}\"\", path);\n                        Console.WriteLine(e.Message);\n                        return false;\n                    }\n                }\n                else\n                {\n                    Console.WriteLine(\"Can not create file \"{0}\". File already exists\", path);\n                    return false;\n\n                }\n            }\n\n            //Reading a file content by using the given path to a memory stream\n            private bool ReadFile(MemoryStream OutputStream, string path)\n            {\n                try\n                {\n                    using (FileStream fs = File.Open(path, FileMode.Open))\n                    {\n                        fs.CopyTo(OutputStream);\n                    }\n                    return true;\n                }\n                catch (Exception e)\n                {\n                    Console.WriteLine(\"The following exception was thrown during reading from the file \"{0}\"\", path);\n                    Console.WriteLine(e.Message);\n                    return false;\n                }\n            }\n\n            //Deleting file by using the given path\n            private void RemoveFile(string path)\n            {\n                if (File.Exists(path))\n                {\n                    try\n                    {\n                        File.Delete(path);\n                    }\n                    catch (Exception e)\n                    {\n                        Console.WriteLine(\"The following exception was thrown during deleting the file \"{0}\"\", path);\n                        Console.WriteLine(e.Message);\n                    }\n                }\n                else\n                {\n                    Console.WriteLine(\"Can not delete file \"{0}\". File does not exist\", path);\n                }\n            }\n\n            static void Main()\n            {\n\n                string sectionDivider = \"---------------------------------------- \";\n\n                //Create an instance of the AvroSample class and invoke methods\n                //illustrating different serializing approaches\n                AvroSample Sample = new AvroSample();\n\n                //Serialization using generic record to Avro object container file\n                Sample.SerializeDeserializeUsingObjectContainersGenericRecord();\n\n                Console.WriteLine(sectionDivider);\n                Console.WriteLine(\"Press any key to exit.\");\n                Console.Read();\n            }\n        }\n    }\n    // The example is expected to display the following output:\n    // SERIALIZATION USING GENERIC RECORD AND AVRO OBJECT CONTAINER FILES\n    //\n    // Defining the Schema and creating Sample Data Set...\n    // Serializing Sample Data Set...\n    // Saving serialized data to file...\n    // Reading data from file...\n    // Deserializing Sample Data Set...\n    // Comparing Initial and Deserialized Data Sets...\n    // For Pair 1 result of Data Set Identity Comparison is True\n    // For Pair 2 result of Data Set Identity Comparison is True\n    // ----------------------------------------\n    // Press any key to exit.\n\n\n\n\n###<a name=\"Scenario5\"></a>示例 5：使用对象容器文件通过自定义压缩编解码器进行序列化\n\n第五个示例演示如何将自定义压缩编解码器用于 Avro 对象容器文件。包含此示例代码的样例可以从 [Azure 代码示例](https://github.com/Azure-Samples)站点下载。\n\n[Avro 规范](http://avro.apache.org/docs/current/spec.html#Required+Codecs)允许使用可选的压缩编解码器（除了 **Null** 和 **Deflate** 默认压缩编解码器外）。此示例未完全实现类似 Snappy（在 [Avro 规范](http://avro.apache.org/docs/current/spec.html#snappy)中作为支持的可选编解码器提及）的新编解码器。它演示如何使用 [**Deflate**][deflate-110] 编解码器的 .NET Framework 4.5 实现，后者基于 [zlib](http://zlib.net/) 压缩库提供比默认的 .NET Framework 4.0 版本更好的压缩算法。\n\n\n    //\n    // This code needs to be compiled with the parameter Target Framework set as \".NET Framework 4.5\"\n    // to ensure the desired implementation of the Deflate compression algorithm is used.\n    // Ensure your C# project is set up accordingly.\n    //\n\n    namespace Microsoft.Hadoop.Avro.Sample\n    {\n        using System;\n        using System.Collections.Generic;\n        using System.Diagnostics;\n        using System.IO;\n        using System.IO.Compression;\n        using System.Linq;\n        using System.Runtime.Serialization;\n        using Microsoft.Hadoop.Avro.Container;\n        using Microsoft.Hadoop.Avro;\n\n        #region Defining objects for serialization\n        //Sample class used in serialization samples\n        [DataContract(Name = \"SensorDataValue\", Namespace = \"Sensors\")]\n        internal class SensorData\n        {\n            [DataMember(Name = \"Location\")]\n            public Location Position { get; set; }\n\n            [DataMember(Name = \"Value\")]\n            public byte[] Value { get; set; }\n        }\n\n        //Sample struct used in serialization samples\n        [DataContract]\n        internal struct Location\n        {\n            [DataMember]\n            public int Floor { get; set; }\n\n            [DataMember]\n            public int Room { get; set; }\n        }\n        #endregion\n\n        #region Defining custom codec based on .NET Framework V.4.5 Deflate\n        //Avro.NET codec class contains two methods,\n        //GetCompressedStreamOver(Stream uncompressed) and GetDecompressedStreamOver(Stream compressed),\n        //which are the key ones for data compression.\n        //To enable a custom codec, one needs to implement these methods for the required codec.\n\n        #region Defining Compression and Decompression Streams\n        //DeflateStream (class from System.IO.Compression namespace that implements Deflate algorithm)\n        //cannot be directly used for Avro because it does not support vital operations like Seek.\n        //Thus one needs to implement two classes inherited from stream\n        //(one for compressed and one for decompressed stream)\n        //that use Deflate compression and implement all required features.\n        internal sealed class CompressionStreamDeflate45 : Stream\n        {\n            private readonly Stream buffer;\n            private DeflateStream compressionStream;\n\n            public CompressionStreamDeflate45(Stream buffer)\n            {\n                Debug.Assert(buffer != null, \"Buffer is not allowed to be null.\");\n\n                this.compressionStream = new DeflateStream(buffer, CompressionLevel.Fastest, true);\n                this.buffer = buffer;\n            }\n\n            public override bool CanRead\n            {\n                get { return this.buffer.CanRead; }\n            }\n\n            public override bool CanSeek\n            {\n                get { return true; }\n            }\n\n            public override bool CanWrite\n            {\n                get { return this.buffer.CanWrite; }\n            }\n\n            public override void Flush()\n            {\n                this.compressionStream.Close();\n            }\n\n            public override long Length\n            {\n                get { return this.buffer.Length; }\n            }\n\n            public override long Position\n            {\n                get\n                {\n                    return this.buffer.Position;\n                }\n\n                set\n                {\n                    this.buffer.Position = value;\n                }\n            }\n\n            public override int Read(byte[] buffer, int offset, int count)\n            {\n                return this.buffer.Read(buffer, offset, count);\n            }\n\n            public override long Seek(long offset, SeekOrigin origin)\n            {\n                return this.buffer.Seek(offset, origin);\n            }\n\n            public override void SetLength(long value)\n            {\n                throw new NotSupportedException();\n            }\n\n            public override void Write(byte[] buffer, int offset, int count)\n            {\n                this.compressionStream.Write(buffer, offset, count);\n            }\n\n            protected override void Dispose(bool disposed)\n            {\n                base.Dispose(disposed);\n\n                if (disposed)\n                {\n                    this.compressionStream.Dispose();\n                    this.compressionStream = null;\n                }\n            }\n        }\n\n        internal sealed class DecompressionStreamDeflate45 : Stream\n        {\n            private readonly DeflateStream decompressed;\n\n            public DecompressionStreamDeflate45(Stream compressed)\n            {\n                this.decompressed = new DeflateStream(compressed, CompressionMode.Decompress, true);\n            }\n\n            public override bool CanRead\n            {\n                get { return true; }\n            }\n\n            public override bool CanSeek\n            {\n                get { return true; }\n            }\n\n            public override bool CanWrite\n            {\n                get { return false; }\n            }\n\n            public override void Flush()\n            {\n                this.decompressed.Close();\n            }\n\n            public override long Length\n            {\n                get { return this.decompressed.Length; }\n            }\n\n            public override long Position\n            {\n                get\n                {\n                    return this.decompressed.Position;\n                }\n\n                set\n                {\n                    throw new NotSupportedException();\n                }\n            }\n\n            public override int Read(byte[] buffer, int offset, int count)\n            {\n                return this.decompressed.Read(buffer, offset, count);\n            }\n\n            public override long Seek(long offset, SeekOrigin origin)\n            {\n                throw new NotSupportedException();\n            }\n\n            public override void SetLength(long value)\n            {\n                throw new NotSupportedException();\n            }\n\n            public override void Write(byte[] buffer, int offset, int count)\n            {\n                throw new NotSupportedException();\n            }\n\n            protected override void Dispose(bool disposing)\n            {\n                base.Dispose(disposing);\n\n                if (disposing)\n                {\n                    this.decompressed.Dispose();\n                }\n            }\n        }\n        #endregion\n\n        #region Define Codec\n        //Define the actual codec class containing the required methods for manipulating streams:\n        //GetCompressedStreamOver(Stream uncompressed) and GetDecompressedStreamOver(Stream compressed).\n        //Codec class uses classes for compressed and decompressed streams defined above.\n        internal sealed class DeflateCodec45 : Codec\n        {\n\n            //We merely use different IMPLEMENTATIONS of Deflate, so CodecName remains \"deflate\"\n            public static readonly string CodecName = \"deflate\";\n\n            public DeflateCodec45()\n                : base(CodecName)\n            {\n            }\n\n            public override Stream GetCompressedStreamOver(Stream decompressed)\n            {\n                if (decompressed == null)\n                {\n                    throw new ArgumentNullException(\"decompressed\");\n                }\n\n                return new CompressionStreamDeflate45(decompressed);\n            }\n\n            public override Stream GetDecompressedStreamOver(Stream compressed)\n            {\n                if (compressed == null)\n                {\n                    throw new ArgumentNullException(\"compressed\");\n                }\n\n                return new DecompressionStreamDeflate45(compressed);\n            }\n        }\n        #endregion\n\n        #region Define modified Codec Factory\n        //Define modified codec factory to be used in the reader.\n        //It will catch the attempt to use \"Deflate\" and provide  a custom codec.\n        //For all other cases, it will rely on the base class (CodecFactory).\n        internal sealed class CodecFactoryDeflate45 : CodecFactory\n        {\n\n            public override Codec Create(string codecName)\n            {\n                if (codecName == DeflateCodec45.CodecName)\n                    return new DeflateCodec45();\n                else\n                    return base.Create(codecName);\n            }\n        }\n        #endregion\n\n        #endregion\n\n        #region Sample Class with demonstration methods\n        //This class contains methods demonstrating\n        //the usage of Microsoft Avro Library\n        public class AvroSample\n        {\n\n            //Serializes and deserializes sample data set by using reflection and Avro object container files.\n            //Serialized data is compressed with the custom compression codec (Deflate of .NET Framework 4.5).\n            //\n            //This sample uses memory stream for all operations related to serialization, deserialization and\n            //object container manipulation, though file stream could be easily used.\n            public void SerializeDeserializeUsingObjectContainersReflectionCustomCodec()\n            {\n\n                Console.WriteLine(\"SERIALIZATION USING REFLECTION, AVRO OBJECT CONTAINER FILES AND CUSTOM CODEC\\n\");\n\n                //Path for Avro object container file\n                string path = \"AvroSampleReflectionDeflate45.avro\";\n\n                //Create a data set by using sample class and struct\n                var testData = new List<SensorData>\n                        {\n                            new SensorData { Value = new byte[] { 1, 2, 3, 4, 5 }, Position = new Location { Room = 243, Floor = 1 } },\n                            new SensorData { Value = new byte[] { 6, 7, 8, 9 }, Position = new Location { Room = 244, Floor = 1 } }\n                        };\n\n                //Serializing and saving data to file.\n                //Creating a memory stream buffer.\n                using (var buffer = new MemoryStream())\n                {\n                    Console.WriteLine(\"Serializing Sample Data Set...\");\n\n                    //Create a SequentialWriter instance for type SensorData, which can serialize a sequence of SensorData objects to stream.\n                    //Here the custom codec is introduced. For convenience, the next commented code line shows how to use built-in Deflate.\n                    //Note that because the sample deals with different IMPLEMENTATIONS of Deflate, built-in and custom codecs are interchangeable\n                    //in read-write operations.\n                    //using (var w = AvroContainer.CreateWriter<SensorData>(buffer, Codec.Deflate))\n                    using (var w = AvroContainer.CreateWriter<SensorData>(buffer, new DeflateCodec45()))\n                    {\n                        using (var writer = new SequentialWriter<SensorData>(w, 24))\n                        {\n                            // Serialize the data to stream using the sequential writer\n                            testData.ForEach(writer.Write);\n                        }\n                    }\n\n                    //Save stream to file\n                    Console.WriteLine(\"Saving serialized data to file...\");\n                    if (!WriteFile(buffer, path))\n                    {\n                        Console.WriteLine(\"Error during file operation. Quitting method\");\n                        return;\n                    }\n                }\n\n                //Reading and deserializing data.\n                //Creating a memory stream buffer.\n                using (var buffer = new MemoryStream())\n                {\n                    Console.WriteLine(\"Reading data from file...\");\n\n                    //Reading data from object container file\n                    if (!ReadFile(buffer, path))\n                    {\n                        Console.WriteLine(\"Error during file operation. Quitting method\");\n                        return;\n                    }\n\n                    Console.WriteLine(\"Deserializing Sample Data Set...\");\n\n                    //Prepare the stream for deserializing the data\n                    buffer.Seek(0, SeekOrigin.Begin);\n\n                    //Because of SequentialReader<T> constructor signature, an AvroSerializerSettings instance is required\n                    //when codec factory is explicitly specified.\n                    //You may comment the line below if you want to use built-in Deflate (see next comment).\n                    AvroSerializerSettings settings = new AvroSerializerSettings();\n\n                    //Create a SequentialReader instance for type SensorData, which will deserialize all serialized objects from the given stream.\n                    //It allows iterating over the deserialized objects because it implements the IEnumerable<T> interface.\n                    //Here the custom codec factory is introduced.\n                    //For convenience, the next commented code line shows how to use built-in Deflate\n                    //(no explicit Codec Factory parameter is required in this case).\n                    //Note that because the sample deals with different IMPLEMENTATIONS of Deflate, built-in and custom codecs are interchangeable\n                    //in read-write operations.\n                    //using (var reader = new SequentialReader<SensorData>(AvroContainer.CreateReader<SensorData>(buffer, true)))\n                    using (var reader = new SequentialReader<SensorData>(\n                        AvroContainer.CreateReader<SensorData>(buffer, true, settings, new CodecFactoryDeflate45())))\n                    {\n                        var results = reader.Objects;\n\n                        //Finally, verify that deserialized data matches the original one\n                        Console.WriteLine(\"Comparing Initial and Deserialized Data Sets...\");\n                        bool isEqual;\n                        int count = 1;\n                        var pairs = testData.Zip(results, (serialized, deserialized) => new { expected = serialized, actual = deserialized });\n                        foreach (var pair in pairs)\n                        {\n                            isEqual = this.Equal(pair.expected, pair.actual);\n                            Console.WriteLine(\"For Pair {0} result of Data Set Identity Comparison is {1}\", count, isEqual.ToString());\n                            count++;\n                        }\n                    }\n                }\n\n                //Delete the file\n                RemoveFile(path);\n            }\n        #endregion\n\n            #region Helper Methods\n\n            //Comparing two SensorData objects\n            private bool Equal(SensorData left, SensorData right)\n            {\n                return left.Position.Equals(right.Position) && left.Value.SequenceEqual(right.Value);\n            }\n\n            //Saving memory stream to a new file with the given path\n            private bool WriteFile(MemoryStream InputStream, string path)\n            {\n                if (!File.Exists(path))\n                {\n                    try\n                    {\n                        using (FileStream fs = File.Create(path))\n                        {\n                            InputStream.Seek(0, SeekOrigin.Begin);\n                            InputStream.CopyTo(fs);\n                        }\n                        return true;\n                    }\n                    catch (Exception e)\n                    {\n                        Console.WriteLine(\"The following exception was thrown during creation and writing to the file \"{0}\"\", path);\n                        Console.WriteLine(e.Message);\n                        return false;\n                    }\n                }\n                else\n                {\n                    Console.WriteLine(\"Can not create file \"{0}\". File already exists\", path);\n                    return false;\n\n                }\n            }\n\n            //Reading file content by using the given path to a memory stream\n            private bool ReadFile(MemoryStream OutputStream, string path)\n            {\n                try\n                {\n                    using (FileStream fs = File.Open(path, FileMode.Open))\n                    {\n                        fs.CopyTo(OutputStream);\n                    }\n                    return true;\n                }\n                catch (Exception e)\n                {\n                    Console.WriteLine(\"The following exception was thrown during reading from the file \"{0}\"\", path);\n                    Console.WriteLine(e.Message);\n                    return false;\n                }\n            }\n\n            //Deleting file by using given path\n            private void RemoveFile(string path)\n            {\n                if (File.Exists(path))\n                {\n                    try\n                    {\n                        File.Delete(path);\n                    }\n                    catch (Exception e)\n                    {\n                        Console.WriteLine(\"The following exception was thrown during deleting the file \"{0}\"\", path);\n                        Console.WriteLine(e.Message);\n                    }\n                }\n                else\n                {\n                    Console.WriteLine(\"Can not delete file \"{0}\". File does not exist\", path);\n                }\n            }\n            #endregion\n\n            static void Main()\n            {\n\n                string sectionDivider = \"---------------------------------------- \";\n\n                //Create an instance of AvroSample Class and invoke methods\n                //illustrating different serializing approaches\n                AvroSample Sample = new AvroSample();\n\n                //Serialization using reflection to Avro object container file using custom codec\n                Sample.SerializeDeserializeUsingObjectContainersReflectionCustomCodec();\n\n                Console.WriteLine(sectionDivider);\n                Console.WriteLine(\"Press any key to exit.\");\n                Console.Read();\n            }\n        }\n    }\n    // The example is expected to display the following output:\n    // SERIALIZATION USING REFLECTION, AVRO OBJECT CONTAINER FILES AND CUSTOM CODEC\n    //\n    // Serializing Sample Data Set...\n    // Saving serialized data to file...\n    // Reading data from file...\n    // Deserializing Sample Data Set...\n    // Comparing Initial and Deserialized Data Sets...\n    // For Pair 1 result of Data Set Identity Comparison is True\n    //For Pair 2 result of Data Set Identity Comparison is True\n    // ----------------------------------------\n    // Press any key to exit.\n\n###<a name=\"Scenario6\"></a>示例 6：使用 Avro 上载 Azure HDInsight 服务的数据\n\n第六个示例演示与 Azure HDInsight 服务交互相关的一些编程技巧。包含此示例代码的样例可以从 [Azure 代码示例](https://github.com/Azure-Samples)站点下载。\n\n该示例将执行以下操作：\n\n* 连接到现有的 HDInsight 服务群集。\n* 序列化多个 CSV 文件并将结果上载到 Azure Blob 存储。（CSV 文件随着示例一起分发，而且代表 [Infochimps](http://www.infochimps.com/) 在 1970 年到 2010 年期间提取自 AMEX 股票的历史记录数据。该示例将读取 CSV 文件数据、将记录转换为 **Stock** 类的实例，然后使用反射序列化这些实例。Stock 类型定义是使用 Microsoft Avro Library 代码生成实用工具从 JSON 架构创建的。\n* 在 Hive 中创建名为 **Stocks** 的新外部表，并将它链接到前一个步骤中上载的数据。\n* 使用 Hive 对 **Stocks** 表执行查询。\n\n此外，该示例将在执行主要操作之前和之后执行清理过程。在清理期间，将删除所有相关的 Azure Blob 数据和文件夹，并删除 Hive 表。你也可以从示例命令行调用清理过程。\n\n该示例要求满足以下先决条件：\n\n* 有效的 Azure 订阅及其订阅 ID。\n* 包含相应私钥的订阅管理证书。该证书应安装在用于运行示例的计算机上的当前用户私用存储中。\n* 活动的 HDInsight 群集。\n* 在先前的必要条件中链接到 HDInsight 群集的 Azure 存储帐户，以及相应的主要或辅助访问密钥。\n\n运行示例之前，必要条件中的所有信息均应输入到示例配置文件中。要运行此操作有两个可行的方式：\n\n* 编辑示例根目录中的 app.config 文件，然后生成示例，或\n* 先生成示例，然后在生成目录中编辑 AvroHDISample.exe.config\n\n在这两个情况下，所有编辑均应该在 **<appSettings>** 设置节中完成。请遵循文件中的注释。\n执行以下命令从命令行运行该示例（其中，包含该示例的 .zip 文件假设已解压缩到 C:\\\\AvroHDISample；如果不是，请使用相关的文件路径）：\n\n    AvroHDISample run C:\\AvroHDISample\\Data\n\n若要清理群集，请运行以下命令：\n\n    AvroHDISample clean\n\n[deflate-100]: http://msdn.microsoft.com/zh-cn/library/system.io.compression.deflatestream(v=vs.100).aspx\n[deflate-110]: http://msdn.microsoft.com/zh-cn/library/system.io.compression.deflatestream(v=vs.110).aspx\n\n<!---HONumber=Mooncake_0307_2016-->"
}