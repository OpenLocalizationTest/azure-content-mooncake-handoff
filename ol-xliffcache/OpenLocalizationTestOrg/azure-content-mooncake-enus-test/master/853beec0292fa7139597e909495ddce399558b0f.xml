{
  "nodes": [
    {
      "content": "Apache Storm on HDInsight 简介 | Azure",
      "pos": [
        27,
        63
      ]
    },
    {
      "content": "获取有关 Apache Storm 的简介，并了解如何使用 Storm on HDInsight 在云中构建实时数据分析解决方案。",
      "pos": [
        82,
        147
      ]
    },
    {
      "content": "Apache Storm on HDInsight 简介：面向 Hadoop 的实时分析",
      "pos": [
        386,
        430
      ]
    },
    {
      "pos": [
        432,
        531
      ],
      "content": "Apache Storm on HDInsight 可让你使用 <bpt id=\"p1\">[</bpt>Apache Hadoop<ept id=\"p1\">](http://hadoop.apache.org)</ept> 在 Azure 环境中创建分布式实时分析解决方案。"
    },
    {
      "content": "什么是 Apache Storm？",
      "pos": [
        535,
        552
      ]
    },
    {
      "content": "Apache Storm 是分布式可容错的开源计算系统，可用于配合 Hadoop 实时处理数据。Storm 解决方案还提供有保障的数据处理功能，能够重播第一次未成功处理的数据。",
      "pos": [
        554,
        642
      ]
    },
    {
      "content": "为何要使用 Storm on HDInsight？",
      "pos": [
        646,
        671
      ]
    },
    {
      "content": "Apache Storm on HDInsight 是已集成到 Azure 环境中的托管群集。它提供以下主要优势：",
      "pos": [
        673,
        730
      ]
    },
    {
      "content": "以托管服务的形式执行，提供 99.9% 运行时间 SLA",
      "pos": [
        734,
        762
      ]
    },
    {
      "pos": [
        766,
        820
      ],
      "content": "使用你选择的语言：支持以 <bpt id=\"p1\">**</bpt>Java<ept id=\"p1\">**</ept>、<bpt id=\"p2\">**</bpt>C#<ept id=\"p2\">**</ept> 和 <bpt id=\"p3\">**</bpt>Python<ept id=\"p3\">**</ept> 编写的 Storm 组件"
    },
    {
      "content": "支持混用编程语言：使用 Java 读取数据，然后使用 C# 处理数据",
      "pos": [
        828,
        862
      ]
    },
    {
      "pos": [
        870,
        938
      ],
      "content": "使用 <bpt id=\"p1\">**</bpt>Trident<ept id=\"p1\">**</ept> Java 接口创建支持“一次性”消息处理、“事务性”数据存储持久性和一组常见流分析操作的 Storm 拓扑"
    },
    {
      "content": "包括内置的向上缩放和向下缩放功能：在不影响运行 Storm 拓扑的情况下缩放 HDInsight 群集",
      "pos": [
        942,
        993
      ]
    },
    {
      "content": "与其他 Azure 服务（包括事件中心、Azure 虚拟网络、SQL 数据库、Blob 存储和 DocumentDB）集成",
      "pos": [
        997,
        1058
      ]
    },
    {
      "content": "通过使用 Azure 虚拟网络中组合多个 HDInsight 群集的功能：创建使用 HDInsight、HBase 或 Hadoop 群集的分析管道",
      "pos": [
        1066,
        1140
      ]
    },
    {
      "pos": [
        1142,
        1257
      ],
      "content": "有关在实时分析解决方案中使用 Apache Storm 的公司列表，请参阅<bpt id=\"p1\">[</bpt>使用 Apache Storm 的公司<ept id=\"p1\">](https://storm.apache.org/documentation/Powered-By.html)</ept>。"
    },
    {
      "pos": [
        1259,
        1316
      ],
      "content": "若要开始使用 Storm，请参阅 <bpt id=\"p1\">[</bpt>Storm on HDInsight 入门<ept id=\"p1\">][gettingstarted]</ept>。"
    },
    {
      "content": "易于设置",
      "pos": [
        1321,
        1325
      ]
    },
    {
      "content": "你可以在分钟数设置好新的 Storm on HDInsight 群集。指定群集名称、大小、管理员帐户和存储帐户。Azure 将创建该群集，包括示例拓扑和 Web 管理仪表板。",
      "pos": [
        1327,
        1414
      ]
    },
    {
      "pos": [
        1418,
        1580
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> 你也可以使用 <bpt id=\"p1\">[</bpt>Azure CLI<ept id=\"p1\">](/documentation/articles/xplat-cli-install)</ept> 或 <bpt id=\"p2\">[</bpt>Azure PowerShell<ept id=\"p2\">](/documentation/articles/powershell-install-configure)</ept> 预配 Storm 群集。"
    },
    {
      "content": "在提交请求后的 15 分钟内，你就可以运行新的 Storm 群集，并准备好建立第一个实时分析管道。",
      "pos": [
        1582,
        1631
      ]
    },
    {
      "content": "易于使用",
      "pos": [
        1636,
        1640
      ]
    },
    {
      "pos": [
        1642,
        1772
      ],
      "content": "<bpt id=\"p1\">__</bpt>对于基于 Windows 的 Storm on HDInsight 群集<ept id=\"p1\">__</ept>，HDInsight Tools for Visual Studio 允许你创建 C# 和混合 C#/Java 拓扑，然后将它们提交到 Storm on HDInsight 群集。"
    },
    {
      "content": "Storm 项目创建",
      "pos": [
        1776,
        1786
      ]
    },
    {
      "content": "HDInsight Tools for Visual Studio 还提供了一个接口让你监视和管理群集上的 Storm 拓扑。",
      "pos": [
        1841,
        1904
      ]
    },
    {
      "content": "Storm 管理",
      "pos": [
        1908,
        1916
      ]
    },
    {
      "pos": [
        1967,
        2137
      ],
      "content": "有关使用 HDInsight 工具创建 Storm 应用程序的示例，请参阅<bpt id=\"p1\">[</bpt>使用 HDInsight Tools for Visual Studio 开发 C# Storm 拓扑<ept id=\"p1\">](/documentation/articles/hdinsight-storm-develop-csharp-visual-studio-topology)</ept>。"
    },
    {
      "pos": [
        2139,
        2299
      ],
      "content": "有关 HDInsight Tools for Visual Studio 的详细信息，请参阅 <bpt id=\"p1\">[</bpt>HDInsight Tools for Visual Studio 入门<ept id=\"p1\">](/documentation/articles/hdinsight-hadoop-visual-studio-tools-get-started)</ept>。"
    },
    {
      "content": "每个 Storm on HDInsight 群集还提供一个基于 Web 的 Storm 仪表板让提交、监视和管理群集上运行的 Storm 拓扑。",
      "pos": [
        2301,
        2373
      ]
    },
    {
      "content": "Storm 仪表板",
      "pos": [
        2377,
        2386
      ]
    },
    {
      "pos": [
        2437,
        2562
      ],
      "content": "有关使用 Storm 仪表板的详细信息，请参阅<bpt id=\"p1\">[</bpt>在 HDInsight 上部署和管理 Apache Storm 拓扑<ept id=\"p1\">](/documentation/articles/hdinsight-storm-deploy-monitor-topology)</ept>。"
    },
    {
      "pos": [
        2564,
        2775
      ],
      "content": "Storm on HDInsight 还支持通过<bpt id=\"p1\">**</bpt>事件中心 Spout<ept id=\"p1\">**</ept> 与 Azure 事件中心轻松集成。可以使用 <bpt id=\"p2\">**</bpt>%STORM\\_HOME%\\\\examples\\\\eventhubspout\\\\eventhubs-storm-spout-0.9-jar-with-dependencies.jar<ept id=\"p2\">**</ept> 在每个 Storm 群集上实现此目的。有关在 Storm 拓扑中使用此 Spout 的示例，请参阅以下文档："
    },
    {
      "content": "开发使用 Azure 事件中心的 C# 拓扑",
      "pos": [
        2780,
        2802
      ]
    },
    {
      "content": "开发使用 Azure 事件中心的 Java 拓扑",
      "pos": [
        2883,
        2907
      ]
    },
    {
      "content": "可靠性",
      "pos": [
        2986,
        2989
      ]
    },
    {
      "content": "Apache Storm 始终保证每个传入消息将完全处理，即使数据分析分散在数百个节点。",
      "pos": [
        2991,
        3035
      ]
    },
    {
      "pos": [
        3037,
        3222
      ],
      "content": "<bpt id=\"p1\">**</bpt>Nimbus 节点<ept id=\"p1\">**</ept>提供的功能与 Hadoop JobTracker 类似，它通过 <bpt id=\"p2\">**</bpt>Zookeeper<ept id=\"p2\">**</ept> 将任务分配给群集中的其他节点。Zookeeper 节点为群集提供协调功能，并促进 Nimbus 与辅助节点上的 <bpt id=\"p3\">**</bpt>Supervisor<ept id=\"p3\">**</ept> 进程进行通信。如果处理的一个节点出现故障，Nimbus 节点将得到通知，并分配到另一个节点的任务和关联的数据。"
    },
    {
      "content": "Apache Storm 的默认配置是只能有一个 Nimbus 节点。Storm on HDInsight 运行两个 Nimbus 节点。如果主节点出现故障，HDInsight 群集将切换到辅助节点，同时主节点将会恢复。",
      "pos": [
        3224,
        3334
      ]
    },
    {
      "content": "nimbus、zookeeper 和 supervisor 示意图",
      "pos": [
        3338,
        3371
      ]
    },
    {
      "content": "缩放",
      "pos": [
        3422,
        3424
      ]
    },
    {
      "content": "虽然可以在创建过程中指定群集中的节点数，但你可能需要扩大或收缩群集以匹配工作负载。所有 HDInsight 群集允许你更改群集中的节点数，即使在处理数据时。",
      "pos": [
        3426,
        3504
      ]
    },
    {
      "pos": [
        3508,
        3556
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph> 若要利用通过缩放添加的新节点，你需要重新平衡在增加大小之前启动的拓扑。"
    },
    {
      "content": "支持",
      "pos": [
        3561,
        3563
      ]
    },
    {
      "content": "Storm on HDInsight 附带全天候企业级支持。Storm on HDInsight 也提供 99.9% 的 SLA。这意味着，我们保证至少 99.9% 的时间群集都能建立外部连接。",
      "pos": [
        3565,
        3662
      ]
    },
    {
      "content": "实时分析常见用例",
      "pos": [
        3666,
        3674
      ]
    },
    {
      "pos": [
        3676,
        3813
      ],
      "content": "以下是你可能使用 Apache storm on HDInsight 的一些常见方案。有关实际方案的信息，请阅读<bpt id=\"p1\">[</bpt>公司如何使用 Storm<ept id=\"p1\">](https://storm.incubator.apache.org/documentation/Powered-By.html)</ept>。"
    },
    {
      "content": "物联网 (IoT)",
      "pos": [
        3817,
        3826
      ]
    },
    {
      "content": "欺诈检测",
      "pos": [
        3829,
        3833
      ]
    },
    {
      "content": "社交分析",
      "pos": [
        3836,
        3840
      ]
    },
    {
      "content": "提取、转换、加载 (ETL)",
      "pos": [
        3843,
        3857
      ]
    },
    {
      "content": "网络监视",
      "pos": [
        3860,
        3864
      ]
    },
    {
      "content": "搜索",
      "pos": [
        3867,
        3869
      ]
    },
    {
      "content": "移动应用场景",
      "pos": [
        3872,
        3878
      ]
    },
    {
      "content": "如何处理 HDInsight Storm 中的数据？",
      "pos": [
        3882,
        3908
      ]
    },
    {
      "pos": [
        3910,
        4053
      ],
      "content": "Apache Storm 运行的是<bpt id=\"p1\">**</bpt>拓扑<ept id=\"p1\">**</ept>，而不是你在 HDInsight 或 Hadoop 中可能熟悉的 MapReduce 作业。Storm on HDInsight 群集包含两种类型的节点：运行 <bpt id=\"p2\">**</bpt>Nimbus<ept id=\"p2\">**</ept> 的头节点和运行 <bpt id=\"p3\">**</bpt>Supervisor<ept id=\"p3\">**</ept> 的辅助节点。"
    },
    {
      "pos": [
        4057,
        4179
      ],
      "content": "<bpt id=\"p1\">**</bpt>Nimbus<ept id=\"p1\">**</ept>：类似于 Hadoop 中的 JobTracker，负责在整个群集中分发代码、将任务分配给虚拟机以及监视故障情况。HDInsight 提供两个 Nimbus 节点，因此 Storm on HDInsight 不会出现单点故障"
    },
    {
      "pos": [
        4183,
        4238
      ],
      "content": "<bpt id=\"p1\">**</bpt>Supervisor<ept id=\"p1\">**</ept>：每个辅助节点的 supervisor 负责启动和停止该节点上的<bpt id=\"p2\">**</bpt>工作进程<ept id=\"p2\">**</ept>。"
    },
    {
      "pos": [
        4242,
        4288
      ],
      "content": "<bpt id=\"p1\">**</bpt>工作进程<ept id=\"p1\">**</ept>：运行<bpt id=\"p2\">**</bpt>拓扑<ept id=\"p2\">**</ept>的一个子集。正在运行的拓扑分布在整个群集的许多工作进程上。"
    },
    {
      "pos": [
        4292,
        4346
      ],
      "content": "<bpt id=\"p1\">**</bpt>拓扑<ept id=\"p1\">**</ept>：定义处理数据<bpt id=\"p2\">**</bpt>流<ept id=\"p2\">**</ept>的计算图形。与 MapReduce 作业不同，拓扑运行到你停止它们为止。"
    },
    {
      "pos": [
        4350,
        4413
      ],
      "content": "<bpt id=\"p1\">**</bpt>流<ept id=\"p1\">**</ept>：一个未绑定的<bpt id=\"p2\">**</bpt>元组<ept id=\"p2\">**</ept>集合。流由 <bpt id=\"p3\">**</bpt>spout<ept id=\"p3\">**</ept> 和 <bpt id=\"p4\">**</bpt>bolt<ept id=\"p4\">**</ept> 生成，并由 <bpt id=\"p5\">**</bpt>bolt<ept id=\"p5\">**</ept> 使用。"
    },
    {
      "pos": [
        4417,
        4438
      ],
      "content": "<bpt id=\"p1\">**</bpt>元组<ept id=\"p1\">**</ept>：动态类型化值的一个命名列表。"
    },
    {
      "pos": [
        4442,
        4475
      ],
      "content": "<bpt id=\"p1\">**</bpt>Spout<ept id=\"p1\">**</ept>：使用数据源中的数据并发出一个或多个<bpt id=\"p2\">**</bpt>流<ept id=\"p2\">**</ept>。"
    },
    {
      "pos": [
        4483,
        4552
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>在许多情况下，从 Kafka、Azure 服务总线队列或事件中心等队列中读取数据。队列确保发生中断时数据持续不断。"
    },
    {
      "pos": [
        4556,
        4646
      ],
      "content": "<bpt id=\"p1\">**</bpt>Bolt<ept id=\"p1\">**</ept>：使用<bpt id=\"p2\">**</bpt>流<ept id=\"p2\">**</ept>，处理<bpt id=\"p3\">**</bpt>元组<ept id=\"p3\">**</ept>，并可以发出<bpt id=\"p4\">**</bpt>流<ept id=\"p4\">**</ept>。Bolt 还负责将数据编写到外部存储，比如队列、HDInsight HBase、blob 或其他数据存储。"
    },
    {
      "pos": [
        4650,
        4788
      ],
      "content": "<bpt id=\"p1\">**</bpt>Apache Thrift<ept id=\"p1\">**</ept>：用于可缩放跨语言服务开发的软件框架。可用于构建在 C++、Java、Python、PHP、Ruby、Erlang、Perl、Haskell、C#、Cocoa、JavaScript、Node.js、Smalltalk 及其他语言间工作的服务。"
    },
    {
      "pos": [
        4796,
        4856
      ],
      "content": "<bpt id=\"p1\">**</bpt>Nimbus<ept id=\"p1\">**</ept> 是一种 Thrift 服务，<bpt id=\"p2\">**</bpt>拓扑<ept id=\"p2\">**</ept>是 Thrift 定义，因此可以使用各种编程语言来开发拓扑"
    },
    {
      "pos": [
        4858,
        4920
      ],
      "content": "有关 Storm 组件的详细信息，请参阅 apache.org 上的 <bpt id=\"p1\">[</bpt>Storm 教程<ept id=\"p1\">][apachetutorial]</ept>。"
    },
    {
      "content": "我可以使用哪些编程语言？",
      "pos": [
        4925,
        4937
      ]
    },
    {
      "content": "Storm on HDInsight 群集支持 C#、Java 和 Python。",
      "pos": [
        4939,
        4980
      ]
    },
    {
      "content": "C&amp;#35;",
      "pos": [
        4986,
        4992
      ]
    },
    {
      "content": "HDInsight Tools for Visual Studio 允许 .NET 开发人员以 C# 语言设计和实施拓扑。你也可以创建使用 Java 和 C# 组件的混合拓扑。",
      "pos": [
        4994,
        5082
      ]
    },
    {
      "pos": [
        5084,
        5229
      ],
      "content": "有关详细信息，请参阅<bpt id=\"p1\">[</bpt>使用 Visual Studio 开发 Apache Storm on HDInsight 的 C# 拓扑<ept id=\"p1\">](/documentation/articles/hdinsight-storm-develop-csharp-visual-studio-topology)</ept>。"
    },
    {
      "content": "Java",
      "pos": [
        5234,
        5238
      ]
    },
    {
      "content": "你遇到的大多数 Java 示例都是无格式 Java 或 Trident。Trident 是一个高级别抽象，可更轻松地执行联接、汇总、分组和筛选等操作。但是，Trident 作用于批量元组，其中原始 Java 解决方案一次将处理一个元组流。",
      "pos": [
        5240,
        5359
      ]
    },
    {
      "pos": [
        5361,
        5481
      ],
      "content": "有关 Trident 的详细信息，请参阅 apache.org 上的 <bpt id=\"p1\">[</bpt>Trident 教程<ept id=\"p1\">](https://storm.incubator.apache.org/documentation/Trident-tutorial.html)</ept>。"
    },
    {
      "pos": [
        5483,
        5617
      ],
      "content": "有关 Java 和 Trident 拓扑的示例，请参阅 <bpt id=\"p1\">[</bpt>Storm 拓扑示例列表<ept id=\"p1\">](/documentation/articles/hdinsight-storm-example-topology)</ept>或 HDInsight 群集上的 storm-starter 示例。"
    },
    {
      "pos": [
        5619,
        5700
      ],
      "content": "storm-starter 示例位于基于 Windows 的群集上的 <bpt id=\"p1\">**</bpt>%storm\\_home%\\\\contrib\\\\storm-starter<ept id=\"p1\">**</ept> 目录中。"
    },
    {
      "content": "常见的开发模式有哪些？",
      "pos": [
        5704,
        5715
      ]
    },
    {
      "content": "有保证的消息处理",
      "pos": [
        5720,
        5728
      ]
    },
    {
      "content": "Storm 可以提供不同级别的有保证的消息处理。例如，基本的 Storm 应用程序至少可以保证一次处理，而 Trident 仅可以保证一次处理。",
      "pos": [
        5730,
        5802
      ]
    },
    {
      "pos": [
        5804,
        5901
      ],
      "content": "有关详细信息，请参阅 apache.org 上的<bpt id=\"p1\">[</bpt>数据处理保证<ept id=\"p1\">](https://storm.apache.org/about/guarantees-data-processing.html)</ept>。"
    },
    {
      "content": "IBasicBolt",
      "pos": [
        5906,
        5916
      ]
    },
    {
      "pos": [
        5918,
        6074
      ],
      "content": "读取输入元组，发出零个或多个元组，然后在执行方法结束时立即询问输入元组，这种模式非常普通，以至 Storm 提供 <bpt id=\"p1\">[</bpt>IBasicBolt<ept id=\"p1\">](https://storm.apache.org/apidocs/backtype/storm/topology/IBasicBolt.html)</ept> 接口来自动执行这种模式。"
    },
    {
      "content": "联接",
      "pos": [
        6079,
        6081
      ]
    },
    {
      "pos": [
        6083,
        6376
      ],
      "content": "在应用程序之间联接两个数据流的方式将有所不同。例如，你可以从多个流将每个元组联接到一个新流，也可以仅联接特定窗口的批量元组。两种方式的联接都可以使用 <bpt id=\"p1\">[</bpt>fieldsGrouping<ept id=\"p1\">](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29)</ept> 来实现，它是定义元组如何路由到 bolt 的方式。"
    },
    {
      "pos": [
        6378,
        6449
      ],
      "content": "在以下 Java 实例中，fieldsGrouping 用于将来自组件“1”、“2”和“3”的元组路由至 <bpt id=\"p1\">**</bpt>MyJoiner<ept id=\"p1\">**</ept> bolt。"
    },
    {
      "content": "批处理",
      "pos": [
        6696,
        6699
      ]
    },
    {
      "content": "批处理可以通过若干方式来实现。利用基本 Storm Java 拓扑，你可以在发出元组前使用简单计数器对 X 个元组进行批处理，或使用称为计时周期元组的内部计时机制每 X 秒发出一批元组。",
      "pos": [
        6701,
        6794
      ]
    },
    {
      "pos": [
        6796,
        6915
      ],
      "content": "有关使用计时周期元组的示例，请参阅<bpt id=\"p1\">[</bpt>使用 HDInsight 上的 Storm 和 HBase 分析传感器数据<ept id=\"p1\">](/documentation/articles/hdinsight-storm-sensor-data-analysis)</ept>。"
    },
    {
      "content": "如果你使用的是 Trident，则其基于批量处理元组。",
      "pos": [
        6917,
        6944
      ]
    },
    {
      "content": "缓存",
      "pos": [
        6949,
        6951
      ]
    },
    {
      "pos": [
        6953,
        7251
      ],
      "content": "内存缓存通常用作加速处理的机制，因为它在内存中存储常用资产。由于拓扑分布于多个节点，并且每个节点中有多个进程，你应考虑使用 <bpt id=\"p1\">[</bpt>fieldsGrouping<ept id=\"p1\">](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29)</ept> 来确保包含用于缓存查询的字段的元组始终路由至同一进程。这可以避免在进程间重复缓存条目。"
    },
    {
      "content": "流式处理 top N",
      "pos": [
        7256,
        7266
      ]
    },
    {
      "pos": [
        7268,
        7593
      ],
      "content": "当拓扑依赖于计算“top”N 值（比如 Twitter 上的前 5 大趋势）时，你应并行计算 top N 值，然后将这些计算的输出合并到全局值中。为此，可以使用 <bpt id=\"p1\">[</bpt>fieldsGrouping<ept id=\"p1\">](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29)</ept> 按字段路由至并行 bolt（该项按字段值对数据进行划分），然后路由至全局确定前 N 个值的 bolt。"
    },
    {
      "pos": [
        7595,
        7729
      ],
      "content": "有关此内容的示例，请参阅 <bpt id=\"p1\">[</bpt>RollingTopWords<ept id=\"p1\">](https://github.com/nathanmarz/storm-starter/blob/master/src/jvm/storm/starter/RollingTopWords.java)</ept> 示例。"
    },
    {
      "content": "后续步骤",
      "pos": [
        7733,
        7737
      ]
    },
    {
      "content": "了解有关使用 HDInsight 中的 Apache Storm 构建实时分析解决方案的详细信息：",
      "pos": [
        7739,
        7788
      ]
    },
    {
      "content": "Storm on HDInsight 入门",
      "pos": [
        7793,
        7814
      ]
    },
    {
      "content": "Storm on HDInsight 的示例拓扑",
      "pos": [
        7836,
        7860
      ]
    }
  ],
  "content": "<properties\n    pageTitle=\"Apache Storm on HDInsight 简介 | Azure\"\n    description=\"获取有关 Apache Storm 的简介，并了解如何使用 Storm on HDInsight 在云中构建实时数据分析解决方案。\"\n    services=\"hdinsight\"\n    documentationCenter=\"\"\n    authors=\"Blackmist\"\n    manager=\"paulettm\"\n    editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.date=\"01/08/2016\"\n    wacn.date=\"02/26/2016\"/>\n\n#Apache Storm on HDInsight 简介：面向 Hadoop 的实时分析\n\nApache Storm on HDInsight 可让你使用 [Apache Hadoop](http://hadoop.apache.org) 在 Azure 环境中创建分布式实时分析解决方案。\n\n##什么是 Apache Storm？\n\nApache Storm 是分布式可容错的开源计算系统，可用于配合 Hadoop 实时处理数据。Storm 解决方案还提供有保障的数据处理功能，能够重播第一次未成功处理的数据。\n\n##为何要使用 Storm on HDInsight？\n\nApache Storm on HDInsight 是已集成到 Azure 环境中的托管群集。它提供以下主要优势：\n\n* 以托管服务的形式执行，提供 99.9% 运行时间 SLA\n\n* 使用你选择的语言：支持以 **Java**、**C#** 和 **Python** 编写的 Storm 组件\n\n    * 支持混用编程语言：使用 Java 读取数据，然后使用 C# 处理数据\n\n    * 使用 **Trident** Java 接口创建支持“一次性”消息处理、“事务性”数据存储持久性和一组常见流分析操作的 Storm 拓扑\n\n* 包括内置的向上缩放和向下缩放功能：在不影响运行 Storm 拓扑的情况下缩放 HDInsight 群集\n\n* 与其他 Azure 服务（包括事件中心、Azure 虚拟网络、SQL 数据库、Blob 存储和 DocumentDB）集成\n\n    * 通过使用 Azure 虚拟网络中组合多个 HDInsight 群集的功能：创建使用 HDInsight、HBase 或 Hadoop 群集的分析管道\n\n有关在实时分析解决方案中使用 Apache Storm 的公司列表，请参阅[使用 Apache Storm 的公司](https://storm.apache.org/documentation/Powered-By.html)。\n\n若要开始使用 Storm，请参阅 [Storm on HDInsight 入门][gettingstarted]。\n\n###易于设置\n\n你可以在分钟数设置好新的 Storm on HDInsight 群集。指定群集名称、大小、管理员帐户和存储帐户。Azure 将创建该群集，包括示例拓扑和 Web 管理仪表板。\n\n> [AZURE.NOTE] 你也可以使用 [Azure CLI](/documentation/articles/xplat-cli-install) 或 [Azure PowerShell](/documentation/articles/powershell-install-configure) 预配 Storm 群集。\n\n在提交请求后的 15 分钟内，你就可以运行新的 Storm 群集，并准备好建立第一个实时分析管道。\n\n###易于使用\n\n__对于基于 Windows 的 Storm on HDInsight 群集__，HDInsight Tools for Visual Studio 允许你创建 C# 和混合 C#/Java 拓扑，然后将它们提交到 Storm on HDInsight 群集。\n\n![Storm 项目创建](./media/hdinsight-storm-overview/createproject.png)\n\nHDInsight Tools for Visual Studio 还提供了一个接口让你监视和管理群集上的 Storm 拓扑。\n\n![Storm 管理](./media/hdinsight-storm-overview/stormview.png)\n\n有关使用 HDInsight 工具创建 Storm 应用程序的示例，请参阅[使用 HDInsight Tools for Visual Studio 开发 C# Storm 拓扑](/documentation/articles/hdinsight-storm-develop-csharp-visual-studio-topology)。\n\n有关 HDInsight Tools for Visual Studio 的详细信息，请参阅 [HDInsight Tools for Visual Studio 入门](/documentation/articles/hdinsight-hadoop-visual-studio-tools-get-started)。\n\n每个 Storm on HDInsight 群集还提供一个基于 Web 的 Storm 仪表板让提交、监视和管理群集上运行的 Storm 拓扑。\n\n![Storm 仪表板](./media/hdinsight-storm-overview/dashboard.png)\n\n有关使用 Storm 仪表板的详细信息，请参阅[在 HDInsight 上部署和管理 Apache Storm 拓扑](/documentation/articles/hdinsight-storm-deploy-monitor-topology)。\n\nStorm on HDInsight 还支持通过**事件中心 Spout** 与 Azure 事件中心轻松集成。可以使用 **%STORM\\_HOME%\\\\examples\\\\eventhubspout\\\\eventhubs-storm-spout-0.9-jar-with-dependencies.jar** 在每个 Storm 群集上实现此目的。有关在 Storm 拓扑中使用此 Spout 的示例，请参阅以下文档：\n\n* [开发使用 Azure 事件中心的 C# 拓扑](/documentation/articles/hdinsight-storm-develop-csharp-event-hub-topology)\n\n* [开发使用 Azure 事件中心的 Java 拓扑](/documentation/articles/hdinsight-storm-develop-java-event-hub-topology)\n\n###可靠性\n\nApache Storm 始终保证每个传入消息将完全处理，即使数据分析分散在数百个节点。\n\n**Nimbus 节点**提供的功能与 Hadoop JobTracker 类似，它通过 **Zookeeper** 将任务分配给群集中的其他节点。Zookeeper 节点为群集提供协调功能，并促进 Nimbus 与辅助节点上的 **Supervisor** 进程进行通信。如果处理的一个节点出现故障，Nimbus 节点将得到通知，并分配到另一个节点的任务和关联的数据。\n\nApache Storm 的默认配置是只能有一个 Nimbus 节点。Storm on HDInsight 运行两个 Nimbus 节点。如果主节点出现故障，HDInsight 群集将切换到辅助节点，同时主节点将会恢复。\n\n![nimbus、zookeeper 和 supervisor 示意图](./media/hdinsight-storm-overview/nimbus.png)\n\n###缩放\n\n虽然可以在创建过程中指定群集中的节点数，但你可能需要扩大或收缩群集以匹配工作负载。所有 HDInsight 群集允许你更改群集中的节点数，即使在处理数据时。\n\n> [AZURE.NOTE] 若要利用通过缩放添加的新节点，你需要重新平衡在增加大小之前启动的拓扑。\n\n###支持\n\nStorm on HDInsight 附带全天候企业级支持。Storm on HDInsight 也提供 99.9% 的 SLA。这意味着，我们保证至少 99.9% 的时间群集都能建立外部连接。\n\n##实时分析常见用例\n\n以下是你可能使用 Apache storm on HDInsight 的一些常见方案。有关实际方案的信息，请阅读[公司如何使用 Storm](https://storm.incubator.apache.org/documentation/Powered-By.html)。\n\n* 物联网 (IoT)\n* 欺诈检测\n* 社交分析\n* 提取、转换、加载 (ETL)\n* 网络监视\n* 搜索\n* 移动应用场景\n\n##如何处理 HDInsight Storm 中的数据？\n\nApache Storm 运行的是**拓扑**，而不是你在 HDInsight 或 Hadoop 中可能熟悉的 MapReduce 作业。Storm on HDInsight 群集包含两种类型的节点：运行 **Nimbus** 的头节点和运行 **Supervisor** 的辅助节点。\n\n* **Nimbus**：类似于 Hadoop 中的 JobTracker，负责在整个群集中分发代码、将任务分配给虚拟机以及监视故障情况。HDInsight 提供两个 Nimbus 节点，因此 Storm on HDInsight 不会出现单点故障\n\n* **Supervisor**：每个辅助节点的 supervisor 负责启动和停止该节点上的**工作进程**。\n\n* **工作进程**：运行**拓扑**的一个子集。正在运行的拓扑分布在整个群集的许多工作进程上。\n\n* **拓扑**：定义处理数据**流**的计算图形。与 MapReduce 作业不同，拓扑运行到你停止它们为止。\n\n* **流**：一个未绑定的**元组**集合。流由 **spout** 和 **bolt** 生成，并由 **bolt** 使用。\n\n* **元组**：动态类型化值的一个命名列表。\n\n* **Spout**：使用数据源中的数据并发出一个或多个**流**。\n\n    > [AZURE.NOTE]在许多情况下，从 Kafka、Azure 服务总线队列或事件中心等队列中读取数据。队列确保发生中断时数据持续不断。\n\n* **Bolt**：使用**流**，处理**元组**，并可以发出**流**。Bolt 还负责将数据编写到外部存储，比如队列、HDInsight HBase、blob 或其他数据存储。\n\n* **Apache Thrift**：用于可缩放跨语言服务开发的软件框架。可用于构建在 C++、Java、Python、PHP、Ruby、Erlang、Perl、Haskell、C#、Cocoa、JavaScript、Node.js、Smalltalk 及其他语言间工作的服务。\n\n    * **Nimbus** 是一种 Thrift 服务，**拓扑**是 Thrift 定义，因此可以使用各种编程语言来开发拓扑\n\n有关 Storm 组件的详细信息，请参阅 apache.org 上的 [Storm 教程][apachetutorial]。\n\n\n##我可以使用哪些编程语言？\n\nStorm on HDInsight 群集支持 C#、Java 和 Python。\n\n### C&#35;\n\nHDInsight Tools for Visual Studio 允许 .NET 开发人员以 C# 语言设计和实施拓扑。你也可以创建使用 Java 和 C# 组件的混合拓扑。\n\n有关详细信息，请参阅[使用 Visual Studio 开发 Apache Storm on HDInsight 的 C# 拓扑](/documentation/articles/hdinsight-storm-develop-csharp-visual-studio-topology)。\n\n###Java\n\n你遇到的大多数 Java 示例都是无格式 Java 或 Trident。Trident 是一个高级别抽象，可更轻松地执行联接、汇总、分组和筛选等操作。但是，Trident 作用于批量元组，其中原始 Java 解决方案一次将处理一个元组流。\n\n有关 Trident 的详细信息，请参阅 apache.org 上的 [Trident 教程](https://storm.incubator.apache.org/documentation/Trident-tutorial.html)。\n\n有关 Java 和 Trident 拓扑的示例，请参阅 [Storm 拓扑示例列表](/documentation/articles/hdinsight-storm-example-topology)或 HDInsight 群集上的 storm-starter 示例。\n\nstorm-starter 示例位于基于 Windows 的群集上的 **%storm\\_home%\\\\contrib\\\\storm-starter** 目录中。\n\n##常见的开发模式有哪些？\n\n###有保证的消息处理\n\nStorm 可以提供不同级别的有保证的消息处理。例如，基本的 Storm 应用程序至少可以保证一次处理，而 Trident 仅可以保证一次处理。\n\n有关详细信息，请参阅 apache.org 上的[数据处理保证](https://storm.apache.org/about/guarantees-data-processing.html)。\n\n###IBasicBolt\n\n读取输入元组，发出零个或多个元组，然后在执行方法结束时立即询问输入元组，这种模式非常普通，以至 Storm 提供 [IBasicBolt](https://storm.apache.org/apidocs/backtype/storm/topology/IBasicBolt.html) 接口来自动执行这种模式。\n\n###联接\n\n在应用程序之间联接两个数据流的方式将有所不同。例如，你可以从多个流将每个元组联接到一个新流，也可以仅联接特定窗口的批量元组。两种方式的联接都可以使用 [fieldsGrouping](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29) 来实现，它是定义元组如何路由到 bolt 的方式。\n\n在以下 Java 实例中，fieldsGrouping 用于将来自组件“1”、“2”和“3”的元组路由至 **MyJoiner** bolt。\n\n    builder.setBolt(\"join\", new MyJoiner(), parallelism) .fieldsGrouping(\"1\", new Fields(\"joinfield1\", \"joinfield2\")) .fieldsGrouping(\"2\", new Fields(\"joinfield1\", \"joinfield2\")) .fieldsGrouping(\"3\", new Fields(\"joinfield1\", \"joinfield2\"));\n\n###批处理\n\n批处理可以通过若干方式来实现。利用基本 Storm Java 拓扑，你可以在发出元组前使用简单计数器对 X 个元组进行批处理，或使用称为计时周期元组的内部计时机制每 X 秒发出一批元组。\n\n有关使用计时周期元组的示例，请参阅[使用 HDInsight 上的 Storm 和 HBase 分析传感器数据](/documentation/articles/hdinsight-storm-sensor-data-analysis)。\n\n如果你使用的是 Trident，则其基于批量处理元组。\n\n###缓存\n\n内存缓存通常用作加速处理的机制，因为它在内存中存储常用资产。由于拓扑分布于多个节点，并且每个节点中有多个进程，你应考虑使用 [fieldsGrouping](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29) 来确保包含用于缓存查询的字段的元组始终路由至同一进程。这可以避免在进程间重复缓存条目。\n\n###流式处理 top N\n\n当拓扑依赖于计算“top”N 值（比如 Twitter 上的前 5 大趋势）时，你应并行计算 top N 值，然后将这些计算的输出合并到全局值中。为此，可以使用 [fieldsGrouping](http://javadox.com/org.apache.storm/storm-core/0.9.1-incubating/backtype/storm/topology/InputDeclarer.html#fieldsGrouping%28java.lang.String,%20backtype.storm.tuple.Fields%29) 按字段路由至并行 bolt（该项按字段值对数据进行划分），然后路由至全局确定前 N 个值的 bolt。\n\n有关此内容的示例，请参阅 [RollingTopWords](https://github.com/nathanmarz/storm-starter/blob/master/src/jvm/storm/starter/RollingTopWords.java) 示例。\n\n##后续步骤\n\n了解有关使用 HDInsight 中的 Apache Storm 构建实时分析解决方案的详细信息：\n\n* [Storm on HDInsight 入门][gettingstarted]\n\n* [Storm on HDInsight 的示例拓扑](/documentation/articles/hdinsight-storm-example-topology)\n\n[stormtrident]: https://storm.incubator.apache.org/documentation/Trident-API-Overview.html\n[samoa]: http://yahooeng.tumblr.com/post/65453012905/introducing-samoa-an-open-source-platform-for-mining\n[apachetutorial]: https://storm.incubator.apache.org/documentation/Tutorial.html\n[gettingstarted]: /documentation/articles/hdinsight-apache-storm-tutorial-get-started\n\n<!---HONumber=Mooncake_0215_2016-->"
}