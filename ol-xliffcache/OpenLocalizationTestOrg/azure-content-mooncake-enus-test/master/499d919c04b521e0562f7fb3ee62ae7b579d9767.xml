{
  "nodes": [
    {
      "content": "在 HDInsight 中将 Pig 与远程桌面配合使用 | Azure",
      "pos": [
        26,
        62
      ]
    },
    {
      "content": "了解如何使用 Pig 命令从到基于 Windows 的 HDInsight Hadoop 群集的远程桌面连接运行 Pig Latin 语句。",
      "pos": [
        80,
        150
      ]
    },
    {
      "content": "从远程桌面连接运行 Pig 作业",
      "pos": [
        384,
        400
      ]
    },
    {
      "content": "本文档演练了如何使用 Pig 命令从到基于 Windows 的 HDInsight 群集的远程桌面连接运行 Pig Latin 语句。Pig Latin 可让你通过描述数据转换来创建 MapReduce 应用程序，而不是创建映射和化简函数。",
      "pos": [
        477,
        597
      ]
    },
    {
      "content": "在本文档中，学习如何",
      "pos": [
        599,
        609
      ]
    },
    {
      "pos": [
        613,
        636
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"prereq\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>先决条件"
    },
    {
      "content": "若要完成本文中的步骤，你将需要：",
      "pos": [
        638,
        654
      ]
    },
    {
      "content": "基于 Windows 的 HDInsight（HDInsight 上的 Hadoop）群集",
      "pos": [
        658,
        703
      ]
    },
    {
      "content": "运行 Windows 10、Windows 8 或 Windows 7 的客户端计算机",
      "pos": [
        707,
        750
      ]
    },
    {
      "pos": [
        754,
        784
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"connect\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>使用远程桌面进行连接"
    },
    {
      "pos": [
        786,
        922
      ],
      "content": "为 HDInsight 群集启用远程桌面，然后根据<bpt id=\"p1\">[</bpt>使用 RDP 连接到 HDInsight 群集<ept id=\"p1\">](/documentation/articles/hdinsight-administer-use-management-portal-v1#rdp)</ept>中的说明连接到该群集。"
    },
    {
      "pos": [
        926,
        951
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"pig\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>使用 Pig 命令"
    },
    {
      "pos": [
        956,
        996
      ],
      "content": "在建立远程桌面连接后，通过使用桌面上的图标来启动 <bpt id=\"p1\">**</bpt>Hadoop 命令行<ept id=\"p1\">**</ept>。"
    },
    {
      "content": "使用以下命令来启动 Pig 命令行：",
      "pos": [
        1001,
        1019
      ]
    },
    {
      "pos": [
        1053,
        1074
      ],
      "content": "系统将为你提供 <ph id=\"ph1\">`grunt&gt;`</ph> 提示符。"
    },
    {
      "content": "输入以下语句：",
      "pos": [
        1079,
        1086
      ]
    },
    {
      "content": "此命令会将 sample.log 文件的内容加载到 LOGS 文件中。你可以通过使用以下方法查看该文件的内容：",
      "pos": [
        1148,
        1203
      ]
    },
    {
      "content": "通过应用正则表达式从每个记录中仅提取日志记录级别来转换数据：",
      "pos": [
        1228,
        1258
      ]
    },
    {
      "pos": [
        1378,
        1424
      ],
      "content": "转换后，你可以使用 <bpt id=\"p1\">**</bpt>DUMP<ept id=\"p1\">**</ept> 来查看数据。在本例中为 <ph id=\"ph1\">`DUMP LEVELS;`</ph>。"
    },
    {
      "pos": [
        1429,
        1465
      ],
      "content": "使用以下语句继续应用转换。使用 <ph id=\"ph1\">`DUMP`</ph> 查看每个步骤后的转换结果。"
    },
    {
      "content": "语句",
      "pos": [
        1488,
        1490
      ]
    },
    {
      "content": "作用",
      "pos": [
        1499,
        1501
      ]
    },
    {
      "content": "FILTEREDLEVELS = FILTER LEVELS by LOGLEVEL is not null;",
      "pos": [
        1522,
        1577
      ]
    },
    {
      "content": "删除包含日志级别 Null 值的行，并将结果存储到 FILTEREDLEVELS。",
      "pos": [
        1586,
        1627
      ]
    },
    {
      "content": "GROUPEDLEVELS = GROUP FILTEREDLEVELS by LOGLEVEL;",
      "pos": [
        1648,
        1697
      ]
    },
    {
      "content": "按日志级别对行进行分组，并将结果存储到 GROUPEDLEVELS。",
      "pos": [
        1706,
        1740
      ]
    },
    {
      "content": "FREQUENCIES = foreach GROUPEDLEVELS generate group as LOGLEVEL, COUNT(FILTEREDLEVELS.LOGLEVEL) as COUNT;",
      "pos": [
        1761,
        1865
      ]
    },
    {
      "content": "创建一组新的数据，其中包含每个唯一日志级别值和其发生次数。此数据将存储到 FREQUENCIES",
      "pos": [
        1874,
        1922
      ]
    },
    {
      "content": "RESULT = order FREQUENCIES by COUNT desc;",
      "pos": [
        1943,
        1984
      ]
    },
    {
      "content": "按计数为日志级别排序（降序），并存储到 RESULT",
      "pos": [
        1993,
        2019
      ]
    },
    {
      "pos": [
        2044,
        2129
      ],
      "content": "你也可以使用 <ph id=\"ph1\">`STORE`</ph> 语句保存转换结果。例如，以下命令将 <ph id=\"ph2\">`RESULT`</ph> 保存到群集的默认存储容器上的 <bpt id=\"p1\">**</bpt>/example/data/pigout<ept id=\"p1\">**</ept> 目录："
    },
    {
      "pos": [
        2194,
        2260
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>数据将存储到指定目录中名为 <bpt id=\"p1\">**</bpt>part-nnnnn<ept id=\"p1\">**</ept> 的文件中。如果该目录已存在，则你将会收到错误消息。"
    },
    {
      "content": "若要退出 grunt 提示符，请输入以下语句。",
      "pos": [
        2265,
        2288
      ]
    },
    {
      "content": "Pig Latin 批处理文件",
      "pos": [
        2308,
        2323
      ]
    },
    {
      "content": "你也可以使用 Pig 命令运行文件中包含的 Pig Latin。",
      "pos": [
        2325,
        2357
      ]
    },
    {
      "pos": [
        2362,
        2434
      ],
      "content": "退出 grunt 提示符之后，请打开“记事本”，并在 <bpt id=\"p1\">**</bpt>%PIG_HOME%<ept id=\"p1\">**</ept> 目录中创建名为 <bpt id=\"p2\">**</bpt>pigbatch.pig<ept id=\"p2\">**</ept> 的新文件。"
    },
    {
      "pos": [
        2439,
        2476
      ],
      "content": "在 <bpt id=\"p1\">**</bpt>pigbatch.pig<ept id=\"p1\">**</ept> 文件中键入或粘贴以下行，然后保存它："
    },
    {
      "pos": [
        2956,
        2996
      ],
      "content": "使用以下命令，以使用 pig 命令运行 <bpt id=\"p1\">**</bpt>pigbatch.pig<ept id=\"p1\">**</ept> 文件。"
    },
    {
      "pos": [
        3039,
        3093
      ],
      "content": "在批处理作业完成后，你应该会看到以下输出，该输出应该与先前步骤中使用 <ph id=\"ph1\">`DUMP RESULT;`</ph> 时相同："
    },
    {
      "pos": [
        3210,
        3232
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"summary\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>摘要"
    },
    {
      "content": "如你所见，Pig 命令允许你以交互方式运行 MapReduce 操作，或运行存储在批处理文件中的 Pig Latin 作业。",
      "pos": [
        3234,
        3296
      ]
    },
    {
      "pos": [
        3300,
        3326
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"nextsteps\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>后续步骤"
    },
    {
      "content": "有关 HDInsight 中的 Pig 的一般信息：",
      "pos": [
        3328,
        3354
      ]
    },
    {
      "content": "将 Pig 与 HDInsight 上的 Hadoop 配合使用",
      "pos": [
        3359,
        3391
      ]
    },
    {
      "content": "有关 HDInsight 上的 Hadoop 的其他使用方法的信息：",
      "pos": [
        3438,
        3472
      ]
    },
    {
      "content": "将 Hive 与 HDInsight 上的 Hadoop 配合使用",
      "pos": [
        3477,
        3510
      ]
    },
    {
      "content": "将 MapReduce 与 HDInsight 上的 Hadoop 配合使用",
      "pos": [
        3561,
        3599
      ]
    }
  ],
  "content": "<properties\n   pageTitle=\"在 HDInsight 中将 Pig 与远程桌面配合使用 | Azure\"\n   description=\"了解如何使用 Pig 命令从到基于 Windows 的 HDInsight Hadoop 群集的远程桌面连接运行 Pig Latin 语句。\"\n   services=\"hdinsight\"\n   documentationCenter=\"\"\n   authors=\"Blackmist\"\n   manager=\"paulettm\"\n   editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n\n<tags\n    ms.service=\"hdinsight\"\n    ms.date=\"12/04/2015\"\n    wacn.date=\"01/14/2016\"/>\n\n#从远程桌面连接运行 Pig 作业\n\n[AZURE.INCLUDE [pig-selector](../includes/hdinsight-selector-use-pig.md)]\n\n本文档演练了如何使用 Pig 命令从到基于 Windows 的 HDInsight 群集的远程桌面连接运行 Pig Latin 语句。Pig Latin 可让你通过描述数据转换来创建 MapReduce 应用程序，而不是创建映射和化简函数。\n\n在本文档中，学习如何\n\n##<a id=\"prereq\"></a>先决条件\n\n若要完成本文中的步骤，你将需要：\n\n* 基于 Windows 的 HDInsight（HDInsight 上的 Hadoop）群集\n\n* 运行 Windows 10、Windows 8 或 Windows 7 的客户端计算机\n\n##<a id=\"connect\"></a>使用远程桌面进行连接\n\n为 HDInsight 群集启用远程桌面，然后根据[使用 RDP 连接到 HDInsight 群集](/documentation/articles/hdinsight-administer-use-management-portal-v1#rdp)中的说明连接到该群集。\n\n##<a id=\"pig\"></a>使用 Pig 命令\n\n2. 在建立远程桌面连接后，通过使用桌面上的图标来启动 **Hadoop 命令行**。\n\n2. 使用以下命令来启动 Pig 命令行：\n\n        %pig_home%\\bin\\pig\n\n    系统将为你提供 `grunt>` 提示符。\n\n3. 输入以下语句：\n\n        LOGS = LOAD 'wasb:///example/data/sample.log';\n\n    此命令会将 sample.log 文件的内容加载到 LOGS 文件中。你可以通过使用以下方法查看该文件的内容：\n\n        DUMP LOGS;\n\n4. 通过应用正则表达式从每个记录中仅提取日志记录级别来转换数据：\n\n        LEVELS = foreach LOGS generate REGEX_EXTRACT($0, '(TRACE|DEBUG|INFO|WARN|ERROR|FATAL)', 1)  as LOGLEVEL;\n\n    转换后，你可以使用 **DUMP** 来查看数据。在本例中为 `DUMP LEVELS;`。\n\n5. 使用以下语句继续应用转换。使用 `DUMP` 查看每个步骤后的转换结果。\n\n    <table>\n<tr>\n<th>语句</th><th>作用</th>\n</tr>\n<tr>\n<td>FILTEREDLEVELS = FILTER LEVELS by LOGLEVEL is not null;</td><td>删除包含日志级别 Null 值的行，并将结果存储到 FILTEREDLEVELS。</td>\n</tr>\n<tr>\n<td>GROUPEDLEVELS = GROUP FILTEREDLEVELS by LOGLEVEL;</td><td>按日志级别对行进行分组，并将结果存储到 GROUPEDLEVELS。</td>\n</tr>\n<tr>\n<td>FREQUENCIES = foreach GROUPEDLEVELS generate group as LOGLEVEL, COUNT(FILTEREDLEVELS.LOGLEVEL) as COUNT;</td><td>创建一组新的数据，其中包含每个唯一日志级别值和其发生次数。此数据将存储到 FREQUENCIES</td>\n</tr>\n<tr>\n<td>RESULT = order FREQUENCIES by COUNT desc;</td><td>按计数为日志级别排序（降序），并存储到 RESULT</td>\n</tr>\n</table>\n\n6. 你也可以使用 `STORE` 语句保存转换结果。例如，以下命令将 `RESULT` 保存到群集的默认存储容器上的 **/example/data/pigout** 目录：\n\n        STORE RESULT into 'wasb:///example/data/pigout'\n\n    > [AZURE.NOTE]数据将存储到指定目录中名为 **part-nnnnn** 的文件中。如果该目录已存在，则你将会收到错误消息。\n\n7. 若要退出 grunt 提示符，请输入以下语句。\n\n        QUIT;\n\n###Pig Latin 批处理文件\n\n你也可以使用 Pig 命令运行文件中包含的 Pig Latin。\n\n3. 退出 grunt 提示符之后，请打开“记事本”，并在 **%PIG_HOME%** 目录中创建名为 **pigbatch.pig** 的新文件。\n\n4. 在 **pigbatch.pig** 文件中键入或粘贴以下行，然后保存它：\n\n        LOGS = LOAD 'wasb:///example/data/sample.log';\n        LEVELS = foreach LOGS generate REGEX_EXTRACT($0, '(TRACE|DEBUG|INFO|WARN|ERROR|FATAL)', 1)  as LOGLEVEL;\n        FILTEREDLEVELS = FILTER LEVELS by LOGLEVEL is not null;\n        GROUPEDLEVELS = GROUP FILTEREDLEVELS by LOGLEVEL;\n        FREQUENCIES = foreach GROUPEDLEVELS generate group as LOGLEVEL, COUNT(FILTEREDLEVELS.LOGLEVEL) as COUNT;\n        RESULT = order FREQUENCIES by COUNT desc;\n        DUMP RESULT;\n\n5. 使用以下命令，以使用 pig 命令运行 **pigbatch.pig** 文件。\n\n        pig %PIG_HOME%\\pigbatch.pig\n\n    在批处理作业完成后，你应该会看到以下输出，该输出应该与先前步骤中使用 `DUMP RESULT;` 时相同：\n\n        (TRACE,816)\n        (DEBUG,434)\n        (INFO,96)\n        (WARN,11)\n        (ERROR,6)\n        (FATAL,2)\n\n##<a id=\"summary\"></a>摘要\n\n如你所见，Pig 命令允许你以交互方式运行 MapReduce 操作，或运行存储在批处理文件中的 Pig Latin 作业。\n\n##<a id=\"nextsteps\"></a>后续步骤\n\n有关 HDInsight 中的 Pig 的一般信息：\n\n* [将 Pig 与 HDInsight 上的 Hadoop 配合使用](/documentation/articles/hdinsight-use-pig/)\n\n有关 HDInsight 上的 Hadoop 的其他使用方法的信息：\n\n* [将 Hive 与 HDInsight 上的 Hadoop 配合使用](/documentation/articles/hdinsight-use-hive/)\n\n* [将 MapReduce 与 HDInsight 上的 Hadoop 配合使用](/documentation/articles/hdinsight-use-mapreduce/)\n\n<!---HONumber=71-->"
}