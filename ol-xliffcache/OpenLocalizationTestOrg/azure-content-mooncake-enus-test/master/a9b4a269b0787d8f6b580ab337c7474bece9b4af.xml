{
  "nodes": [
    {
      "content": "将数据迁移到 SQL 数据仓库 | Azure",
      "pos": [
        26,
        49
      ]
    },
    {
      "content": "有关在开发解决方案时将数据迁移到 Azure SQL 数据仓库的技巧。",
      "pos": [
        67,
        102
      ]
    },
    {
      "content": "迁移数据",
      "pos": [
        326,
        330
      ]
    },
    {
      "content": "迁移数据时的主要目标是填充 SQLDW 数据库。此过程可以通过多种方式来完成。ADF 复制、SSIS 和 bcp 都可用来实现此目标。但是，随着数据量的增加，你应该考虑将数据迁移过程划分成多个步骤。这样，你便有机会优化每个步骤以提高性能和弹性，确保顺利迁移数据。",
      "pos": [
        331,
        462
      ]
    },
    {
      "content": "本文首先讨论 ADF 复制、SSIS 和 bcp 的简单迁移方案。然后稍微深入讨论如何优化迁移。",
      "pos": [
        464,
        512
      ]
    },
    {
      "content": "Azure 数据工厂 (ADF) 复制",
      "pos": [
        517,
        536
      ]
    },
    {
      "content": "ADF 复制是Azure 数据工厂的一部分。你可以使用 ADF 复制将数据导出到位于本地存储的平面文件、保留在 Azure Blob 存储中的远程平面文件，或者直接导出到 SQL 数据仓库。",
      "pos": [
        537,
        632
      ]
    },
    {
      "content": "如果数据从平面文件开始，则在开始将数据载入 SQL 数据仓库之前，首先要将数据传输到 Azure 存储 Blob。将数据传输到 Azure Blob 存储后，可以选择再次使用ADF 复制，将数据推送到 SQL 数据仓库。",
      "pos": [
        634,
        744
      ]
    },
    {
      "content": "PolyBase 还提供极高性能的选项来加载数据。但是，这意味着要使用两种工具，而不只是一种工具。若要获得最佳性能，请使用 PolyBase。如果只想要使用单个工具（且数据量不大），则 ADF 就是答案。",
      "pos": [
        746,
        848
      ]
    },
    {
      "pos": [
        852,
        944
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>PolyBase 规定数据文件必须采用 UTF-8 格式。这是 ADF 复制的默认编码，因此不需要更改任何设置。这是为了提醒你不要更改 ADF 复制的默认行为。"
    },
    {
      "content": "以下文章提供了一些极好的ADF复制示例。",
      "pos": [
        946,
        966
      ]
    },
    {
      "content": "Integration Services",
      "pos": [
        971,
        991
      ]
    },
    {
      "content": "集成服务 (SSIS) 是一个功能强大且灵活的提取、转换和加载 (ETL) 工具，支持复杂的工作流、数据转换，以及多个数据加载选项。使用 SSIS 可以单纯将数据传输到 Azure，或作为更广泛迁移的一部分。",
      "pos": [
        995,
        1099
      ]
    },
    {
      "pos": [
        1103,
        1242
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>SSIS 可以导出为 UTF-8，文件中不需要有字节顺序标记。若要这样配置，必须先使用派生的列组件，转换数据流中的字符数据来使用 65001 UTF-8 代码页。转换列之后，将数据写入平面文件目标适配器，但要确保同时选择了 65001 作为文件的代码页。"
    },
    {
      "pos": [
        1244,
        1371
      ],
      "content": "SSIS 将连接到 SQL 数据仓库，就像连接到 SQL Server 部署一样。但是，你的连接需要使用 ADO.NET 连接管理器。你还应谨慎配置“可用时使用批量插入”设置，以最大化吞吐量。请参阅 <bpt id=\"p1\">[</bpt>ADO.NET 目标适配器<ept id=\"p1\">][]</ept>一文以深入了解此属性"
    },
    {
      "pos": [
        1375,
        1418
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>不支持使用 OLEDB 连接到 Azure SQL 数据仓库。"
    },
    {
      "content": "此外，包经常可能会因为限制或网络问题而失败。请将包设计为可以从失败点恢复，而不必重做失败之前已完成的工作。",
      "pos": [
        1420,
        1473
      ]
    },
    {
      "pos": [
        1475,
        1498
      ],
      "content": "有关详细信息，请参阅 <bpt id=\"p1\">[</bpt>SSIS 文档<ept id=\"p1\">][]</ept>。"
    },
    {
      "content": "bcp",
      "pos": [
        1503,
        1506
      ]
    },
    {
      "content": "bcp 是专为平面文件数据导入和导出所设计的命令行实用程序。数据导出期间可以进行某些转换。若要执行简单的转换，请使用查询来选择和转换数据。导出之后，可将平面文件直接加载到目标 SQL 数据仓库数据库。",
      "pos": [
        1507,
        1607
      ]
    },
    {
      "pos": [
        1611,
        1670
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>通常建议将数据导出时使用的转换封装在源系统上的视图中。这可以确保逻辑得到保留，并且过程可重复。"
    },
    {
      "content": "bcp 的优点包括：",
      "pos": [
        1672,
        1682
      ]
    },
    {
      "content": "简单。bcp 命令的构建和执行十分简单",
      "pos": [
        1686,
        1705
      ]
    },
    {
      "content": "可重新启动的加载过程。导出后，即可不限次数执行加载",
      "pos": [
        1708,
        1733
      ]
    },
    {
      "content": "bcp 的限制包括：",
      "pos": [
        1735,
        1745
      ]
    },
    {
      "content": "bcp 只能使用表格型平面文件。无法使用 xml 或 JSON 之类的文件",
      "pos": [
        1749,
        1786
      ]
    },
    {
      "content": "bcp 不支持导出为 UTF-8。这可能导致无法对 bcp 导出的数据使用 PolyBase",
      "pos": [
        1789,
        1835
      ]
    },
    {
      "content": "数据转换功能仅限于导出阶段且性质简单",
      "pos": [
        1838,
        1856
      ]
    },
    {
      "content": "当通过 Internet 加载数据时，bcp 的设计尚不够健全。任何网络不稳定状况都可能造成加载错误。",
      "pos": [
        1859,
        1910
      ]
    },
    {
      "content": "bcp 依赖于加载之前存在于目标数据库中的架构",
      "pos": [
        1913,
        1936
      ]
    },
    {
      "pos": [
        1938,
        1974
      ],
      "content": "有关详细信息，请参阅<bpt id=\"p1\">[</bpt>使用 bcp 将数据载入 SQL 数据仓库<ept id=\"p1\">][]</ept>。"
    },
    {
      "content": "优化数据迁移",
      "pos": [
        1979,
        1985
      ]
    },
    {
      "content": "SQLDW 数据迁移过程可以有效地划分成三个独立的步骤：",
      "pos": [
        1986,
        2014
      ]
    },
    {
      "content": "导出源数据",
      "pos": [
        2019,
        2024
      ]
    },
    {
      "content": "将数据传输到 Azure",
      "pos": [
        2028,
        2040
      ]
    },
    {
      "content": "载入目标 SQLDW 数据库",
      "pos": [
        2044,
        2058
      ]
    },
    {
      "content": "每个步骤可以单独进行优化，以创建稳健、可重新启动且富有弹性的迁移过程，让每个步骤发挥最高的性能。",
      "pos": [
        2060,
        2108
      ]
    },
    {
      "content": "优化数据加载",
      "pos": [
        2113,
        2119
      ]
    },
    {
      "content": "反过来看，加载数据最快的方式是通过 PolyBase。优化 PolyBase 加载过程对上述步骤规定了先决条件，最好先了解这一点。它们具有以下特点：",
      "pos": [
        2120,
        2194
      ]
    },
    {
      "content": "数据文件的编码",
      "pos": [
        2199,
        2206
      ]
    },
    {
      "content": "数据文件的格式",
      "pos": [
        2210,
        2217
      ]
    },
    {
      "content": "数据文件的位置",
      "pos": [
        2221,
        2228
      ]
    },
    {
      "content": "编码",
      "pos": [
        2234,
        2236
      ]
    },
    {
      "content": "PolyBase 规定数据文件必须采用 UTF-8 编码。这意味着在导出数据时，数据必须符合这项要求。如果数据只包含基本 ASCII 字符（不是扩展的 ASCII），则这些直接映射到 UTF-8 标准，不需要太担心编码。但是，如果数据包含任何特殊字符，例如变音符、腔调符或符号，或数据支持非拉丁语言，则必须确保导出文件经过适当的 UTF-8 编码。",
      "pos": [
        2237,
        2411
      ]
    },
    {
      "pos": [
        2415,
        2511
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>bcp 不支持将数据导出为 UTF-8。因此，最好的选择是使用集成服务或 ADF 复制来导出数据。值得指出的是，数据文件中不需要 UTF-8 字节顺序标记 (BOM)。"
    },
    {
      "pos": [
        2513,
        2553
      ],
      "content": "数据传输<bpt id=\"p1\">***</bpt>之前<ept id=\"p1\">***</ept>，任何使用 UFT-16 编码的文件都需要经过重新编写。"
    },
    {
      "content": "数据文件的格式",
      "pos": [
        2559,
        2566
      ]
    },
    {
      "content": "PolyBase 规定要有固定的行终止符 \\\\n 或换行符。数据文件必须符合此标准。字符串或列终止符没有任何限制。",
      "pos": [
        2567,
        2624
      ]
    },
    {
      "content": "在 PolyBase 中，必须将文件中的每个列定义为外部表的一部分。请确保所有导出的列都是必需的，且类型符合所需的标准。",
      "pos": [
        2626,
        2686
      ]
    },
    {
      "content": "有关支持的数据类型的详细信息，请参阅前面的 [迁移架构] 一文。",
      "pos": [
        2688,
        2720
      ]
    },
    {
      "content": "数据文件的位置",
      "pos": [
        2726,
        2733
      ]
    },
    {
      "content": "SQL 数据仓库只使用 PolyBase 从 Azure Blob 存储加载数据。因此，数据必须先传输到 Blob 存储。",
      "pos": [
        2734,
        2795
      ]
    },
    {
      "content": "优化数据传输",
      "pos": [
        2800,
        2806
      ]
    },
    {
      "content": "数据迁移过程中，最慢的一部分是将数据传输到 Azure。不只网络带宽可能是个问题，网络可靠性也可能会严重阻碍进度。默认情况下，将数据迁移到 Azure 是通过 Internet 完成的，因此很可能会发生传输错误。但是，这些错误可能需要重新发送整个或部分数据。",
      "pos": [
        2807,
        2936
      ]
    },
    {
      "content": "幸运的是，有多个选项可以提升此过程的速度和恢复能力：",
      "pos": [
        2938,
        2964
      ]
    },
    {
      "content": "ExpressRoute",
      "pos": [
        2971,
        2983
      ]
    },
    {
      "pos": [
        2987,
        3115
      ],
      "content": "你可以考虑使用 <bpt id=\"p1\">[</bpt>ExpressRoute<ept id=\"p1\">][]</ept> 加速传输。<bpt id=\"p2\">[</bpt>ExpressRoute<ept id=\"p2\">][]</ept> 为你提供可靠的 Azure 专用连接，这种连接不经由公共 Internet。这不是一项强制措施。但是，从本地或共置设备向 Azure 推送数据时，它会改善吞吐量。"
    },
    {
      "pos": [
        3117,
        3143
      ],
      "content": "使用 <bpt id=\"p1\">[</bpt>ExpressRoute<ept id=\"p1\">][]</ept> 的优点包括："
    },
    {
      "content": "更高的可靠性",
      "pos": [
        3148,
        3154
      ]
    },
    {
      "content": "更快的网络速度",
      "pos": [
        3158,
        3165
      ]
    },
    {
      "content": "更低的网络延迟",
      "pos": [
        3169,
        3176
      ]
    },
    {
      "content": "更高的网络安全性",
      "pos": [
        3180,
        3188
      ]
    },
    {
      "pos": [
        3190,
        3222
      ],
      "content": "<bpt id=\"p1\">[</bpt>ExpressRoute<ept id=\"p1\">][]</ept> 有利于许多情况，而不只是迁移。"
    },
    {
      "pos": [
        3224,
        3264
      ],
      "content": "感兴趣吗？ 有关详细信息和价格，请访问 <bpt id=\"p1\">[</bpt>ExpressRoute 文档<ept id=\"p1\">][]</ept>。"
    },
    {
      "content": "Azure 导入和导出服务",
      "pos": [
        3270,
        3283
      ]
    },
    {
      "content": "Azure 导入和导出服务是一个数据传输进程，用于将大量 (GB++) 和巨量 (TB++) 的数据传输到 Azure。它涉及到将数据写入磁盘并传送到 Azure 数据中心。然后代你将磁盘内容载入 Azure 存储 Blob。",
      "pos": [
        3284,
        3397
      ]
    },
    {
      "content": "导入导出过程的高级视图如下：",
      "pos": [
        3399,
        3413
      ]
    },
    {
      "content": "配置要接收数据的 Azure Blob 存储容器",
      "pos": [
        3418,
        3442
      ]
    },
    {
      "content": "将数据导出到本地存储",
      "pos": [
        3446,
        3456
      ]
    },
    {
      "content": "使用 [Azure 导入/导出工具] 将数据复制到 3.5 英吋 SATA II/III 硬盘",
      "pos": [
        3460,
        3507
      ]
    },
    {
      "content": "使用 Azure 导入和导出服务，并提供 [Azure 导入/导出工具] 生成的日记文件，来创建导入作业",
      "pos": [
        3511,
        3563
      ]
    },
    {
      "content": "将磁盘寄送到指定的 Azure 数据中心",
      "pos": [
        3567,
        3587
      ]
    },
    {
      "content": "你的数据将传输到 Azure Blob 存储容器",
      "pos": [
        3591,
        3615
      ]
    },
    {
      "content": "使用 PolyBase 将数据载入 SQLDW",
      "pos": [
        3619,
        3642
      ]
    },
    {
      "pos": [
        3648,
        3663
      ],
      "content": "<bpt id=\"p1\">[</bpt>AZCopy<ept id=\"p1\">][]</ept> 实用程序"
    },
    {
      "pos": [
        3664,
        3863
      ],
      "content": "<bpt id=\"p1\">[</bpt>AZCopy<ept id=\"p1\">][]</ept> 实用程序是将数据传输到 Azure 存储 Blob 的一个极佳工具。它旨在用于少量 (MB++) 到极大量 (GB++) 的数据传输。将数据传输到 Azure 时，<bpt id=\"p2\">[</bpt><ept id=\"p2\">AZCopy]</ept> 还能提供高度灵活的吞吐量，因此是数据传输措施的理想选择。传输后，你可以使用 PolyBase 将数据载入 SQL 数据仓库。你还可以使用“执行进程”任务将 AZCopy 合并到 SSIS 包中。"
    },
    {
      "pos": [
        3865,
        3909
      ],
      "content": "若要使用 AZCopy，必须先下载并安装它。可用版本包括<bpt id=\"p1\">[</bpt>生产版<ept id=\"p1\">][]</ept>和<bpt id=\"p2\">[</bpt>预览版<ept id=\"p2\">][]</ept>。"
    },
    {
      "content": "若要从文件系统上载文件，需要执行如下所示的命令：",
      "pos": [
        3911,
        3935
      ]
    },
    {
      "content": "高级过程摘要如下：",
      "pos": [
        4066,
        4075
      ]
    },
    {
      "content": "配置要接收数据的 Azure 存储 Blob 容器",
      "pos": [
        4080,
        4105
      ]
    },
    {
      "content": "将数据导出到本地存储",
      "pos": [
        4109,
        4119
      ]
    },
    {
      "content": "使用 AZCopy 复制 Azure Blob 存储容器中的数据",
      "pos": [
        4123,
        4155
      ]
    },
    {
      "content": "使用 PolyBase 将数据载入 SQL 数据仓库",
      "pos": [
        4159,
        4185
      ]
    },
    {
      "pos": [
        4187,
        4203
      ],
      "content": "完整文档：<bpt id=\"p1\">[</bpt>AZCopy<ept id=\"p1\">][]</ept>。"
    },
    {
      "content": "优化数据导出",
      "pos": [
        4208,
        4214
      ]
    },
    {
      "content": "除了确保导出符合 PolyBase 规定的要求外，你还可以设法优化数据导出，以进一步改善过程。",
      "pos": [
        4215,
        4262
      ]
    },
    {
      "pos": [
        4266,
        4379
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>由于 PolyBase 要求数据必须采用 UTF-8 格式，因此你不太可能会使用 bcp 来执行数据导出。bcp 不支持将数据文件输出为 UTF-8。SSIS 或 ADF 复制比较适合执行此类数据导出。"
    },
    {
      "content": "数据压缩",
      "pos": [
        4385,
        4389
      ]
    },
    {
      "content": "PolyBase 可以读取 gzip 压缩数据。如果你可以将数据压缩成 gzip 文件，就能将网络上推送的数据量减到最少。",
      "pos": [
        4390,
        4451
      ]
    },
    {
      "content": "多个文件",
      "pos": [
        4457,
        4461
      ]
    },
    {
      "content": "将大型表分割成多个文件不仅有助于改善导出速度，还有助于重新开始传输，以及数据进入 Azure Blob 存储之后的整体易管理性。PolyBase 的众多优点之一是可以读取文件夹内的所有文件，并将其视为一个表。因此，最好将每个表的文件隔离到它自身的文件夹中。",
      "pos": [
        4462,
        4590
      ]
    },
    {
      "content": "PolyBase 还支持名为“递归文件夹遍历”的功能。你可以使用此功能来进一步增强所导出数据的组织方式，以改善数据管理。",
      "pos": [
        4592,
        4652
      ]
    },
    {
      "pos": [
        4654,
        4713
      ],
      "content": "若要深入了解如何使用 PolyBase 加载数据，请参阅<bpt id=\"p1\">[</bpt>使用 PolyBase 将数据载入 SQL 数据仓库<ept id=\"p1\">][]</ept>。"
    },
    {
      "content": "后续步骤",
      "pos": [
        4719,
        4723
      ]
    },
    {
      "content": "有关迁移的详细信息，请参阅<bpt id=\"p1\">[</bpt>将解决方案迁移到 SQL 数据仓库<ept id=\"p1\">][]</ept>。",
      "pos": [
        4724,
        4759
      ]
    },
    {
      "content": "有关更多开发技巧，请参阅开发概述。",
      "pos": [
        4760,
        4777
      ]
    }
  ],
  "content": "<properties\n   pageTitle=\"将数据迁移到 SQL 数据仓库 | Azure\"\n   description=\"有关在开发解决方案时将数据迁移到 Azure SQL 数据仓库的技巧。\"\n   services=\"sql-data-warehouse\"\n   documentationCenter=\"NA\"\n   authors=\"jrowlandjones\"\n   manager=\"barbkess\"\n   editor=\"\"/>\n\n<tags\n   ms.service=\"sql-data-warehouse\"\n   ms.date=\"09/22/2015\"\n   wacn.date=\"01/20/2016\"/>\n\n# 迁移数据\n迁移数据时的主要目标是填充 SQLDW 数据库。此过程可以通过多种方式来完成。ADF 复制、SSIS 和 bcp 都可用来实现此目标。但是，随着数据量的增加，你应该考虑将数据迁移过程划分成多个步骤。这样，你便有机会优化每个步骤以提高性能和弹性，确保顺利迁移数据。\n\n本文首先讨论 ADF 复制、SSIS 和 bcp 的简单迁移方案。然后稍微深入讨论如何优化迁移。\n\n## Azure 数据工厂 (ADF) 复制\nADF 复制是Azure 数据工厂的一部分。你可以使用 ADF 复制将数据导出到位于本地存储的平面文件、保留在 Azure Blob 存储中的远程平面文件，或者直接导出到 SQL 数据仓库。\n\n如果数据从平面文件开始，则在开始将数据载入 SQL 数据仓库之前，首先要将数据传输到 Azure 存储 Blob。将数据传输到 Azure Blob 存储后，可以选择再次使用ADF 复制，将数据推送到 SQL 数据仓库。\n\nPolyBase 还提供极高性能的选项来加载数据。但是，这意味着要使用两种工具，而不只是一种工具。若要获得最佳性能，请使用 PolyBase。如果只想要使用单个工具（且数据量不大），则 ADF 就是答案。\n\n> [AZURE.NOTE]PolyBase 规定数据文件必须采用 UTF-8 格式。这是 ADF 复制的默认编码，因此不需要更改任何设置。这是为了提醒你不要更改 ADF 复制的默认行为。\n\n以下文章提供了一些极好的ADF复制示例。\n\n## Integration Services ##\n集成服务 (SSIS) 是一个功能强大且灵活的提取、转换和加载 (ETL) 工具，支持复杂的工作流、数据转换，以及多个数据加载选项。使用 SSIS 可以单纯将数据传输到 Azure，或作为更广泛迁移的一部分。\n\n> [AZURE.NOTE]SSIS 可以导出为 UTF-8，文件中不需要有字节顺序标记。若要这样配置，必须先使用派生的列组件，转换数据流中的字符数据来使用 65001 UTF-8 代码页。转换列之后，将数据写入平面文件目标适配器，但要确保同时选择了 65001 作为文件的代码页。\n\nSSIS 将连接到 SQL 数据仓库，就像连接到 SQL Server 部署一样。但是，你的连接需要使用 ADO.NET 连接管理器。你还应谨慎配置“可用时使用批量插入”设置，以最大化吞吐量。请参阅 [ADO.NET 目标适配器][]一文以深入了解此属性\n\n> [AZURE.NOTE]不支持使用 OLEDB 连接到 Azure SQL 数据仓库。\n\n此外，包经常可能会因为限制或网络问题而失败。请将包设计为可以从失败点恢复，而不必重做失败之前已完成的工作。\n\n有关详细信息，请参阅 [SSIS 文档][]。\n\n## bcp\nbcp 是专为平面文件数据导入和导出所设计的命令行实用程序。数据导出期间可以进行某些转换。若要执行简单的转换，请使用查询来选择和转换数据。导出之后，可将平面文件直接加载到目标 SQL 数据仓库数据库。\n\n> [AZURE.NOTE]通常建议将数据导出时使用的转换封装在源系统上的视图中。这可以确保逻辑得到保留，并且过程可重复。\n\nbcp 的优点包括：\n\n- 简单。bcp 命令的构建和执行十分简单\n- 可重新启动的加载过程。导出后，即可不限次数执行加载\n\nbcp 的限制包括：\n\n- bcp 只能使用表格型平面文件。无法使用 xml 或 JSON 之类的文件\n- bcp 不支持导出为 UTF-8。这可能导致无法对 bcp 导出的数据使用 PolyBase\n- 数据转换功能仅限于导出阶段且性质简单\n- 当通过 Internet 加载数据时，bcp 的设计尚不够健全。任何网络不稳定状况都可能造成加载错误。\n- bcp 依赖于加载之前存在于目标数据库中的架构\n\n有关详细信息，请参阅[使用 bcp 将数据载入 SQL 数据仓库][]。\n\n## 优化数据迁移\nSQLDW 数据迁移过程可以有效地划分成三个独立的步骤：\n\n1. 导出源数据\n2. 将数据传输到 Azure\n3. 载入目标 SQLDW 数据库\n\n每个步骤可以单独进行优化，以创建稳健、可重新启动且富有弹性的迁移过程，让每个步骤发挥最高的性能。\n\n## 优化数据加载\n反过来看，加载数据最快的方式是通过 PolyBase。优化 PolyBase 加载过程对上述步骤规定了先决条件，最好先了解这一点。它们具有以下特点：\n\n1. 数据文件的编码\n2. 数据文件的格式\n3. 数据文件的位置\n\n### 编码\nPolyBase 规定数据文件必须采用 UTF-8 编码。这意味着在导出数据时，数据必须符合这项要求。如果数据只包含基本 ASCII 字符（不是扩展的 ASCII），则这些直接映射到 UTF-8 标准，不需要太担心编码。但是，如果数据包含任何特殊字符，例如变音符、腔调符或符号，或数据支持非拉丁语言，则必须确保导出文件经过适当的 UTF-8 编码。\n\n> [AZURE.NOTE]bcp 不支持将数据导出为 UTF-8。因此，最好的选择是使用集成服务或 ADF 复制来导出数据。值得指出的是，数据文件中不需要 UTF-8 字节顺序标记 (BOM)。\n\n数据传输***之前***，任何使用 UFT-16 编码的文件都需要经过重新编写。\n\n### 数据文件的格式\nPolyBase 规定要有固定的行终止符 \\\\n 或换行符。数据文件必须符合此标准。字符串或列终止符没有任何限制。\n\n在 PolyBase 中，必须将文件中的每个列定义为外部表的一部分。请确保所有导出的列都是必需的，且类型符合所需的标准。\n\n有关支持的数据类型的详细信息，请参阅前面的 [迁移架构] 一文。\n\n### 数据文件的位置\nSQL 数据仓库只使用 PolyBase 从 Azure Blob 存储加载数据。因此，数据必须先传输到 Blob 存储。\n\n## 优化数据传输\n数据迁移过程中，最慢的一部分是将数据传输到 Azure。不只网络带宽可能是个问题，网络可靠性也可能会严重阻碍进度。默认情况下，将数据迁移到 Azure 是通过 Internet 完成的，因此很可能会发生传输错误。但是，这些错误可能需要重新发送整个或部分数据。\n\n幸运的是，有多个选项可以提升此过程的速度和恢复能力：\n\n### [ExpressRoute][]\n你可以考虑使用 [ExpressRoute][] 加速传输。[ExpressRoute][] 为你提供可靠的 Azure 专用连接，这种连接不经由公共 Internet。这不是一项强制措施。但是，从本地或共置设备向 Azure 推送数据时，它会改善吞吐量。\n\n使用 [ExpressRoute][] 的优点包括：\n\n1. 更高的可靠性\n2. 更快的网络速度\n3. 更低的网络延迟\n4. 更高的网络安全性\n\n[ExpressRoute][] 有利于许多情况，而不只是迁移。\n\n感兴趣吗？ 有关详细信息和价格，请访问 [ExpressRoute 文档][]。\n\n### Azure 导入和导出服务\nAzure 导入和导出服务是一个数据传输进程，用于将大量 (GB++) 和巨量 (TB++) 的数据传输到 Azure。它涉及到将数据写入磁盘并传送到 Azure 数据中心。然后代你将磁盘内容载入 Azure 存储 Blob。\n\n导入导出过程的高级视图如下：\n\n1. 配置要接收数据的 Azure Blob 存储容器\n2. 将数据导出到本地存储\n2. 使用 [Azure 导入/导出工具] 将数据复制到 3.5 英吋 SATA II/III 硬盘\n3. 使用 Azure 导入和导出服务，并提供 [Azure 导入/导出工具] 生成的日记文件，来创建导入作业\n4. 将磁盘寄送到指定的 Azure 数据中心\n5. 你的数据将传输到 Azure Blob 存储容器\n6. 使用 PolyBase 将数据载入 SQLDW\n\n### [AZCopy][] 实用程序\n[AZCopy][] 实用程序是将数据传输到 Azure 存储 Blob 的一个极佳工具。它旨在用于少量 (MB++) 到极大量 (GB++) 的数据传输。将数据传输到 Azure 时，[AZCopy] 还能提供高度灵活的吞吐量，因此是数据传输措施的理想选择。传输后，你可以使用 PolyBase 将数据载入 SQL 数据仓库。你还可以使用“执行进程”任务将 AZCopy 合并到 SSIS 包中。\n\n若要使用 AZCopy，必须先下载并安装它。可用版本包括[生产版][]和[预览版][]。\n\n若要从文件系统上载文件，需要执行如下所示的命令：\n\n```\nAzCopy /Source:C:\\myfolder /Dest:https://myaccount.blob.core.chinacloudapi.cn/mycontainer /DestKey:key /Pattern:abc.txt\n```\n\n高级过程摘要如下：\n\n1. 配置要接收数据的 Azure 存储 Blob 容器\n2. 将数据导出到本地存储\n3. 使用 AZCopy 复制 Azure Blob 存储容器中的数据\n4. 使用 PolyBase 将数据载入 SQL 数据仓库\n\n完整文档：[AZCopy][]。\n\n## 优化数据导出\n除了确保导出符合 PolyBase 规定的要求外，你还可以设法优化数据导出，以进一步改善过程。\n\n> [AZURE.NOTE]由于 PolyBase 要求数据必须采用 UTF-8 格式，因此你不太可能会使用 bcp 来执行数据导出。bcp 不支持将数据文件输出为 UTF-8。SSIS 或 ADF 复制比较适合执行此类数据导出。\n\n### 数据压缩\nPolyBase 可以读取 gzip 压缩数据。如果你可以将数据压缩成 gzip 文件，就能将网络上推送的数据量减到最少。\n\n### 多个文件\n将大型表分割成多个文件不仅有助于改善导出速度，还有助于重新开始传输，以及数据进入 Azure Blob 存储之后的整体易管理性。PolyBase 的众多优点之一是可以读取文件夹内的所有文件，并将其视为一个表。因此，最好将每个表的文件隔离到它自身的文件夹中。\n\nPolyBase 还支持名为“递归文件夹遍历”的功能。你可以使用此功能来进一步增强所导出数据的组织方式，以改善数据管理。\n\n若要深入了解如何使用 PolyBase 加载数据，请参阅[使用 PolyBase 将数据载入 SQL 数据仓库][]。\n\n\n## 后续步骤\n有关迁移的详细信息，请参阅[将解决方案迁移到 SQL 数据仓库][]。\n有关更多开发技巧，请参阅开发概述。\n\n<!--Image references-->\n\n<!--Article references-->\n[AZCopy]: /documentation/articles/storage-use-azcopy\n[ADF 复制]: /documentation/articles/data-factory-copy-activity\n[ADF 复制示例]: /documentation/articles/data-factory-copy-activity-examples\n[开发概述]: /documentation/articles/sql-data-warehouse-develop-overview\n[将解决方案迁移到 SQL 数据仓库]: /documentation/articles/sql-data-warehouse-overview-migrate\n[SQL Data Warehouse development overview]: /documentation/articles/sql-data-warehouse-overview-develop\n[使用 bcp 将数据载入 SQL 数据仓库]: /documentation/articles/sql-data-warehouse-load-with-bcp\n[使用 PolyBase 将数据载入 SQL 数据仓库]: /documentation/articles/sql-data-warehouse-load-with-polybase\n\n\n<!--MSDN references-->\n\n<!--Other Web references-->\n[Azure 数据工厂]: /services/data-factory/\n[ExpressRoute]: /services/expressroute/\n[ExpressRoute 文档]: /documentation/services/expressroute/\n\n[生产版]: http://aka.ms/downloadazcopy/\n[预览版]: http://aka.ms/downloadazcopypr/\n[ADO.NET 目标适配器]: https://msdn.microsoft.com/zh-cn/library/bb934041.aspx\n[SSIS 文档]: https://msdn.microsoft.com/zh-cn/library/ms141026.aspx\n\n<!---HONumber=Mooncake_1207_2015-->\n"
}