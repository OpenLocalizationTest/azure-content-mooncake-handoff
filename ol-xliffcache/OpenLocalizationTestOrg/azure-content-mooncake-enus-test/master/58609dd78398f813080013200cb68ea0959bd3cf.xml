{
  "nodes": [
    {
      "content": "使用 Maven 开发 Scalding MapReduce 作业 | Azure",
      "pos": [
        24,
        65
      ]
    },
    {
      "content": "了解如何使用 Maven 创建 Scalding MapReduce 作业，然后在 Hadoop on HDInsight 群集上部署并运行该作业。",
      "pos": [
        81,
        155
      ]
    },
    {
      "content": "使用 Apache Hadoop on HDInsight 开发 Scalding MapReduce 作业",
      "pos": [
        379,
        433
      ]
    },
    {
      "content": "Scalding 是一种 Scala 库，它可以让你轻松地创建 Hadoop MapReduce 作业。它提供简明的语法以及与 Scala 的紧密集成。",
      "pos": [
        435,
        511
      ]
    },
    {
      "content": "在本文档中，你将学习如何使用 Maven 来创建以 Scalding 编写的单词计数 MapReduce 作业。然后，你将学习如何在 HDInsight 群集上部署并运行此作业。",
      "pos": [
        513,
        602
      ]
    },
    {
      "content": "先决条件",
      "pos": [
        607,
        611
      ]
    },
    {
      "pos": [
        615,
        671
      ],
      "content": "<bpt id=\"p1\">**</bpt>一个 Azure 订阅<ept id=\"p1\">**</ept>。请参阅<bpt id=\"p2\">[</bpt>获取 Azure 试用版<ept id=\"p2\">](/pricing/1rmb-trial/)</ept>。"
    },
    {
      "pos": [
        674,
        815
      ],
      "content": "<bpt id=\"p1\">**</bpt>HDInsight 群集上基于 Windows 的 Hadoop<ept id=\"p1\">**</ept>。有关详细信息，请参阅<bpt id=\"p2\">[</bpt>在 HDInsight 上预配基于 Windows 的 Hadoop<ept id=\"p2\">](/documentation/articles/hdinsight-provision-clusters-v1)</ept>。"
    },
    {
      "content": "Maven",
      "pos": [
        822,
        827
      ]
    },
    {
      "pos": [
        862,
        951
      ],
      "content": "<bpt id=\"p1\">[</bpt>Java 平台 JDK<ept id=\"p1\">](http://www.oracle.com/technetwork/java/javase/downloads/index.html)</ept> 7 或更高版本"
    },
    {
      "content": "创建和生成项目",
      "pos": [
        958,
        965
      ]
    },
    {
      "content": "输入以下命令来创建新的 Maven 项目：",
      "pos": [
        970,
        991
      ]
    },
    {
      "pos": [
        1207,
        1263
      ],
      "content": "此命令将创建一个名为 <bpt id=\"p1\">**</bpt>scaldingwordcount<ept id=\"p1\">**</ept> 的新目录，并创建 Scala 应用程序的基架。"
    },
    {
      "pos": [
        1268,
        1326
      ],
      "content": "在 <bpt id=\"p1\">**</bpt>scaldingwordcount<ept id=\"p1\">**</ept> 目录中，打开 <bpt id=\"p2\">**</bpt>pom.xml<ept id=\"p2\">**</ept> 文件并将其内容替换为以下内容："
    },
    {
      "content": "此文件描述了项目、依赖关系和插件。以下是重要条目：",
      "pos": [
        5068,
        5093
      ]
    },
    {
      "pos": [
        5101,
        5169
      ],
      "content": "<bpt id=\"p1\">**</bpt>maven.compiler.source<ept id=\"p1\">**</ept> 和 <bpt id=\"p2\">**</bpt>maven.compiler.target<ept id=\"p2\">**</ept>：设置此项目的 Java 版本"
    },
    {
      "pos": [
        5177,
        5210
      ],
      "content": "<bpt id=\"p1\">**</bpt>repositories<ept id=\"p1\">**</ept>：包含此项目使用的依赖文件的存储库"
    },
    {
      "pos": [
        5218,
        5290
      ],
      "content": "<bpt id=\"p1\">**</bpt>scalding-core\\_2.11<ept id=\"p1\">**</ept> 和 <bpt id=\"p2\">**</bpt>hadoop-core<ept id=\"p2\">**</ept>：此项目依赖于 Scalding 和 Hadoop 核心程序包"
    },
    {
      "pos": [
        5298,
        5339
      ],
      "content": "<bpt id=\"p1\">**</bpt>maven-scala-plugin<ept id=\"p1\">**</ept>：用于编译 scala 应用程序的插件"
    },
    {
      "pos": [
        5347,
        5409
      ],
      "content": "<bpt id=\"p1\">**</bpt>maven-shade-plugin<ept id=\"p1\">**</ept>：用于创建阴影 (fat) jar 的插件。此插件将应用筛选器和转换，具体包括："
    },
    {
      "pos": [
        5421,
        5487
      ],
      "content": "<bpt id=\"p1\">**</bpt>筛选器<ept id=\"p1\">**</ept>：应用的筛选器将修改 jar 文件中包含的元信息。为了防止运行时发生签名异常，它会排除依赖项中可能包含的各种签名文件。"
    },
    {
      "pos": [
        5499,
        5632
      ],
      "content": "<bpt id=\"p1\">**</bpt>执行<ept id=\"p1\">**</ept>：程序包阶段执行配置将 <bpt id=\"p2\">**</bpt>com.twitter.scalding.Tool<ept id=\"p2\">**</ept> 类指定为程序包的主类。如果没有此项配置，则你在使用 hadoop 命令运行作业时，需要指定 com.twitter.scalding.Tool 以及包含应用程序逻辑的类。"
    },
    {
      "pos": [
        5637,
        5672
      ],
      "content": "删除 <bpt id=\"p1\">**</bpt>src/test<ept id=\"p1\">**</ept> 目录，因为你不需要使用此示例创建测试。"
    },
    {
      "pos": [
        5677,
        5747
      ],
      "content": "打开 <bpt id=\"p1\">**</bpt>src/main/scala/com/microsoft/example/app.scala<ept id=\"p1\">**</ept> 文件，并将其内容替换为以下内容："
    },
    {
      "content": "这将会实现基本的单词计数作业。",
      "pos": [
        6506,
        6521
      ]
    },
    {
      "content": "保存并关闭文件。",
      "pos": [
        6526,
        6534
      ]
    },
    {
      "pos": [
        6539,
        6581
      ],
      "content": "使用以下命令从 <bpt id=\"p1\">**</bpt>scaldingwordcount<ept id=\"p1\">**</ept> 目录生成并打包应用程序："
    },
    {
      "pos": [
        6608,
        6690
      ],
      "content": "完成此作业后，可以在 <bpt id=\"p1\">**</bpt>target/scaldingwordcount-1.0-SNAPSHOT.jar<ept id=\"p1\">**</ept> 中找到包含 WordCount 应用程序的程序包。"
    },
    {
      "content": "在基于 Windows 的群集上运行作业",
      "pos": [
        6695,
        6715
      ]
    },
    {
      "pos": [
        6719,
        6870
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>以下步骤使用 Windows PowerShell。有关运行 MapReduce 作业的其他方法，请参阅<bpt id=\"p1\">[</bpt>在 HDInsight 上的 Hadoop 中使用 MapReduce<ept id=\"p1\">](/documentation/articles/hdinsight-use-mapreduce)</ept>。"
    },
    {
      "pos": [
        6875,
        6954
      ],
      "content": "<bpt id=\"p1\">[</bpt>安装和配置 Azure PowerShell<ept id=\"p1\">](/documentation/articles/powershell-install-configure)</ept>。"
    },
    {
      "pos": [
        6959,
        7102
      ],
      "content": "下载 <bpt id=\"p1\">[</bpt>hdinsight-tools.psm1<ept id=\"p1\">](https://github.com/Blackmist/hdinsight-tools/blob/master/hdinsight-tools.psm1)</ept> 并将其保存到名为 <bpt id=\"p2\">**</bpt>hdinsight-tools.psm1<ept id=\"p2\">**</ept> 的文件。"
    },
    {
      "pos": [
        7107,
        7186
      ],
      "content": "打开一个新的 <bpt id=\"p1\">**</bpt>Azure PoweShell<ept id=\"p1\">**</ept> 会话并输入以下命令。如果 hdinsight-tools.psm1 不在当前目录中，请提供该文件的路径："
    },
    {
      "content": "这将会导入多个函数用于处理 HDInsight 中的文件。",
      "pos": [
        7236,
        7265
      ]
    },
    {
      "pos": [
        7270,
        7338
      ],
      "content": "使用以下命令上载包含 WordCount 作业的 jar 文件。将 <ph id=\"ph1\">`CLUSTERNAME`</ph> 替换为 HDInsight 群集的名称。"
    },
    {
      "content": "完成上载后，使用以下命令运行作业：",
      "pos": [
        7551,
        7568
      ]
    },
    {
      "content": "完成作业后，使用以下命令下载作业输出：",
      "pos": [
        8039,
        8058
      ]
    },
    {
      "content": "输出中包括制表符分隔的单词和计数值。使用以下命令以显示结果。",
      "pos": [
        8182,
        8212
      ]
    },
    {
      "content": "该文件应包含如下所示的值：",
      "pos": [
        8242,
        8255
      ]
    },
    {
      "content": "后续步骤",
      "pos": [
        8534,
        8538
      ]
    },
    {
      "content": "现在，你已学习如何使用 Scalding 来创建适用于 HDInsight 的 MapRedcue 作业，接下来请使用以下链接学习 Azure HDInsight 的其他用法。",
      "pos": [
        8540,
        8628
      ]
    },
    {
      "content": "将 Hive 与 HDInsight 配合使用",
      "pos": [
        8633,
        8656
      ]
    },
    {
      "content": "将 Pig 与 HDInsight 配合使用",
      "pos": [
        8706,
        8728
      ]
    },
    {
      "content": "将 MapReduce 作业与 HDInsight 配合使用",
      "pos": [
        8777,
        8807
      ]
    }
  ],
  "content": "<properties\n pageTitle=\"使用 Maven 开发 Scalding MapReduce 作业 | Azure\"\n description=\"了解如何使用 Maven 创建 Scalding MapReduce 作业，然后在 Hadoop on HDInsight 群集上部署并运行该作业。\"\n services=\"hdinsight\"\n documentationCenter=\"\"\n authors=\"Blackmist\"\n manager=\"paulettm\"\n editor=\"cgronlun\"\n    tags=\"azure-portal\"/>\n<tags\n    ms.service=\"hdinsight\"\n    ms.date=\"12/04/2015\"\n    wacn.date=\"01/14/2016\"/>\n\n# 使用 Apache Hadoop on HDInsight 开发 Scalding MapReduce 作业\n\nScalding 是一种 Scala 库，它可以让你轻松地创建 Hadoop MapReduce 作业。它提供简明的语法以及与 Scala 的紧密集成。\n\n在本文档中，你将学习如何使用 Maven 来创建以 Scalding 编写的单词计数 MapReduce 作业。然后，你将学习如何在 HDInsight 群集上部署并运行此作业。\n\n## 先决条件\n\n- **一个 Azure 订阅**。请参阅[获取 Azure 试用版](/pricing/1rmb-trial/)。\n* **HDInsight 群集上基于 Windows 的 Hadoop**。有关详细信息，请参阅[在 HDInsight 上预配基于 Windows 的 Hadoop](/documentation/articles/hdinsight-provision-clusters-v1)。\n\n* **[Maven](http://maven.apache.org/)**\n\n* **[Java 平台 JDK](http://www.oracle.com/technetwork/java/javase/downloads/index.html) 7 或更高版本**\n\n## 创建和生成项目\n\n1. 输入以下命令来创建新的 Maven 项目：\n\n        mvn archetype:generate -DgroupId=com.microsoft.example -DartifactId=scaldingwordcount -DarchetypeGroupId=org.scala-tools.archetypes -DarchetypeArtifactId=scala-archetype-simple -DinteractiveMode=false\n\n    此命令将创建一个名为 **scaldingwordcount** 的新目录，并创建 Scala 应用程序的基架。\n\n2. 在 **scaldingwordcount** 目录中，打开 **pom.xml** 文件并将其内容替换为以下内容：\n\n        <project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/maven-v4_0_0.xsd\">\n          <modelVersion>4.0.0</modelVersion>\n          <groupId>com.microsoft.example</groupId>\n          <artifactId>scaldingwordcount</artifactId>\n          <version>1.0-SNAPSHOT</version>\n          <name>${project.artifactId}</name>\n          <properties>\n            <maven.compiler.source>1.6</maven.compiler.source>\n            <maven.compiler.target>1.6</maven.compiler.target>\n            <encoding>UTF-8</encoding>\n          </properties>\n          <repositories>\n            <repository>\n              <id>conjars</id>\n              <url>http://conjars.org/repo</url>\n            </repository>\n            <repository>\n              <id>maven-central</id>\n              <url>http://repo1.maven.org/maven2</url>\n            </repository>\n          </repositories>\n          <dependencies>\n            <dependency>\n              <groupId>com.twitter</groupId>\n              <artifactId>scalding-core_2.11</artifactId>\n              <version>0.13.1</version>\n            </dependency>\n            <dependency>\n              <groupId>org.apache.hadoop</groupId>\n              <artifactId>hadoop-core</artifactId>\n              <version>1.2.1</version>\n              <scope>provided</scope>\n            </dependency>\n          </dependencies>\n          <build>\n            <sourceDirectory>src/main/scala</sourceDirectory>\n            <plugins>\n              <plugin>\n                <groupId>org.scala-tools</groupId>\n                <artifactId>maven-scala-plugin</artifactId>\n                <version>2.15.2</version>\n                <executions>\n                  <execution>\n                    <id>scala-compile-first</id>\n                    <phase>process-resources</phase>\n                    <goals>\n                      <goal>add-source</goal>\n                      <goal>compile</goal>\n                    </goals>\n                  </execution>\n                </executions>\n              </plugin>\n              <plugin>\n                <groupId>org.apache.maven.plugins</groupId>\n                <artifactId>maven-shade-plugin</artifactId>\n                <version>2.3</version>\n                <configuration>\n                  <transformers>\n                    <transformer implementation=\"org.apache.maven.plugins.shade.resource.ApacheLicenseResourceTransformer\">\n                    </transformer>\n                  </transformers>\n                  <filters>\n                    <filter>\n                      <artifact>*:*</artifact>\n                      <excludes>\n                        <exclude>META-INF/*.SF</exclude>\n                        <exclude>META-INF/*.DSA</exclude>\n                        <exclude>META-INF/*.RSA</exclude>\n                      </excludes>\n                    </filter>\n                  </filters>\n                </configuration>\n                <executions>\n                  <execution>\n                    <phase>package</phase>\n                    <goals>\n                      <goal>shade</goal>\n                    </goals>\n                    <configuration>\n                      <transformers>\n                        <transformer implementation=\"org.apache.maven.plugins.shade.resource.ManifestResourceTransformer\">\n                          <mainClass>com.twitter.scalding.Tool</mainClass>\n                        </transformer>\n                      </transformers>\n                    </configuration>\n                  </execution>\n                </executions>\n              </plugin>\n            </plugins>\n          </build>\n        </project>\n\n    此文件描述了项目、依赖关系和插件。以下是重要条目：\n\n    * **maven.compiler.source** 和 **maven.compiler.target**：设置此项目的 Java 版本\n\n    * **repositories**：包含此项目使用的依赖文件的存储库\n\n    * **scalding-core\\_2.11** 和 **hadoop-core**：此项目依赖于 Scalding 和 Hadoop 核心程序包\n\n    * **maven-scala-plugin**：用于编译 scala 应用程序的插件\n\n    * **maven-shade-plugin**：用于创建阴影 (fat) jar 的插件。此插件将应用筛选器和转换，具体包括：\n\n        * **筛选器**：应用的筛选器将修改 jar 文件中包含的元信息。为了防止运行时发生签名异常，它会排除依赖项中可能包含的各种签名文件。\n\n        * **执行**：程序包阶段执行配置将 **com.twitter.scalding.Tool** 类指定为程序包的主类。如果没有此项配置，则你在使用 hadoop 命令运行作业时，需要指定 com.twitter.scalding.Tool 以及包含应用程序逻辑的类。\n\n3. 删除 **src/test** 目录，因为你不需要使用此示例创建测试。\n\n4. 打开 **src/main/scala/com/microsoft/example/app.scala** 文件，并将其内容替换为以下内容：\n\n        package com.microsoft.example\n\n        import com.twitter.scalding._\n\n        class WordCount(args : Args) extends Job(args) {\n          // 1. Read lines from the specified input location\n          // 2. Extract individual words from each line\n          // 3. Group words and count them\n          // 4. Write output to the specified output location\n          TextLine(args(\"input\"))\n            .flatMap('line -> 'word) { line : String => tokenize(line) }\n            .groupBy('word) { _.size }\n            .write(Tsv(args(\"output\")))\n\n          //Tokenizer to split sentance into words\n          def tokenize(text : String) : Array[String] = {\n            text.toLowerCase.replaceAll(\"[^a-zA-Z0-9\\\\s]\", \"\").split(\"\\\\s+\")\n          }\n        }\n\n    这将会实现基本的单词计数作业。\n\n5. 保存并关闭文件。\n\n6. 使用以下命令从 **scaldingwordcount** 目录生成并打包应用程序：\n\n        mvn package\n\n    完成此作业后，可以在 **target/scaldingwordcount-1.0-SNAPSHOT.jar** 中找到包含 WordCount 应用程序的程序包。\n\n## 在基于 Windows 的群集上运行作业\n\n> [AZURE.NOTE]以下步骤使用 Windows PowerShell。有关运行 MapReduce 作业的其他方法，请参阅[在 HDInsight 上的 Hadoop 中使用 MapReduce](/documentation/articles/hdinsight-use-mapreduce)。\n\n1. [安装和配置 Azure PowerShell](/documentation/articles/powershell-install-configure)。\n\n2. 下载 [hdinsight-tools.psm1](https://github.com/Blackmist/hdinsight-tools/blob/master/hdinsight-tools.psm1) 并将其保存到名为 **hdinsight-tools.psm1** 的文件。\n\n3. 打开一个新的 **Azure PoweShell** 会话并输入以下命令。如果 hdinsight-tools.psm1 不在当前目录中，请提供该文件的路径：\n\n        import-module hdinsight-tools.psm1\n\n    这将会导入多个函数用于处理 HDInsight 中的文件。\n\n4. 使用以下命令上载包含 WordCount 作业的 jar 文件。将 `CLUSTERNAME` 替换为 HDInsight 群集的名称。\n\n        $clusterName=\"CLUSTERNAME\"\n        Add-HDInsightFile -clusterName $clusterName -localPath \\path\\to\\scaldingwordcount-1.0-SNAPSHOT.jar -destinationPath example/jars/scaldingwordcount-1.0-SNAPSHOT.jar\n\n5. 完成上载后，使用以下命令运行作业：\n\n        $jobDef=New-AzureHDInsightMapReduceJobDefinition -JobName ScaldingWordCount -JarFile wasb:///example/jars/scaldingwordcount-1.0-SNAPSHOT.jar -ClassName com.microsoft.example.WordCount -arguments \"--hdfs\", \"--input\", \"wasb:///example/data/gutenberg/davinci.txt\", \"--output\", \"wasb:///example/wordcountout\"\n        $job = start-azurehdinsightjob -cluster $clusterName -jobdefinition $jobDef\n        wait-azurehdinsightjob -Job $job -waittimeoutinseconds 3600\n\n6. 完成作业后，使用以下命令下载作业输出：\n\n        Get-HDInsightFile -clusterName $clusterName -remotePath example/wordcountout/part-00000 -localPath output.txt\n\n7. 输出中包括制表符分隔的单词和计数值。使用以下命令以显示结果。\n\n        cat output.txt\n\n    该文件应包含如下所示的值：\n\n        writers 9\n        writes  18\n        writhed 1\n        writing 51\n        writings        24\n        written 208\n        writtenthese    1\n        wrong   11\n        wrongly 2\n        wrongplace      1\n        wrote   34\n        wrotefootnote   1\n        wrought 7\n\n## 后续步骤\n\n现在，你已学习如何使用 Scalding 来创建适用于 HDInsight 的 MapRedcue 作业，接下来请使用以下链接学习 Azure HDInsight 的其他用法。\n\n* [将 Hive 与 HDInsight 配合使用](/documentation/articles/hdinsight-use-hive)\n\n* [将 Pig 与 HDInsight 配合使用](/documentation/articles/hdinsight-use-pig)\n\n* [将 MapReduce 作业与 HDInsight 配合使用](/documentation/articles/hdinsight-use-mapreduce)\n\n<!---HONumber=Mooncake_0104_2016-->"
}