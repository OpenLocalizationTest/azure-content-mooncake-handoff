{
  "nodes": [
    {
      "content": "在 HDInsight 中使用基于时间的 Hadoop Oozie 协调器 | Azure",
      "pos": [
        28,
        73
      ]
    },
    {
      "content": "在 HDInsight 中使用基于时间的 Hadoop Oozie 协调器（大数据服务）。了解如何定义 Oozie 工作流和协调器，并提交作业。",
      "pos": [
        93,
        165
      ]
    },
    {
      "content": "将基于时间的 Oozie 协调器与 HDInsight 中的 Hadoop 配合使用以定义工作流和协调作业",
      "pos": [
        409,
        462
      ]
    },
    {
      "pos": [
        464,
        637
      ],
      "content": "在本文中，你将学习如何定义工作流和协调器，以及如何基于时间触发协调器作业。在阅读本文之前，先浏览<bpt id=\"p1\">[</bpt>将 Oozie 与 HDInsight 配合使用<ept id=\"p1\">][hdinsight-use-oozie]</ept>一文会很有用。若要了解 Azure 数据工厂，请参阅 [将 Pig 和 Hive 用于数据工厂][azure-data-factory-pig-hive]。"
    },
    {
      "pos": [
        641,
        674
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"whatisoozie\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>什么是 Oozie"
    },
    {
      "content": "Apache Oozie 是一个管理 Hadoop 作业的工作流/协调系统。它与 Hadoop 堆栈集成，支持 Apache MapReduce、Apache Pig、Apache Hive 和 Apache Sqoop 的 Hadoop 作业。它也能用于安排特定于某系统的作业，例如 Java 程序或 shell 脚本。",
      "pos": [
        676,
        837
      ]
    },
    {
      "content": "下图显示将要实施的工作流：",
      "pos": [
        839,
        852
      ]
    },
    {
      "content": "工作流关系图",
      "pos": [
        856,
        862
      ]
    },
    {
      "content": "工作流包含两个操作：",
      "pos": [
        887,
        897
      ]
    },
    {
      "content": "Hive 操作运行 HiveQL 脚本以统计 log4j 日志文件中每个日志级类型的次数。每个 log4j 日志都包含一行字段，其中包含 [LOG LEVEL] 字段，可显示类型和严重性，例如：",
      "pos": [
        902,
        999
      ]
    },
    {
      "content": "该 Hive 脚本的输出结果类似于：",
      "pos": [
        1256,
        1274
      ]
    },
    {
      "pos": [
        1398,
        1461
      ],
      "content": "有关 Hive 的详细信息，请参阅<bpt id=\"p1\">[</bpt>将 Hive 与 HDInsight 配合使用<ept id=\"p1\">][hdinsight-use-hive]</ept>。"
    },
    {
      "pos": [
        1471,
        1581
      ],
      "content": "Sqoop 操作将 HiveQL 操作输出结果导出到 Azure SQL 数据库中的表。有关 Sqoop 的详细信息，请参阅<bpt id=\"p1\">[</bpt>将 Sqoop 与 HDInsight 配合使用<ept id=\"p1\">][hdinsight-use-sqoop]</ept>。"
    },
    {
      "pos": [
        1585,
        1677
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>有关 HDInsight 群集上支持的 Oozie 版本，请参阅 <bpt id=\"p1\">[</bpt>HDInsight 提供的群集版本有哪些新功能？<ept id=\"p1\">][hdinsight-versions]</ept>。"
    },
    {
      "pos": [
        1681,
        1755
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>本教程适用于 HDInsight 群集版本 2.1 和 3.0。本文尚未在 HDInsight Emulator 上测试过。"
    },
    {
      "pos": [
        1760,
        1790
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"prerequisites\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>先决条件"
    },
    {
      "content": "在开始阅读本教程前，你必须具有：",
      "pos": [
        1792,
        1808
      ]
    },
    {
      "pos": [
        1812,
        2034
      ],
      "content": "<bpt id=\"p1\">**</bpt>配备 Azure PowerShell 的工作站<ept id=\"p1\">**</ept>。请参阅<bpt id=\"p2\">[</bpt>安装和使用 Azure PowerShell<ept id=\"p2\">][powershell-install-configure]</ept>。若要执行 Windows PowerShell 脚本，必须以管理员身份运行 Azure PowerShell 并将执行策略设为 <bpt id=\"p3\">*</bpt>RemoteSigned<ept id=\"p3\">*</ept>。有关详细信息，请参阅<bpt id=\"p4\">[</bpt>运行 Windows PowerShell 脚本<ept id=\"p4\">][powershell-script]</ept>。"
    },
    {
      "pos": [
        2037,
        2175
      ],
      "content": "<bpt id=\"p1\">**</bpt>一个 HDInsight 群集<ept id=\"p1\">**</ept>。有关创建 HDInsight 群集的信息，请参阅<bpt id=\"p2\">[</bpt>预配 HDInsight 群集<ept id=\"p2\">][hdinsight-provision]</ept>或 <bpt id=\"p3\">[</bpt>HDInsight 入门<ept id=\"p3\">][hdinsight-get-started]</ept>。你将需要以下数据才能完成本教程："
    },
    {
      "pos": [
        2181,
        2880
      ],
      "content": "<table border = \"1\">\n  <tr><th>群集属性</th><th>Windows PowerShell 变量名</th><th>值</th><th>说明</th></tr>\n  <tr><td>HDInsight 群集名称</td><td>$clusterName</td><td></td><td>要在其中运行本教程的 HDInsight 群集。</td></tr>\n  <tr><td>HDInsight 群集用户名</td><td>$clusterUsername</td><td></td><td>HDInsight 群集用户名。</td></tr>\n  <tr><td>HDInsight 群集用户的密码 </td><td>$clusterPassword</td><td></td><td>HDInsight 群集用户的密码。</td></tr>\n  <tr><td>Azure 存储帐户名称</td><td>$storageAccountName</td><td></td><td>可用于 HDInsight 群集的 Azure 存储帐户。在本教程中，使用在群集设置过程中指定的默认存储帐户。</td></tr>\n  <tr><td>Azure Blob 容器名称</td><td>$containerName</td><td></td><td>在此示例中，使用用于默认 HDInsight 群集文件系统的 Azure Blob 存储容器。默认情况下，该容器与 HDInsight 群集同名。</td></tr>\n  </table>",
      "leadings": [
        "",
        "  ",
        "  ",
        "  ",
        "  ",
        "  ",
        "  ",
        "  "
      ],
      "nodes": [
        {
          "content": "群集属性",
          "pos": [
            31,
            35
          ]
        },
        {
          "content": "Windows PowerShell 变量名",
          "pos": [
            44,
            66
          ]
        },
        {
          "content": "值",
          "pos": [
            75,
            76
          ]
        },
        {
          "content": "说明",
          "pos": [
            85,
            87
          ]
        },
        {
          "content": "HDInsight 群集名称",
          "pos": [
            108,
            122
          ]
        },
        {
          "content": "$clusterName",
          "pos": [
            131,
            143
          ]
        },
        {
          "content": "要在其中运行本教程的 HDInsight 群集。",
          "pos": [
            161,
            185
          ]
        },
        {
          "content": "HDInsight 群集用户名",
          "pos": [
            206,
            221
          ]
        },
        {
          "content": "$clusterUsername",
          "pos": [
            230,
            246
          ]
        },
        {
          "content": "HDInsight 群集用户名。",
          "pos": [
            264,
            280
          ]
        },
        {
          "content": "HDInsight 群集用户的密码",
          "pos": [
            301,
            318
          ]
        },
        {
          "content": "$clusterPassword",
          "pos": [
            328,
            344
          ]
        },
        {
          "content": "HDInsight 群集用户的密码。",
          "pos": [
            362,
            380
          ]
        },
        {
          "content": "Azure 存储帐户名称",
          "pos": [
            401,
            413
          ]
        },
        {
          "content": "$storageAccountName",
          "pos": [
            422,
            441
          ]
        },
        {
          "content": "可用于 HDInsight 群集的 Azure 存储帐户。在本教程中，使用在群集设置过程中指定的默认存储帐户。",
          "pos": [
            459,
            514
          ]
        },
        {
          "content": "Azure Blob 容器名称",
          "pos": [
            535,
            550
          ]
        },
        {
          "content": "$containerName",
          "pos": [
            559,
            573
          ]
        },
        {
          "content": "在此示例中，使用用于默认 HDInsight 群集文件系统的 Azure Blob 存储容器。默认情况下，该容器与 HDInsight 群集同名。",
          "pos": [
            591,
            664
          ]
        }
      ]
    },
    {
      "pos": [
        2884,
        3067
      ],
      "content": "<bpt id=\"p1\">**</bpt>Azure SQL 数据库<ept id=\"p1\">**</ept>。你必须为 SQL 数据库服务器配置防火墙规则以允许从你的工作站进行访问。有关创建 Azure SQL 数据库和配置防火墙的说明，请参阅 <bpt id=\"p2\">[</bpt>Azure SQL 数据库入门<ept id=\"p2\">][sqldatabase-get-started]</ept>。本文提供了用于创建本教程所需的 Azure SQL 数据库表的 Windows PowerShell 脚本。"
    },
    {
      "pos": [
        3073,
        3589
      ],
      "content": "<table border = \"1\">\n  <tr><th>SQL 数据库属性</th><th>Windows PowerShell 变量名</th><th>值</th><th>说明</th></tr>\n  <tr><td>SQL 数据库服务器名称</td><td>$sqlDatabaseServer</td><td></td><td>Sqoop 要将数据导出到其中的 SQL 数据库服务器。</td></tr>\n  <tr><td>SQL 数据库登录名</td><td>$sqlDatabaseLogin</td><td></td><td>SQL 数据库登录名。</td></tr>\n  <tr><td>SQL 数据库登录密码</td><td>$sqlDatabaseLoginPassword</td><td></td><td>SQL 数据库登录密码。</td></tr>\n  <tr><td>SQL 数据库名</td><td>$sqlDatabaseName</td><td></td><td>Sqoop 要将数据导出到其中的 Azure SQL 数据库。</td></tr>\n  </table>",
      "leadings": [
        "",
        "  ",
        "  ",
        "  ",
        "  ",
        "  ",
        "  "
      ],
      "nodes": [
        {
          "content": "SQL 数据库属性",
          "pos": [
            31,
            40
          ]
        },
        {
          "content": "Windows PowerShell 变量名",
          "pos": [
            49,
            71
          ]
        },
        {
          "content": "值",
          "pos": [
            80,
            81
          ]
        },
        {
          "content": "说明",
          "pos": [
            90,
            92
          ]
        },
        {
          "content": "SQL 数据库服务器名称",
          "pos": [
            113,
            125
          ]
        },
        {
          "content": "$sqlDatabaseServer",
          "pos": [
            134,
            152
          ]
        },
        {
          "content": "Sqoop 要将数据导出到其中的 SQL 数据库服务器。",
          "pos": [
            170,
            198
          ]
        },
        {
          "content": "SQL 数据库登录名",
          "pos": [
            219,
            229
          ]
        },
        {
          "content": "$sqlDatabaseLogin",
          "pos": [
            238,
            255
          ]
        },
        {
          "content": "SQL 数据库登录名。",
          "pos": [
            273,
            284
          ]
        },
        {
          "content": "SQL 数据库登录密码",
          "pos": [
            305,
            316
          ]
        },
        {
          "content": "$sqlDatabaseLoginPassword",
          "pos": [
            325,
            350
          ]
        },
        {
          "content": "SQL 数据库登录密码。",
          "pos": [
            368,
            380
          ]
        },
        {
          "content": "SQL 数据库名",
          "pos": [
            401,
            409
          ]
        },
        {
          "content": "$sqlDatabaseName",
          "pos": [
            418,
            434
          ]
        },
        {
          "content": "Sqoop 要将数据导出到其中的 Azure SQL 数据库。",
          "pos": [
            452,
            483
          ]
        }
      ]
    },
    {
      "pos": [
        3597,
        3767
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>默认情况下，可以从 Azure HDInsight 这样的 Azure 服务连接 Azure SQL 数据库。如果禁用了此防火墙设置，则必须从 Azure 门户启用它。有关创建 SQL 数据库和配置防火墙规则的说明，请参阅 [创建和配置 SQL 数据库][sqldatabase-create-configure]。"
    },
    {
      "pos": [
        3772,
        3803
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>将值填充到表中。这将有助于学习本教程。"
    },
    {
      "pos": [
        3808,
        3860
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"defineworkflow\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>定义 Oozie 工作流及相关 HiveQL 脚本"
    },
    {
      "pos": [
        3862,
        3986
      ],
      "content": "Oozie 工作流定义是用 hPDL（一种 XML 过程定义语言）编写的。默认的工作流文件名为 <bpt id=\"p1\">*</bpt>workflow.xml<ept id=\"p1\">*</ept>。你将在本地保存该工作流文件，并将在本教程后面使用 Azure PowerShell 将它部署到 HDInsight 群集。"
    },
    {
      "content": "该工作流中的 Hive 操作调用 HiveQL 脚本文件。此脚本文件包含三个 HiveQL 语句：",
      "pos": [
        3988,
        4037
      ]
    },
    {
      "pos": [
        4042,
        4081
      ],
      "content": "<bpt id=\"p1\">**</bpt>DROP TABLE 语句<ept id=\"p1\">**</ept>删除 log4j Hive 表（如果存在）。"
    },
    {
      "pos": [
        4085,
        4143
      ],
      "content": "<bpt id=\"p1\">**</bpt>CREATE TABLE 语句<ept id=\"p1\">**</ept>创建一个 log4j Hive 外部表，该表指向 log4j 日志文件的位置；"
    },
    {
      "pos": [
        4148,
        4234
      ],
      "content": "<bpt id=\"p1\">**</bpt>log4j 日志文件的位置<ept id=\"p1\">**</ept>。字段分隔符为“,”。默认分行符为“\\\\n”。Hive 外部表用于在你想多次运行 Oozie 工作流的情况下避免数据文件从原始位置被删除。"
    },
    {
      "pos": [
        4238,
        4314
      ],
      "content": "<bpt id=\"p1\">**</bpt>INSERT OVERWRITE 语句<ept id=\"p1\">**</ept>从 log4j Hive 表统计每个日志级类型的次数，并将输出结果保存到 Azure Blob 存储位置。"
    },
    {
      "pos": [
        4317,
        4445
      ],
      "content": "<bpt id=\"p1\">**</bpt>注意<ept id=\"p1\">**</ept>：有一个已知的 Hive 路径问题。你在提交 Oozie 作业时将会遇到这个问题。可在 TechNet Wiki 上找到用于解决此问题的说明：<bpt id=\"p2\">[</bpt>HDInsight Hive 错误: 无法重命名<ept id=\"p2\">][technetwiki-hive-error]</ept>。"
    },
    {
      "content": "将 HiveQL 脚本文件定义为由工作流调用",
      "pos": [
        4449,
        4471
      ]
    },
    {
      "content": "创建一个内容如下的文本文件：",
      "pos": [
        4478,
        4492
      ]
    },
    {
      "content": "该脚本中使用了三个变量：",
      "pos": [
        4900,
        4912
      ]
    },
    {
      "content": "${hiveTableName}",
      "pos": [
        4920,
        4936
      ]
    },
    {
      "content": "${hiveDataFolder}",
      "pos": [
        4943,
        4960
      ]
    },
    {
      "content": "${hiveOutputFolder}",
      "pos": [
        4967,
        4986
      ]
    },
    {
      "content": "工作流定义文件（本教程中的 workflow.xml）在运行时会将三个值传递到这个 HiveQL 脚本。",
      "pos": [
        5004,
        5056
      ]
    },
    {
      "pos": [
        5069,
        5196
      ],
      "content": "使用 ANSI (ASCII) 编码将文件另存为 <bpt id=\"p1\">**</bpt>C:\\\\Tutorials\\\\UseOozie\\\\useooziewf.hql<ept id=\"p1\">**</ept>。（如果你的文本编辑器不提供此选项，则使用记事本。） 在本教程的后面，此脚本文件将被部署到 HDInsight 群集。"
    },
    {
      "content": "定义工作流",
      "pos": [
        5202,
        5207
      ]
    },
    {
      "content": "创建一个内容如下的文本文件：",
      "pos": [
        5214,
        5228
      ]
    },
    {
      "pos": [
        7502,
        7581
      ],
      "content": "该工作流中定义了两个操作。start-to 操作是 <bpt id=\"p1\">*</bpt>RunHiveScript<ept id=\"p1\">*</ept>。如果该操作运行<bpt id=\"p2\">*</bpt>正常<ept id=\"p2\">*</ept>，则下一个操作是 <bpt id=\"p3\">*</bpt>RunSqoopExport<ept id=\"p3\">*</ept>。"
    },
    {
      "content": "RunHiveScript 有几个变量。在从工作站使用 Azure PowerShell 提交 Oozie 作业时，将会传递值。",
      "pos": [
        7587,
        7651
      ]
    },
    {
      "pos": [
        7657,
        8770
      ],
      "content": "<table border = \"1\">\n <tr><th>工作流变量</th><th>说明</th></tr>\n <tr><td>${jobTracker}</td><td>指定 Hadoop 作业跟踪器的 URL。在 HDInsight 群集版本 2.0 和 3.0 上使用 <strong>jobtrackerhost:9010</strong>。</td></tr>\n <tr><td>${nameNode}</td><td>指定 Hadoop 名称节点的 URL。使用默认文件系统 wasb:// 地址，例如 <i>wasb://&lt;containerName>@&lt;storageAccountName>.blob.core.chinacloudapi.cn</i>。</td></tr>\n <tr><td>${queueName}</td><td>指定要将作业提交到的 queuename。使用“默认”。<strong></strong></td></tr>\n </table><table border = \"1\">\n <tr><th>Hive 操作变量</th><th>说明</th></tr>\n <tr><td>${hiveDataFolder}</td><td>Hive Create Table 命令的源目录。</td></tr>\n <tr><td>${hiveOutputFolder}</td><td>INSERT OVERWRITE 语句的输出文件夹。</td></tr>\n <tr><td>${hiveTableName}</td><td>引用 log4j 数据文件的 Hive 表的名称。</td></tr>\n </table><table border = \"1\">\n <tr><th>Sqoop 操作变量</th><th>说明</th></tr>\n <tr><td>${sqlDatabaseConnectionString}</td><td>SQL 数据库连接字符串。</td></tr>\n <tr><td>${sqlDatabaseTableName}</td><td>数据将要导出到的 Azure SQL 数据库表。</td></tr>\n <tr><td>${hiveOutputFolder}</td><td>Hive INSERT OVERWRITE 语句的输出文件夹。这是用于 Sqoop 导出 (export-dir) 的同一个文件夹。</td></tr>\n </table>",
      "leadings": [
        "",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   ",
        "   "
      ],
      "nodes": [
        {
          "content": "工作流变量",
          "pos": [
            30,
            35
          ]
        },
        {
          "content": "说明",
          "pos": [
            44,
            46
          ]
        },
        {
          "content": "${jobTracker}",
          "pos": [
            66,
            79
          ]
        },
        {
          "content": "指定 Hadoop 作业跟踪器的 URL。在 HDInsight 群集版本 2.0 和 3.0 上使用 <ph id=\"ph1\">&lt;strong&gt;</ph>jobtrackerhost:9010<ph id=\"ph2\">&lt;/strong&gt;</ph>。",
          "pos": [
            88,
            177
          ]
        },
        {
          "content": "${nameNode}",
          "pos": [
            197,
            208
          ]
        },
        {
          "content": "指定 Hadoop 名称节点的 URL。使用默认文件系统 wasb:// 地址，例如 <ph id=\"ph1\">&lt;i&gt;</ph>wasb://&amp;lt;containerName&gt;@&amp;lt;storageAccountName&gt;.blob.core.chinacloudapi.cn<ph id=\"ph2\">&lt;/i&gt;</ph>。",
          "pos": [
            217,
            344
          ]
        },
        {
          "content": "${queueName}",
          "pos": [
            364,
            376
          ]
        },
        {
          "content": "指定要将作业提交到的 queuename。使用“默认”。<ph id=\"ph1\">&lt;strong&gt;</ph><ph id=\"ph2\">&lt;/strong&gt;</ph>",
          "pos": [
            385,
            430
          ]
        },
        {
          "content": "Hive 操作变量",
          "pos": [
            480,
            489
          ]
        },
        {
          "content": "说明",
          "pos": [
            498,
            500
          ]
        },
        {
          "content": "${hiveDataFolder}",
          "pos": [
            520,
            537
          ]
        },
        {
          "content": "Hive Create Table 命令的源目录。",
          "pos": [
            546,
            571
          ]
        },
        {
          "content": "${hiveOutputFolder}",
          "pos": [
            591,
            610
          ]
        },
        {
          "content": "INSERT OVERWRITE 语句的输出文件夹。",
          "pos": [
            619,
            645
          ]
        },
        {
          "content": "${hiveTableName}",
          "pos": [
            665,
            681
          ]
        },
        {
          "content": "引用 log4j 数据文件的 Hive 表的名称。",
          "pos": [
            690,
            715
          ]
        },
        {
          "content": "Sqoop 操作变量",
          "pos": [
            765,
            775
          ]
        },
        {
          "content": "说明",
          "pos": [
            784,
            786
          ]
        },
        {
          "content": "${sqlDatabaseConnectionString}",
          "pos": [
            806,
            836
          ]
        },
        {
          "content": "SQL 数据库连接字符串。",
          "pos": [
            845,
            858
          ]
        },
        {
          "content": "${sqlDatabaseTableName}",
          "pos": [
            878,
            901
          ]
        },
        {
          "content": "数据将要导出到的 Azure SQL 数据库表。",
          "pos": [
            910,
            934
          ]
        },
        {
          "content": "${hiveOutputFolder}",
          "pos": [
            954,
            973
          ]
        },
        {
          "content": "Hive INSERT OVERWRITE 语句的输出文件夹。这是用于 Sqoop 导出 (export-dir) 的同一个文件夹。",
          "pos": [
            982,
            1048
          ]
        }
      ]
    },
    {
      "pos": [
        8776,
        8936
      ],
      "content": "有关 Oozie 工作流以及使用工作流操作的详细信息，请参阅 <bpt id=\"p1\">[</bpt>Apache Oozie 4.0 文档<ept id=\"p1\">][apache-oozie-400]</ept>（用于 HDInsight 群集版本 3.0）或 <bpt id=\"p2\">[</bpt>Apache Oozie 3.3.2 文档<ept id=\"p2\">][apache-oozie-332]</ept>（用于 HDInsight 群集版本 2.1）。"
    },
    {
      "pos": [
        8941,
        9033
      ],
      "content": "使用 ANSI (ASCII) 编码将文件另存为 <bpt id=\"p1\">**</bpt>C:\\\\Tutorials\\\\UseOozie\\\\workflow.xml<ept id=\"p1\">**</ept>。（如果你的文本编辑器不提供此选项，则使用记事本。）"
    },
    {
      "content": "定义协调器",
      "pos": [
        9037,
        9042
      ]
    },
    {
      "content": "创建一个内容如下的文本文件：",
      "pos": [
        9049,
        9063
      ]
    },
    {
      "content": "该定义文件中使用了五个变量：",
      "pos": [
        9415,
        9429
      ]
    },
    {
      "content": "变量",
      "pos": [
        9437,
        9439
      ]
    },
    {
      "content": "说明",
      "pos": [
        9442,
        9444
      ]
    },
    {
      "content": "${coordFrequency}",
      "pos": [
        9493,
        9510
      ]
    },
    {
      "content": "作业暂停时间。频率总是用分钟来表示的。",
      "pos": [
        9513,
        9532
      ]
    },
    {
      "content": "${coordStart}",
      "pos": [
        9541,
        9554
      ]
    },
    {
      "content": "作业开始时间。",
      "pos": [
        9557,
        9564
      ]
    },
    {
      "content": "${coordEnd}",
      "pos": [
        9573,
        9584
      ]
    },
    {
      "content": "作业结束时间。",
      "pos": [
        9587,
        9594
      ]
    },
    {
      "content": "${coordTimezone}",
      "pos": [
        9603,
        9619
      ]
    },
    {
      "content": "Oozie 在没有夏时制的固定时区（通常用 UTC 表示）处理协调器作业。此时区被称为“Oozie 处理时区”。",
      "pos": [
        9622,
        9678
      ]
    },
    {
      "content": "${wfPath}",
      "pos": [
        9687,
        9696
      ]
    },
    {
      "content": "workflow.xml 的路径。如果该工作流文件名不是默认文件名 (workflow.xml)，则必须指定该名称。",
      "pos": [
        9699,
        9757
      ]
    },
    {
      "pos": [
        9768,
        9863
      ],
      "content": "使用 ANSI (ASCII) 编码将文件另存为 <bpt id=\"p1\">**</bpt>C:\\\\Tutorials\\\\UseOozie\\\\coordinator.xml<ept id=\"p1\">**</ept>。（如果你的文本编辑器不提供此选项，则使用记事本。）"
    },
    {
      "pos": [
        9871,
        9906
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"deploy\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>部署 Oozie 项目并准备教程"
    },
    {
      "content": "你将运行 Azure PowerShell 脚本来执行以下操作：",
      "pos": [
        9908,
        9940
      ]
    },
    {
      "content": "将 HiveQL 脚本 (useoozie.hql) 复制到 Azure Blob 存储 wasb:///tutorials/useoozie/useoozie.hql。",
      "pos": [
        9944,
        10029
      ]
    },
    {
      "content": "将 workflow.xml 复制到 wasb:///tutorials/useoozie/workflow.xml。",
      "pos": [
        10032,
        10091
      ]
    },
    {
      "content": "将 coordinator.xml 复制到 wasb:///tutorials/useoozie/coordinator.xml。",
      "pos": [
        10094,
        10159
      ]
    },
    {
      "content": "将数据文件 (/example/data/sample.log) 复制到 wasb:///tutorials/useoozie/data/sample.log。",
      "pos": [
        10162,
        10242
      ]
    },
    {
      "pos": [
        10246,
        10302
      ],
      "content": "创建用于存储 Sqoop 导出数据的 Azure SQL 数据库表。表的名称为 <bpt id=\"p1\">*</bpt>log4jLogCount<ept id=\"p1\">*</ept>。"
    },
    {
      "content": "了解 HDInsight 存储",
      "pos": [
        10306,
        10321
      ]
    },
    {
      "pos": [
        10325,
        10484
      ],
      "content": "HDInsight 将 Azure Blob 存储用于数据存储。wasb:// 是 Microsoft 在 Azure Blob 存储中对 Hadoop 分布式文件系统 (HDFS) 的实施。有关详细信息，请参阅<bpt id=\"p1\">[</bpt>将 Azure Blob 存储与 HDInsight 配合使用<ept id=\"p1\">][hdinsight-storage]</ept>。"
    },
    {
      "pos": [
        10486,
        10769
      ],
      "content": "设置 HDInsight 群集时，请将 Azure Blob 存储帐户和该帐户上的特定容器指定为默认文件系统，就像在 HDFS 中一样。除了此存储帐户外，在设置过程中，你还可以从同一 Azure 订阅或不同 Azure 订阅添加其他存储帐户。有关添加其他存储帐户的说明，请参阅<bpt id=\"p1\">[</bpt>设置 HDInsight 群集<ept id=\"p1\">][hdinsight-provision]</ept>。为了简化本教程中使用的 Azure PowerShell 脚本，所有文件都存储在默认文件系统容器（位于 <bpt id=\"p2\">*</bpt>/tutorials/useoozie<ept id=\"p2\">*</ept>）中。默认情况下，此容器与 HDInsight 群集同名。语法为："
    },
    {
      "pos": [
        10870,
        10986
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>HDInsight 群集 3.0 版只支持 <bpt id=\"p1\">*</bpt>wasb://<ept id=\"p1\">*</ept> 语法。较早的 <bpt id=\"p2\">*</bpt>asv://<ept id=\"p2\">*</ept> 语法在 HDInsight 2.1 和 1.6 群集中受支持，但在 HDInsight 3.0 群集中不受支持。"
    },
    {
      "pos": [
        10990,
        11081
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>wasb:// 路径是虚拟路径。有关详细信息，请参阅<bpt id=\"p1\">[</bpt>将 Azure Blob 存储与 HDInsight 配合使用<ept id=\"p1\">][hdinsight-storage]</ept>。"
    },
    {
      "content": "存储在默认文件系统容器中的文件可以使用以下任一 URI 从 HDInsight 进行访问（以 workflow.xml 为例）：",
      "pos": [
        11083,
        11147
      ]
    },
    {
      "content": "如果要从存储帐户直接访问该文件，则请注意，该文件的 Blob 名称是：",
      "pos": [
        11330,
        11365
      ]
    },
    {
      "content": "了解 Hive 内部表和外部表",
      "pos": [
        11406,
        11421
      ]
    },
    {
      "content": "以下是你需要了解的有关 Hive 内部表和外部表的一些信息：",
      "pos": [
        11425,
        11455
      ]
    },
    {
      "content": "CREATE TABLE 命令创建内部表，也称为托管表。数据文件必须位于默认容器中。",
      "pos": [
        11459,
        11501
      ]
    },
    {
      "content": "CREATE TABLE 命令将数据文件移动到默认容器中的 /hive/warehouse/",
      "pos": [
        11504,
        11550
      ]
    },
    {
      "content": "文件夹。",
      "pos": [
        11562,
        11566
      ]
    },
    {
      "content": "CREATE EXTERNAL TABLE 命令创建外部表。数据文件可以位于默认容器以外的位置。",
      "pos": [
        11569,
        11617
      ]
    },
    {
      "content": "CREATE EXTERNAL TABLE 命令不移动数据文件。",
      "pos": [
        11620,
        11652
      ]
    },
    {
      "content": "CREATE EXTERNAL TABLE 命令不允许 LOCATION 子句中指定的文件夹下有任何子文件夹。这是本教程生成 sample.log 文件的副本的原因。",
      "pos": [
        11655,
        11738
      ]
    },
    {
      "pos": [
        11740,
        11801
      ],
      "content": "有关详细信息，请参阅 <bpt id=\"p1\">[</bpt>HDInsight：Hive 内部和外部表简介<ept id=\"p1\">][cindygross-hive-tables]</ept>。"
    },
    {
      "content": "准备教程",
      "pos": [
        11805,
        11809
      ]
    },
    {
      "pos": [
        11816,
        11987
      ],
      "content": "打开 Windows PowerShell ISE（在 Windows 8“开始”屏幕上，键入 <bpt id=\"p1\">**</bpt>PowerShell_ISE<ept id=\"p1\">**</ept>，然后单击“Windows PowerShell ISE”。有关详细信息，请参阅<bpt id=\"p2\">[</bpt>在 Windows 8 和 Windows 上启动 Windows PowerShell<ept id=\"p2\">][powershell-start]</ept>。"
    },
    {
      "content": "在底部窗格中，运行以下命令以连接到 Azure 订阅：",
      "pos": [
        11991,
        12018
      ]
    },
    {
      "content": "系统将提示你输入 Azure 帐户凭据。这种添加订阅连接的方法会超时，12 个小时之后，你将需要再次运行该 cmdlet。",
      "pos": [
        12079,
        12140
      ]
    },
    {
      "pos": [
        12148,
        12249
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>如果你有多个 Azure 订阅，而默认订阅不是你想使用的，则请使用 <ph id=\"ph2\">&lt;strong&gt;</ph>Select-AzureSubscription<ph id=\"ph3\">&lt;/strong&gt;</ph> cmdlet 来选择订阅。"
    },
    {
      "content": "将以下脚本复制到脚本窗格，然后设置前六个变量：",
      "pos": [
        12254,
        12277
      ]
    },
    {
      "pos": [
        13136,
        13181
      ],
      "content": "有关这些变量的详细说明，请参阅本教程中的<bpt id=\"p1\">[</bpt>先决条件<ept id=\"p1\">](#prerequisites)</ept>部分。"
    },
    {
      "content": "在脚本窗格中将以下内容追加到脚本：",
      "pos": [
        13186,
        13203
      ]
    },
    {
      "pos": [
        16010,
        16046
      ],
      "content": "单击“运行脚本”或按 <bpt id=\"p1\">**</bpt>F5<ept id=\"p1\">**</ept> 键以运行该脚本。输出结果将会类似于："
    },
    {
      "content": "教程准备的输出结果",
      "pos": [
        16054,
        16063
      ]
    },
    {
      "pos": [
        16092,
        16119
      ],
      "content": "<ph id=\"ph1\">&lt;a id=\"run\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>运行 Oozie 项目"
    },
    {
      "pos": [
        16121,
        16416
      ],
      "content": "Azure PowerShell 目前不提供任何用于定义 Oozie 作业的 cmdlet。你可以使用 <bpt id=\"p1\">**</bpt>Invoke-RestMethod<ept id=\"p1\">**</ept> cmdlet 来调用 Oozie Web 服务。Oozie Web 服务 API 是 HTTP REST JSON API。有关 Oozie Web 服务 API 的详细信息，请参阅 <bpt id=\"p2\">[</bpt>Apache Oozie 4.0 文档<ept id=\"p2\">][apache-oozie-400]</ept>（用于 HDInsight 群集版本 3.0）或 <bpt id=\"p3\">[</bpt>Apache Oozie 3.3.2 文档<ept id=\"p3\">][apache-oozie-332]</ept>（用于 HDInsight 群集版本 2.1）。"
    },
    {
      "content": "提交 Oozie 作业",
      "pos": [
        16420,
        16431
      ]
    },
    {
      "pos": [
        16438,
        16609
      ],
      "content": "打开 Windows PowerShell ISE（在 Windows 8“开始”屏幕上，键入 <bpt id=\"p1\">**</bpt>PowerShell_ISE<ept id=\"p1\">**</ept>，然后单击“Windows PowerShell ISE”。有关详细信息，请参阅<bpt id=\"p2\">[</bpt>在 Windows 8 和 Windows 上启动 Windows PowerShell<ept id=\"p2\">][powershell-start]</ept>。"
    },
    {
      "pos": [
        16614,
        16664
      ],
      "content": "将以下脚本复制到脚本窗格，然后设置前 14 个变量（不过，请跳过 <bpt id=\"p1\">**</bpt>$storageUri<ept id=\"p1\">**</ept>）。"
    },
    {
      "pos": [
        18568,
        18613
      ],
      "content": "有关这些变量的详细说明，请参阅本教程中的<bpt id=\"p1\">[</bpt>先决条件<ept id=\"p1\">](#prerequisites)</ept>部分。"
    },
    {
      "content": "$coordstart 和 $coordend 是工作流的开始和结束时间。若要了解 UTC/GMT 时间，请在 bing.com 上搜索“utc 时间”。$coordFrequency 是指你想要运行工作流的频率（以分钟为单位）。",
      "pos": [
        18619,
        18734
      ]
    },
    {
      "content": "将以下内容追加到脚本。这部分定义 Oozie 负载：",
      "pos": [
        18739,
        18765
      ]
    },
    {
      "pos": [
        21335,
        21447
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>与工作流提交负载文件相比，主要区别是变量 <bpt id=\"p1\">**</bpt>oozie.coord.application.path<ept id=\"p1\">**</ept>。在提交工作流作业时，你使用的是 <bpt id=\"p2\">**</bpt>oozie.wf.application.path<ept id=\"p2\">**</ept>。"
    },
    {
      "content": "将以下内容追加到脚本。这部分检查 Oozie Web 服务状态：",
      "pos": [
        21452,
        21484
      ]
    },
    {
      "content": "将以下内容追加到脚本。这部分创建一项 Oozie 作业：",
      "pos": [
        22362,
        22390
      ]
    },
    {
      "pos": [
        23167,
        23248
      ],
      "content": "<ph id=\"ph1\">[AZURE.NOTE]</ph>在提交工作流作业时，你必须在创建作业后进行另一次 Web 服务调用以启动该作业。在这种情况下，该协调器作业会按时间触发。该作业将自动启动。"
    },
    {
      "content": "将以下内容追加到脚本。这部分检查 Oozie 作业状态：",
      "pos": [
        23253,
        23281
      ]
    },
    {
      "content": "（可选）将以下内容追加到脚本。",
      "pos": [
        24977,
        24992
      ]
    },
    {
      "content": "将以下内容追加到脚本：",
      "pos": [
        26711,
        26722
      ]
    },
    {
      "content": "如果要运行这些附加的功能，请删除这些 # 号。",
      "pos": [
        26950,
        26973
      ]
    },
    {
      "content": "如果你的 HDinsight 群集是 2.1 版的，请将“https://$clusterName.azurehdinsight.cn:443/oozie/v2/”替换为“https://$clusterName.azurehdinsight.cn:443/oozie/v1/”。HDInsight 群集版本 2.1 不支持 Web 服务的版本 2。",
      "pos": [
        26978,
        27153
      ]
    },
    {
      "pos": [
        27158,
        27194
      ],
      "content": "单击“运行脚本”或按 <bpt id=\"p1\">**</bpt>F5<ept id=\"p1\">**</ept> 键以运行该脚本。输出结果将会类似于："
    },
    {
      "content": "教程运行工作流输出",
      "pos": [
        27202,
        27211
      ]
    },
    {
      "content": "连接到 SQL 数据库以查看导出的数据。",
      "pos": [
        27241,
        27261
      ]
    },
    {
      "content": "检查作业错误日志",
      "pos": [
        27265,
        27273
      ]
    },
    {
      "pos": [
        27277,
        27452
      ],
      "content": "若要解决工作流的疑难问题，可从群集头节点中的 C:\\\\apps\\\\dist\\\\oozie-3.3.2.1.3.2.0-05\\\\oozie-win-distro\\\\logs\\\\Oozie.log 位置找到 Oozie 日志文件。有关 RDP 的信息，请参阅<bpt id=\"p1\">[</bpt>使用管理门户管理 HDInsight 群集<ept id=\"p1\">][hdinsight-admin-portal]</ept>。"
    },
    {
      "content": "重新运行教程",
      "pos": [
        27456,
        27462
      ]
    },
    {
      "content": "若要重新运行该工作流，必须执行以下任务：",
      "pos": [
        27466,
        27486
      ]
    },
    {
      "content": "删除 Hive 脚本输出文件。",
      "pos": [
        27490,
        27505
      ]
    },
    {
      "content": "删除 log4jLogsCount 表中的数据。",
      "pos": [
        27508,
        27532
      ]
    },
    {
      "content": "这是你可以使用的一个示例 Windows PowerShell 脚本：",
      "pos": [
        27534,
        27569
      ]
    },
    {
      "content": "<ph id=\"ph1\">&lt;a id=\"nextsteps\"&gt;</ph><ph id=\"ph2\">&lt;/a&gt;</ph>后续步骤",
      "pos": [
        28975,
        29001
      ]
    },
    {
      "content": "在本教程中，你已经学习了如何定义 Oozie 工作流、Oozie 协调器，以及如何使用 Azure PowerShell 运行 Oozie 协调器作业。若要了解更多信息，请参阅下列文章：",
      "pos": [
        29002,
        29095
      ]
    },
    {
      "content": "开始使用 HDInsight",
      "pos": [
        29100,
        29114
      ]
    },
    {
      "content": "HDInsight Emulator 入门",
      "pos": [
        29142,
        29163
      ]
    },
    {
      "content": "将 Azure Blob 存储与 HDInsight 配合使用",
      "pos": [
        29200,
        29231
      ]
    },
    {
      "content": "使用 Azure PowerShell 管理 HDInsight",
      "pos": [
        29255,
        29287
      ]
    },
    {
      "content": "将数据上载到 HDInsight",
      "pos": [
        29320,
        29336
      ]
    },
    {
      "content": "将 Sqoop 与 HDInsight 配合使用",
      "pos": [
        29364,
        29388
      ]
    },
    {
      "content": "将 Hive 与 HDInsight 配合使用",
      "pos": [
        29414,
        29437
      ]
    },
    {
      "content": "将 Pig 与 HDInsight 配合使用",
      "pos": [
        29462,
        29484
      ]
    },
    {
      "content": "为 HDInsight 开发 C# Hadoop 流作业",
      "pos": [
        29508,
        29536
      ]
    },
    {
      "content": "为 HDInsight 开发 Java MapReduce 程序",
      "pos": [
        29575,
        29607
      ]
    }
  ],
  "content": "<properties \n    pageTitle=\"在 HDInsight 中使用基于时间的 Hadoop Oozie 协调器 | Azure\" \n    description=\"在 HDInsight 中使用基于时间的 Hadoop Oozie 协调器（大数据服务）。了解如何定义 Oozie 工作流和协调器，并提交作业。\"\n    services=\"hdinsight\" \n    documentationCenter=\"\" \n    tags=\"azure-portal\"\n    authors=\"mumian\" \n    manager=\"paulettm\" \n    editor=\"cgronlun\"/>\n\n<tags \n    ms.service=\"hdinsight\" \n    ms.date=\"12/02/2015\"\n    wacn.date=\"01/14/2016\"/>\n\n\n# 将基于时间的 Oozie 协调器与 HDInsight 中的 Hadoop 配合使用以定义工作流和协调作业\n\n在本文中，你将学习如何定义工作流和协调器，以及如何基于时间触发协调器作业。在阅读本文之前，先浏览[将 Oozie 与 HDInsight 配合使用][hdinsight-use-oozie]一文会很有用。若要了解 Azure 数据工厂，请参阅 [将 Pig 和 Hive 用于数据工厂][azure-data-factory-pig-hive]。\n\n##<a id=\"whatisoozie\"></a>什么是 Oozie\n\nApache Oozie 是一个管理 Hadoop 作业的工作流/协调系统。它与 Hadoop 堆栈集成，支持 Apache MapReduce、Apache Pig、Apache Hive 和 Apache Sqoop 的 Hadoop 作业。它也能用于安排特定于某系统的作业，例如 Java 程序或 shell 脚本。\n\n下图显示将要实施的工作流：\n\n![工作流关系图][img-workflow-diagram]\n\n工作流包含两个操作：\n\n1. Hive 操作运行 HiveQL 脚本以统计 log4j 日志文件中每个日志级类型的次数。每个 log4j 日志都包含一行字段，其中包含 [LOG LEVEL] 字段，可显示类型和严重性，例如：\n\n        2012-02-03 18:35:34 SampleClass6 [INFO] everything normal for id 577725851\n        2012-02-03 18:35:34 SampleClass4 [FATAL] system problem at id 1991281254\n        2012-02-03 18:35:34 SampleClass3 [DEBUG] detail for id 1304807656\n        ...\n\n    该 Hive 脚本的输出结果类似于：\n    \n        [DEBUG] 434\n        [ERROR] 3\n        [FATAL] 1\n        [INFO]  96\n        [TRACE] 816\n        [WARN]  4\n\n    有关 Hive 的详细信息，请参阅[将 Hive 与 HDInsight 配合使用][hdinsight-use-hive]。\n    \n2.  Sqoop 操作将 HiveQL 操作输出结果导出到 Azure SQL 数据库中的表。有关 Sqoop 的详细信息，请参阅[将 Sqoop 与 HDInsight 配合使用][hdinsight-use-sqoop]。\n\n> [AZURE.NOTE]有关 HDInsight 群集上支持的 Oozie 版本，请参阅 [HDInsight 提供的群集版本有哪些新功能？][hdinsight-versions]。\n\n> [AZURE.NOTE]本教程适用于 HDInsight 群集版本 2.1 和 3.0。本文尚未在 HDInsight Emulator 上测试过。\n\n\n##<a id=\"prerequisites\"></a>先决条件\n\n在开始阅读本教程前，你必须具有：\n\n- **配备 Azure PowerShell 的工作站**。请参阅[安装和使用 Azure PowerShell][powershell-install-configure]。若要执行 Windows PowerShell 脚本，必须以管理员身份运行 Azure PowerShell 并将执行策略设为 *RemoteSigned*。有关详细信息，请参阅[运行 Windows PowerShell 脚本][powershell-script]。\n- **一个 HDInsight 群集**。有关创建 HDInsight 群集的信息，请参阅[预配 HDInsight 群集][hdinsight-provision]或 [HDInsight 入门][hdinsight-get-started]。你将需要以下数据才能完成本教程：\n\n    <table border = \"1\">\n    <tr><th>群集属性</th><th>Windows PowerShell 变量名</th><th>值</th><th>说明</th></tr>\n    <tr><td>HDInsight 群集名称</td><td>$clusterName</td><td></td><td>要在其中运行本教程的 HDInsight 群集。</td></tr>\n    <tr><td>HDInsight 群集用户名</td><td>$clusterUsername</td><td></td><td>HDInsight 群集用户名。</td></tr>\n    <tr><td>HDInsight 群集用户的密码 </td><td>$clusterPassword</td><td></td><td>HDInsight 群集用户的密码。</td></tr>\n    <tr><td>Azure 存储帐户名称</td><td>$storageAccountName</td><td></td><td>可用于 HDInsight 群集的 Azure 存储帐户。在本教程中，使用在群集设置过程中指定的默认存储帐户。</td></tr>\n    <tr><td>Azure Blob 容器名称</td><td>$containerName</td><td></td><td>在此示例中，使用用于默认 HDInsight 群集文件系统的 Azure Blob 存储容器。默认情况下，该容器与 HDInsight 群集同名。</td></tr>\n    </table>\n\n- **Azure SQL 数据库**。你必须为 SQL 数据库服务器配置防火墙规则以允许从你的工作站进行访问。有关创建 Azure SQL 数据库和配置防火墙的说明，请参阅 [Azure SQL 数据库入门][sqldatabase-get-started]。本文提供了用于创建本教程所需的 Azure SQL 数据库表的 Windows PowerShell 脚本。\n\n    <table border = \"1\">\n    <tr><th>SQL 数据库属性</th><th>Windows PowerShell 变量名</th><th>值</th><th>说明</th></tr>\n    <tr><td>SQL 数据库服务器名称</td><td>$sqlDatabaseServer</td><td></td><td>Sqoop 要将数据导出到其中的 SQL 数据库服务器。</td></tr>\n    <tr><td>SQL 数据库登录名</td><td>$sqlDatabaseLogin</td><td></td><td>SQL 数据库登录名。</td></tr>\n    <tr><td>SQL 数据库登录密码</td><td>$sqlDatabaseLoginPassword</td><td></td><td>SQL 数据库登录密码。</td></tr>\n    <tr><td>SQL 数据库名</td><td>$sqlDatabaseName</td><td></td><td>Sqoop 要将数据导出到其中的 Azure SQL 数据库。</td></tr>\n    </table>\n\n    > [AZURE.NOTE]默认情况下，可以从 Azure HDInsight 这样的 Azure 服务连接 Azure SQL 数据库。如果禁用了此防火墙设置，则必须从 Azure 门户启用它。有关创建 SQL 数据库和配置防火墙规则的说明，请参阅 [创建和配置 SQL 数据库][sqldatabase-create-configure]。\n\n\n> [AZURE.NOTE]将值填充到表中。这将有助于学习本教程。\n\n\n##<a id=\"defineworkflow\"></a>定义 Oozie 工作流及相关 HiveQL 脚本\n\nOozie 工作流定义是用 hPDL（一种 XML 过程定义语言）编写的。默认的工作流文件名为 *workflow.xml*。你将在本地保存该工作流文件，并将在本教程后面使用 Azure PowerShell 将它部署到 HDInsight 群集。\n\n该工作流中的 Hive 操作调用 HiveQL 脚本文件。此脚本文件包含三个 HiveQL 语句：\n\n1. **DROP TABLE 语句**删除 log4j Hive 表（如果存在）。\n2. **CREATE TABLE 语句**创建一个 log4j Hive 外部表，该表指向 log4j 日志文件的位置；\n3.  **log4j 日志文件的位置**。字段分隔符为“,”。默认分行符为“\\\\n”。Hive 外部表用于在你想多次运行 Oozie 工作流的情况下避免数据文件从原始位置被删除。\n3. **INSERT OVERWRITE 语句**从 log4j Hive 表统计每个日志级类型的次数，并将输出结果保存到 Azure Blob 存储位置。 \n\n**注意**：有一个已知的 Hive 路径问题。你在提交 Oozie 作业时将会遇到这个问题。可在 TechNet Wiki 上找到用于解决此问题的说明：[HDInsight Hive 错误: 无法重命名][technetwiki-hive-error]。\n\n**将 HiveQL 脚本文件定义为由工作流调用**\n\n1. 创建一个内容如下的文本文件：\n\n        DROP TABLE ${hiveTableName};\n        CREATE EXTERNAL TABLE ${hiveTableName}(t1 string, t2 string, t3 string, t4 string, t5 string, t6 string, t7 string) ROW FORMAT DELIMITED FIELDS TERMINATED BY ' ' STORED AS TEXTFILE LOCATION '${hiveDataFolder}';\n        INSERT OVERWRITE DIRECTORY '${hiveOutputFolder}' SELECT t4 AS sev, COUNT(*) AS cnt FROM ${hiveTableName} WHERE t4 LIKE '[%' GROUP BY t4;\n\n    该脚本中使用了三个变量：\n\n    - ${hiveTableName}\n    - ${hiveDataFolder}\n    - ${hiveOutputFolder}\n            \n    工作流定义文件（本教程中的 workflow.xml）在运行时会将三个值传递到这个 HiveQL 脚本。\n        \n2. 使用 ANSI (ASCII) 编码将文件另存为 **C:\\\\Tutorials\\\\UseOozie\\\\useooziewf.hql**。（如果你的文本编辑器不提供此选项，则使用记事本。） 在本教程的后面，此脚本文件将被部署到 HDInsight 群集。\n\n\n\n**定义工作流**\n\n1. 创建一个内容如下的文本文件：\n\n        <workflow-app name=\"useooziewf\" xmlns=\"uri:oozie:workflow:0.2\">\n            <start to = \"RunHiveScript\"/> \n            \n            <action name=\"RunHiveScript\">\n                <hive xmlns=\"uri:oozie:hive-action:0.2\">\n                    <job-tracker>${jobTracker}</job-tracker>\n                    <name-node>${nameNode}</name-node>\n                    <configuration>\n                        <property>\n                            <name>mapred.job.queue.name</name>\n                            <value>${queueName}</value>\n                        </property>\n                    </configuration>\n                    <script>${hiveScript}</script>\n                    <param>hiveTableName=${hiveTableName}</param>\n                    <param>hiveDataFolder=${hiveDataFolder}</param>\n                    <param>hiveOutputFolder=${hiveOutputFolder}</param>\n                </hive>\n                <ok to=\"RunSqoopExport\"/>\n                <error to=\"fail\"/>\n            </action>\n        \n            <action name=\"RunSqoopExport\">\n                <sqoop xmlns=\"uri:oozie:sqoop-action:0.2\">\n                    <job-tracker>${jobTracker}</job-tracker>\n                    <name-node>${nameNode}</name-node>\n                    <configuration>\n                        <property>\n                            <name>mapred.compress.map.output</name>\n                            <value>true</value>\n                        </property>\n                    </configuration>\n                <arg>export</arg>\n                <arg>--connect</arg> \n                <arg>${sqlDatabaseConnectionString}</arg> \n                <arg>--table</arg>\n                <arg>${sqlDatabaseTableName}</arg> \n                <arg>--export-dir</arg> \n                <arg>${hiveOutputFolder}</arg> \n                <arg>-m</arg> \n                <arg>1</arg>\n                <arg>--input-fields-terminated-by</arg>\n                <arg>\"\\001\"</arg>\n                </sqoop>\n                <ok to=\"end\"/>\n                <error to=\"fail\"/>\n            </action>\n        \n            <kill name=\"fail\">\n                <message>Job failed, error message[${wf:errorMessage(wf:lastErrorNode())}] </message>\n            </kill>\n        \n           <end name=\"end\"/>\n        </workflow-app>\n\n    该工作流中定义了两个操作。start-to 操作是 *RunHiveScript*。如果该操作运行*正常*，则下一个操作是 *RunSqoopExport*。\n\n    RunHiveScript 有几个变量。在从工作站使用 Azure PowerShell 提交 Oozie 作业时，将会传递值。\n\n    <table border = \"1\">\n    <tr><th>工作流变量</th><th>说明</th></tr>\n    <tr><td>${jobTracker}</td><td>指定 Hadoop 作业跟踪器的 URL。在 HDInsight 群集版本 2.0 和 3.0 上使用 <strong>jobtrackerhost:9010</strong>。</td></tr>\n    <tr><td>${nameNode}</td><td>指定 Hadoop 名称节点的 URL。使用默认文件系统 wasb:// 地址，例如 <i>wasb://&lt;containerName>@&lt;storageAccountName>.blob.core.chinacloudapi.cn</i>。</td></tr>\n    <tr><td>${queueName}</td><td>指定要将作业提交到的 queuename。使用“默认”。<strong></strong></td></tr>\n    </table><table border = \"1\">\n    <tr><th>Hive 操作变量</th><th>说明</th></tr>\n    <tr><td>${hiveDataFolder}</td><td>Hive Create Table 命令的源目录。</td></tr>\n    <tr><td>${hiveOutputFolder}</td><td>INSERT OVERWRITE 语句的输出文件夹。</td></tr>\n    <tr><td>${hiveTableName}</td><td>引用 log4j 数据文件的 Hive 表的名称。</td></tr>\n    </table><table border = \"1\">\n    <tr><th>Sqoop 操作变量</th><th>说明</th></tr>\n    <tr><td>${sqlDatabaseConnectionString}</td><td>SQL 数据库连接字符串。</td></tr>\n    <tr><td>${sqlDatabaseTableName}</td><td>数据将要导出到的 Azure SQL 数据库表。</td></tr>\n    <tr><td>${hiveOutputFolder}</td><td>Hive INSERT OVERWRITE 语句的输出文件夹。这是用于 Sqoop 导出 (export-dir) 的同一个文件夹。</td></tr>\n    </table>\n\n    有关 Oozie 工作流以及使用工作流操作的详细信息，请参阅 [Apache Oozie 4.0 文档][apache-oozie-400]（用于 HDInsight 群集版本 3.0）或 [Apache Oozie 3.3.2 文档][apache-oozie-332]（用于 HDInsight 群集版本 2.1）。\n\n2. 使用 ANSI (ASCII) 编码将文件另存为 **C:\\\\Tutorials\\\\UseOozie\\\\workflow.xml**。（如果你的文本编辑器不提供此选项，则使用记事本。）\n\n**定义协调器**\n\n1. 创建一个内容如下的文本文件：\n\n        <coordinator-app name=\"my_coord_app\" frequency=\"${coordFrequency}\" start=\"${coordStart}\" end=\"${coordEnd}\" timezone=\"${coordTimezone}\" xmlns=\"uri:oozie:coordinator:0.4\">\n           <action>\n              <workflow>\n                 <app-path>${wfPath}</app-path>\n              </workflow>\n           </action>\n        </coordinator-app>\n\n    该定义文件中使用了五个变量：\n\n    | 变量 | 说明 |\n    | ------------------|------------ |\n    | ${coordFrequency} | 作业暂停时间。频率总是用分钟来表示的。 |\n    | ${coordStart} | 作业开始时间。 |\n    | ${coordEnd} | 作业结束时间。 |\n    | ${coordTimezone} | Oozie 在没有夏时制的固定时区（通常用 UTC 表示）处理协调器作业。此时区被称为“Oozie 处理时区”。 |\n    | ${wfPath} | workflow.xml 的路径。如果该工作流文件名不是默认文件名 (workflow.xml)，则必须指定该名称。 |\n    \n2. 使用 ANSI (ASCII) 编码将文件另存为 **C:\\\\Tutorials\\\\UseOozie\\\\coordinator.xml**。（如果你的文本编辑器不提供此选项，则使用记事本。）\n    \n##<a id=\"deploy\"></a>部署 Oozie 项目并准备教程\n\n你将运行 Azure PowerShell 脚本来执行以下操作：\n\n- 将 HiveQL 脚本 (useoozie.hql) 复制到 Azure Blob 存储 wasb:///tutorials/useoozie/useoozie.hql。\n- 将 workflow.xml 复制到 wasb:///tutorials/useoozie/workflow.xml。\n- 将 coordinator.xml 复制到 wasb:///tutorials/useoozie/coordinator.xml。\n- 将数据文件 (/example/data/sample.log) 复制到 wasb:///tutorials/useoozie/data/sample.log。 \n- 创建用于存储 Sqoop 导出数据的 Azure SQL 数据库表。表的名称为 *log4jLogCount*。\n\n**了解 HDInsight 存储**\n\nHDInsight 将 Azure Blob 存储用于数据存储。wasb:// 是 Microsoft 在 Azure Blob 存储中对 Hadoop 分布式文件系统 (HDFS) 的实施。有关详细信息，请参阅[将 Azure Blob 存储与 HDInsight 配合使用][hdinsight-storage]。\n\n设置 HDInsight 群集时，请将 Azure Blob 存储帐户和该帐户上的特定容器指定为默认文件系统，就像在 HDFS 中一样。除了此存储帐户外，在设置过程中，你还可以从同一 Azure 订阅或不同 Azure 订阅添加其他存储帐户。有关添加其他存储帐户的说明，请参阅[设置 HDInsight 群集][hdinsight-provision]。为了简化本教程中使用的 Azure PowerShell 脚本，所有文件都存储在默认文件系统容器（位于 */tutorials/useoozie*）中。默认情况下，此容器与 HDInsight 群集同名。语法为：\n\n    wasb[s]://<ContainerName>@<StorageAccountName>.blob.core.chinacloudapi.cn/<path>/<filename>\n\n> [AZURE.NOTE]HDInsight 群集 3.0 版只支持 *wasb://* 语法。较早的 *asv://* 语法在 HDInsight 2.1 和 1.6 群集中受支持，但在 HDInsight 3.0 群集中不受支持。\n\n> [AZURE.NOTE]wasb:// 路径是虚拟路径。有关详细信息，请参阅[将 Azure Blob 存储与 HDInsight 配合使用][hdinsight-storage]。\n\n存储在默认文件系统容器中的文件可以使用以下任一 URI 从 HDInsight 进行访问（以 workflow.xml 为例）：\n\n    wasb://mycontainer@mystorageaccount.blob.core.chinacloudapi.cn/tutorials/useoozie/workflow.xml\n    wasb:///tutorials/useoozie/workflow.xml\n    /tutorials/useoozie/workflow.xml\n\n如果要从存储帐户直接访问该文件，则请注意，该文件的 Blob 名称是：\n\n    tutorials/useoozie/workflow.xml\n\n**了解 Hive 内部表和外部表**\n\n以下是你需要了解的有关 Hive 内部表和外部表的一些信息：\n\n- CREATE TABLE 命令创建内部表，也称为托管表。数据文件必须位于默认容器中。\n- CREATE TABLE 命令将数据文件移动到默认容器中的 /hive/warehouse/<TableName> 文件夹。\n- CREATE EXTERNAL TABLE 命令创建外部表。数据文件可以位于默认容器以外的位置。\n- CREATE EXTERNAL TABLE 命令不移动数据文件。\n- CREATE EXTERNAL TABLE 命令不允许 LOCATION 子句中指定的文件夹下有任何子文件夹。这是本教程生成 sample.log 文件的副本的原因。\n\n有关详细信息，请参阅 [HDInsight：Hive 内部和外部表简介][cindygross-hive-tables]。\n\n**准备教程**\n\n1. 打开 Windows PowerShell ISE（在 Windows 8“开始”屏幕上，键入 **PowerShell_ISE**，然后单击“Windows PowerShell ISE”。有关详细信息，请参阅[在 Windows 8 和 Windows 上启动 Windows PowerShell][powershell-start]。\n2. 在底部窗格中，运行以下命令以连接到 Azure 订阅：\n\n        Add-AzureAccount -Environment AzureChinaCloud\n\n    系统将提示你输入 Azure 帐户凭据。这种添加订阅连接的方法会超时，12 个小时之后，你将需要再次运行该 cmdlet。\n\n    > [AZURE.NOTE]如果你有多个 Azure 订阅，而默认订阅不是你想使用的，则请使用 <strong>Select-AzureSubscription</strong> cmdlet 来选择订阅。\n\n3. 将以下脚本复制到脚本窗格，然后设置前六个变量：\n            \n        # WASB variables\n        $storageAccountName = \"<StorageAccountName>\"\n        $containerName = \"<BlobStorageContainerName>\"\n        \n        # SQL database variables\n        $sqlDatabaseServer = \"<SQLDatabaseServerName>\"  \n        $sqlDatabaseLogin = \"<SQLDatabaseLoginName>\"\n        $sqlDatabaseLoginPassword = \"SQLDatabaseLoginPassword>\"\n        $sqlDatabaseName = \"<SQLDatabaseName>\"  \n        $sqlDatabaseTableName = \"log4jLogsCount\"\n        \n        # Oozie files for the tutorial  \n        $hiveQLScript = \"C:\\Tutorials\\UseOozie\\useooziewf.hql\"\n        $workflowDefinition = \"C:\\Tutorials\\UseOozie\\workflow.xml\"\n        $coordDefinition =  \"C:\\Tutorials\\UseOozie\\coordinator.xml\"\n        \n        # WASB folder for storing the Oozie tutorial files.\n        $destFolder = \"tutorials/useoozie\"  # Do NOT use the long path here\n\n\n    有关这些变量的详细说明，请参阅本教程中的[先决条件](#prerequisites)部分。\n\n3. 在脚本窗格中将以下内容追加到脚本：\n        \n        # Create a storage context object\n        $storageaccountkey = get-azurestoragekey $storageAccountName | %{$_.Primary}\n        $destContext = New-AzureStorageContext -Environment AzureChinaCloud -StorageAccountName $storageAccountName -StorageAccountKey $storageaccountkey\n        \n        function uploadOozieFiles()\n        {       \n            Write-Host \"Copy HiveQL script, workflow definition and coordinator definition ...\" -ForegroundColor Green\n            Set-AzureStorageBlobContent -File $hiveQLScript -Container $containerName -Blob \"$destFolder/useooziewf.hql\" -Context $destContext\n            Set-AzureStorageBlobContent -File $workflowDefinition -Container $containerName -Blob \"$destFolder/workflow.xml\" -Context $destContext\n            Set-AzureStorageBlobContent -File $coordDefinition -Container $containerName -Blob \"$destFolder/coordinator.xml\" -Context $destContext\n        }\n                \n        function prepareHiveDataFile()\n        {\n            Write-Host \"Make a copy of the sample.log file ... \" -ForegroundColor Green\n            Start-CopyAzureStorageBlob -SrcContainer $containerName -SrcBlob \"example/data/sample.log\" -Context $destContext -DestContainer $containerName -destBlob \"$destFolder/data/sample.log\" -DestContext $destContext\n        }\n                \n        function prepareSQLDatabase()\n        {\n            # SQL query string for creating log4jLogsCount table\n            $cmdCreateLog4jCountTable = \" CREATE TABLE [dbo].[$sqlDatabaseTableName](\n                    [Level] [nvarchar](10) NOT NULL,\n                    [Total] float,\n                CONSTRAINT [PK_$sqlDatabaseTableName] PRIMARY KEY CLUSTERED   \n                (\n                [Level] ASC\n                )\n                )\"\n                \n            #Create the log4jLogsCount table\n            Write-Host \"Create Log4jLogsCount table ...\" -ForegroundColor Green\n            $conn = New-Object System.Data.SqlClient.SqlConnection\n            $conn.ConnectionString = \"Data Source=$sqlDatabaseServer.database.chinacloudapi.cn;Initial Catalog=$sqlDatabaseName;User ID=$sqlDatabaseLogin;Password=$sqlDatabaseLoginPassword;Encrypt=true;Trusted_Connection=false;\"\n            $conn.open()\n            $cmd = New-Object System.Data.SqlClient.SqlCommand\n            $cmd.connection = $conn\n            $cmd.commandtext = $cmdCreateLog4jCountTable\n            $cmd.executenonquery()\n                \n            $conn.close()\n        }\n                \n        # upload workflow.xml, coordinator.xml, and ooziewf.hql\n        uploadOozieFiles;\n                \n        # make a copy of example/data/sample.log to example/data/log4j/sample.log\n        prepareHiveDataFile;\n        \n        # create log4jlogsCount table on SQL database\n        prepareSQLDatabase;\n\n4. 单击“运行脚本”或按 **F5** 键以运行该脚本。输出结果将会类似于：\n\n    ![教程准备的输出结果][img-preparation-output]\n\n##<a id=\"run\"></a>运行 Oozie 项目\n\nAzure PowerShell 目前不提供任何用于定义 Oozie 作业的 cmdlet。你可以使用 **Invoke-RestMethod** cmdlet 来调用 Oozie Web 服务。Oozie Web 服务 API 是 HTTP REST JSON API。有关 Oozie Web 服务 API 的详细信息，请参阅 [Apache Oozie 4.0 文档][apache-oozie-400]（用于 HDInsight 群集版本 3.0）或 [Apache Oozie 3.3.2 文档][apache-oozie-332]（用于 HDInsight 群集版本 2.1）。\n\n**提交 Oozie 作业**\n\n1. 打开 Windows PowerShell ISE（在 Windows 8“开始”屏幕上，键入 **PowerShell_ISE**，然后单击“Windows PowerShell ISE”。有关详细信息，请参阅[在 Windows 8 和 Windows 上启动 Windows PowerShell][powershell-start]。\n\n3. 将以下脚本复制到脚本窗格，然后设置前 14 个变量（不过，请跳过 **$storageUri**）。\n\n        #HDInsight cluster variables\n        $clusterName = \"<HDInsightClusterName>\"\n        $clusterUsername = \"<HDInsightClusterUsername>\"\n        $clusterPassword = \"<HDInsightClusterUserPassword>\"\n        \n        #Azure Blob storage (WASB) variables\n        $storageAccountName = \"<StorageAccountName>\"\n        $storageContainerName = \"<BlobContainerName>\"\n        $storageUri=\"wasb://$storageContainerName@$storageAccountName.blob.core.chinacloudapi.cn\"\n        \n        #Azure SQL database variables\n        $sqlDatabaseServer = \"<SQLDatabaseServerName>\"\n        $sqlDatabaseLogin = \"<SQLDatabaseLoginName>\"\n        $sqlDatabaseLoginPassword = \"<SQLDatabaseloginPassword>\"\n        $sqlDatabaseName = \"<SQLDatabaseName>\"  \n        \n        #Oozie WF/coordinator variables\n        $coordStart = \"2014-03-21T13:45Z\"\n        $coordEnd = \"2014-03-21T13:45Z\"\n        $coordFrequency = \"1440\"    # in minutes, 24h x 60m = 1440m\n        $coordTimezone = \"UTC\"  #UTC/GMT\n\n        $oozieWFPath=\"$storageUri/tutorials/useoozie\"  # The default name is workflow.xml. And you don't need to specify the file name.\n        $waitTimeBetweenOozieJobStatusCheck=10\n\n        #Hive action variables\n        $hiveScript = \"$storageUri/tutorials/useoozie/useooziewf.hql\"\n        $hiveTableName = \"log4jlogs\"\n        $hiveDataFolder = \"$storageUri/tutorials/useoozie/data\"\n        $hiveOutputFolder = \"$storageUri/tutorials/useoozie/output\"\n        \n        #Sqoop action variables\n        $sqlDatabaseConnectionString = \"jdbc:sqlserver://$sqlDatabaseServer.database.chinacloudapi.cn;user=$sqlDatabaseLogin@$sqlDatabaseServer;password=$sqlDatabaseLoginPassword;database=$sqlDatabaseName\"\n        $sqlDatabaseTableName = \"log4jLogsCount\"\n\n        $passwd = ConvertTo-SecureString $clusterPassword -AsPlainText -Force\n        $creds = New-Object System.Management.Automation.PSCredential ($clusterUsername, $passwd)\n\n    有关这些变量的详细说明，请参阅本教程中的[先决条件](#prerequisites)部分。\n\n    $coordstart 和 $coordend 是工作流的开始和结束时间。若要了解 UTC/GMT 时间，请在 bing.com 上搜索“utc 时间”。$coordFrequency 是指你想要运行工作流的频率（以分钟为单位）。\n\n3. 将以下内容追加到脚本。这部分定义 Oozie 负载：\n        \n        #OoziePayload used for Oozie web service submission\n        $OoziePayload =  @\"\n        <?xml version=\"1.0\" encoding=\"UTF-8\"?>\n        <configuration>\n        \n           <property>\n               <name>nameNode</name>\n               <value>$storageUrI</value>\n           </property>\n        \n           <property>\n               <name>jobTracker</name>\n               <value>jobtrackerhost:9010</value>\n           </property>\n        \n           <property>\n               <name>queueName</name>\n               <value>default</value>\n           </property>\n        \n           <property>\n               <name>oozie.use.system.libpath</name>\n               <value>true</value>\n           </property>\n\n           <property>\n               <name>oozie.coord.application.path</name>\n               <value>$oozieWFPath</value>\n           </property>\n\n           <property>\n               <name>wfPath</name>\n               <value>$oozieWFPath</value>\n           </property>\n\n           <property>\n               <name>coordStart</name>\n               <value>$coordStart</value>\n           </property>\n\n           <property>\n               <name>coordEnd</name>\n               <value>$coordEnd</value>\n           </property>\n\n           <property>\n               <name>coordFrequency</name>\n               <value>$coordFrequency</value>\n           </property>\n\n           <property>\n               <name>coordTimezone</name>\n               <value>$coordTimezone</value>\n           </property>\n\n           <property>\n               <name>hiveScript</name>\n               <value>$hiveScript</value>\n           </property>\n        \n           <property>\n               <name>hiveTableName</name>\n               <value>$hiveTableName</value>\n           </property>\n        \n           <property>\n               <name>hiveDataFolder</name>\n               <value>$hiveDataFolder</value>\n           </property>\n        \n           <property>\n               <name>hiveOutputFolder</name>\n               <value>$hiveOutputFolder</value>\n           </property>\n        \n           <property>\n               <name>sqlDatabaseConnectionString</name>\n               <value>\";$sqlDatabaseConnectionString\";</value>\n           </property>\n        \n           <property>\n               <name>sqlDatabaseTableName</name>\n               <value>$SQLDatabaseTableName</value>\n           </property>\n        \n           <property>\n               <name>user.name</name>\n               <value>admin</value>\n           </property>\n        \n        </configuration>\n        \"@\n\n    >[AZURE.NOTE]与工作流提交负载文件相比，主要区别是变量 **oozie.coord.application.path**。在提交工作流作业时，你使用的是 **oozie.wf.application.path**。\n\n4. 将以下内容追加到脚本。这部分检查 Oozie Web 服务状态：\n            \n        function checkOozieServerStatus()\n        {\n            Write-Host \"Checking Oozie server status...\" -ForegroundColor Green\n            $clusterUriStatus = \"https://$clusterName.azurehdinsight.cn:443/oozie/v2/admin/status\"\n            $response = Invoke-RestMethod -Method Get -Uri $clusterUriStatus -Credential $creds -OutVariable $OozieServerStatus \n            \n            $jsonResponse = ConvertFrom-Json (ConvertTo-Json -InputObject $response)\n            $oozieServerSatus = $jsonResponse[0].(\"systemMode\")\n            Write-Host \"Oozie server status is $oozieServerSatus...\"\n        \n            if($oozieServerSatus -notmatch \"NORMAL\")\n            {\n                Write-Host \"Oozie server status is $oozieServerSatus...cannot submit Oozie jobs. Check the server status and re-run the job.\"\n                exit 1\n            }\n        }\n    \n5. 将以下内容追加到脚本。这部分创建一项 Oozie 作业：\n\n        function createOozieJob()\n        {\n            # create Oozie job\n            Write-Host \"Sending the following Payload to the cluster:\" -ForegroundColor Green\n            Write-Host \"`n--------`n$OoziePayload`n--------\"\n            $clusterUriCreateJob = \"https://$clusterName.azurehdinsight.cn:443/oozie/v2/jobs\"\n            $response = Invoke-RestMethod -Method Post -Uri $clusterUriCreateJob -Credential $creds -Body $OoziePayload -ContentType \"application/xml\" -OutVariable $OozieJobName -debug -Verbose\n        \n            $jsonResponse = ConvertFrom-Json (ConvertTo-Json -InputObject $response)\n            $oozieJobId = $jsonResponse[0].(\"id\")\n            Write-Host \"Oozie job id is $oozieJobId...\"\n        \n            return $oozieJobId\n        }\n\n    > [AZURE.NOTE]在提交工作流作业时，你必须在创建作业后进行另一次 Web 服务调用以启动该作业。在这种情况下，该协调器作业会按时间触发。该作业将自动启动。\n\n6. 将以下内容追加到脚本。这部分检查 Oozie 作业状态：\n\n        function checkOozieJobStatus($oozieJobId)\n        {\n            # get job status\n            Write-Host \"Sleeping for $waitTimeBetweenOozieJobStatusCheck seconds until the job metadata is populated in the Oozie metastore...\" -ForegroundColor Green\n            Start-Sleep -Seconds $waitTimeBetweenOozieJobStatusCheck\n        \n            Write-Host \"Getting job status and waiting for the job to complete...\" -ForegroundColor Green\n            $clusterUriGetJobStatus = \"https://$clusterName.azurehdinsight.cn:443/oozie/v2/job/\" + $oozieJobId + \"?show=info\"\n            $response = Invoke-RestMethod -Method Get -Uri $clusterUriGetJobStatus -Credential $creds \n            $jsonResponse = ConvertFrom-Json (ConvertTo-Json -InputObject $response)\n            $JobStatus = $jsonResponse[0].(\"status\")\n        \n            while($JobStatus -notmatch \"SUCCEEDED|KILLED\")\n            {\n                Write-Host \"$(Get-Date -format 'G'): $oozieJobId is in $JobStatus state...waiting $waitTimeBetweenOozieJobStatusCheck seconds for the job to complete...\"\n                Start-Sleep -Seconds $waitTimeBetweenOozieJobStatusCheck\n                $response = Invoke-RestMethod -Method Get -Uri $clusterUriGetJobStatus -Credential $creds \n                $jsonResponse = ConvertFrom-Json (ConvertTo-Json -InputObject $response)\n                $JobStatus = $jsonResponse[0].(\"status\")\n            }\n        \n            Write-Host \"$(Get-Date -format 'G'): $oozieJobId is in $JobStatus state!\"\n            if($JobStatus -notmatch \"SUCCEEDED\")\n            {\n                Write-Host \"Check logs at http://headnode0:9014/cluster for detais.\"\n                exit -1\n            }\n        }\n\n7. （可选）将以下内容追加到脚本。\n\n        function listOozieJobs()\n        {\n            Write-Host \"Listing Oozie jobs...\" -ForegroundColor Green\n            $clusterUriStatus = \"https://$clusterName.azurehdinsight.cn:443/oozie/v2/jobs\"\n            $response = Invoke-RestMethod -Method Get -Uri $clusterUriStatus -Credential $creds \n            \n            write-host \"Job ID                                   App Name        Status      Started                         Ended\"\n            write-host \"----------------------------------------------------------------------------------------------------------------------------------\"\n            foreach($job in $response.workflows)\n            {\n                Write-Host $job.id \"`t\" $job.appName \"`t\" $job.status \"`t\" $job.startTime \"`t\" $job.endTime\n            }\n        }\n\n        function ShowOozieJobLog($oozieJobId)\n        {\n            Write-Host \"Showing Oozie job info...\" -ForegroundColor Green\n            $clusterUriStatus = \"https://$clusterName.azurehdinsight.cn:443/oozie/v2/job/$oozieJobId\" + \"?show=log\"\n            $response = Invoke-RestMethod -Method Get -Uri $clusterUriStatus -Credential $creds \n            write-host $response\n        }\n\n        function killOozieJob($oozieJobId)\n        {\n            Write-Host \"Killing the Oozie job $oozieJobId...\" -ForegroundColor Green\n            $clusterUriStartJob = \"https://$clusterName.azurehdinsight.cn:443/oozie/v2/job/\" + $oozieJobId + \"?action=kill\" #Valid values for the 'action' parameter are 'start', 'suspend', 'resume', 'kill', 'dryrun', 'rerun', and 'change'.\n            $response = Invoke-RestMethod -Method Put -Uri $clusterUriStartJob -Credential $creds | Format-Table -HideTableHeaders -debug\n        }\n  \n7. 将以下内容追加到脚本：\n\n        checkOozieServerStatus\n        # listOozieJobs\n        $oozieJobId = createOozieJob($oozieJobId)\n        checkOozieJobStatus($oozieJobId)\n        # ShowOozieJobLog($oozieJobId)\n        # killOozieJob($oozieJobId)\n\n    如果要运行这些附加的功能，请删除这些 # 号。\n\n7. 如果你的 HDinsight 群集是 2.1 版的，请将“https://$clusterName.azurehdinsight.cn:443/oozie/v2/”替换为“https://$clusterName.azurehdinsight.cn:443/oozie/v1/”。HDInsight 群集版本 2.1 不支持 Web 服务的版本 2。\n\n7. 单击“运行脚本”或按 **F5** 键以运行该脚本。输出结果将会类似于：\n\n    ![教程运行工作流输出][img-runworkflow-output]\n\n8. 连接到 SQL 数据库以查看导出的数据。\n\n**检查作业错误日志**\n\n若要解决工作流的疑难问题，可从群集头节点中的 C:\\\\apps\\\\dist\\\\oozie-3.3.2.1.3.2.0-05\\\\oozie-win-distro\\\\logs\\\\Oozie.log 位置找到 Oozie 日志文件。有关 RDP 的信息，请参阅[使用管理门户管理 HDInsight 群集][hdinsight-admin-portal]。\n\n**重新运行教程**\n\n若要重新运行该工作流，必须执行以下任务：\n\n- 删除 Hive 脚本输出文件。\n- 删除 log4jLogsCount 表中的数据。\n\n这是你可以使用的一个示例 Windows PowerShell 脚本：\n\n    $storageAccountName = \"<AzureStorageAccountName>\"\n    $containerName = \"<ContainerName>\"\n    \n    #SQL database variables\n    $sqlDatabaseServer = \"<SQLDatabaseServerName>\"\n    $sqlDatabaseLogin = \"<SQLDatabaseLoginName>\"\n    $sqlDatabaseLoginPassword = \"<SQLDatabaseLoginPassword>\"\n    $sqlDatabaseName = \"<SQLDatabaseName>\"\n    $sqlDatabaseTableName = \"log4jLogsCount\"\n    \n    Write-host \"Delete the Hive script output file ...\" -ForegroundColor Green\n    $storageaccountkey = get-azurestoragekey $storageAccountName | %{$_.Primary}\n    $destContext = New-AzureStorageContext -Environment AzureChinaCloud -StorageAccountName $storageAccountName -StorageAccountKey $storageaccountkey\n    Remove-AzureStorageBlob -Context $destContext -Blob \"tutorials/useoozie/output/000000_0\" -Container $containerName\n    \n    Write-host \"Delete all the records from the log4jLogsCount table ...\" -ForegroundColor Green\n    $conn = New-Object System.Data.SqlClient.SqlConnection\n    $conn.ConnectionString = \"Data Source=$sqlDatabaseServer.database.chinacloudapi.cn;Initial Catalog=$sqlDatabaseName;User ID=$sqlDatabaseLogin;Password=$sqlDatabaseLoginPassword;Encrypt=true;Trusted_Connection=false;\"\n    $conn.open()\n    $cmd = New-Object System.Data.SqlClient.SqlCommand\n    $cmd.connection = $conn\n    $cmd.commandtext = \"delete from $sqlDatabaseTableName\"\n    $cmd.executenonquery()\n    \n    $conn.close()\n\n\n##<a id=\"nextsteps\"></a>后续步骤\n在本教程中，你已经学习了如何定义 Oozie 工作流、Oozie 协调器，以及如何使用 Azure PowerShell 运行 Oozie 协调器作业。若要了解更多信息，请参阅下列文章：\n\n- [开始使用 HDInsight][hdinsight-get-started]\n- [HDInsight Emulator 入门][hdinsight-get-started-emulator]\n- [将 Azure Blob 存储与 HDInsight 配合使用][hdinsight-storage]\n- [使用 Azure PowerShell 管理 HDInsight][hdinsight-admin-powershell]\n- [将数据上载到 HDInsight][hdinsight-upload-data]\n- [将 Sqoop 与 HDInsight 配合使用][hdinsight-use-sqoop]\n- [将 Hive 与 HDInsight 配合使用][hdinsight-use-hive]\n- [将 Pig 与 HDInsight 配合使用][hdinsight-use-pig]\n- [为 HDInsight 开发 C# Hadoop 流作业][hdinsight-develop-streaming-jobs]\n- [为 HDInsight 开发 Java MapReduce 程序][hdinsight-develop-java-mapreduce]\n\n\n\n[hdinsight-cmdlets-download]: http://go.microsoft.com/fwlink/?LinkID=325563\n\n\n[hdinsight-versions]: /documentation/articles/hdinsight-component-versioning-v1/\n[hdinsight-storage]: /documentation/articles/hdinsight-hadoop-use-blob-storage/\n[hdinsight-get-started]: /documentation/articles/hdinsight-hadoop-tutorial-get-started-windows-v1/\n[hdinsight-admin-portal]: /documentation/articles/hdinsight-administer-use-management-portal-v1/\n\n\n[hdinsight-use-sqoop]: /documentation/articles/hdinsight-use-sqoop/\n[hdinsight-provision]: /documentation/articles/hdinsight-provision-clusters-v1/\n[hdinsight-admin-powershell]: /documentation/articles/hdinsight-administer-use-powershell/\n[hdinsight-upload-data]: /documentation/articles/hdinsight-upload-data/\n[hdinsight-use-hive]: /documentation/articles/hdinsight-use-hive/\n[hdinsight-use-pig]: /documentation/articles/hdinsight-use-pig/\n[hdinsight-storage]: /documentation/articles/hdinsight-hadoop-use-blob-storage/\n[hdinsight-get-started-emulator]: /documentation/articles/hdinsight-hadoop-emulator-get-started/\n[hdinsight-develop-streaming-jobs]: /documentation/articles/hdinsight-hadoop-develop-deploy-streaming-jobs/\n[hdinsight-develop-java-mapreduce]: /documentation/articles/hdinsight-develop-deploy-java-mapreduce/\n[hdinsight-use-oozie]: /documentation/articles/hdinsight-use-oozie/\n\n[sqldatabase-create-configue]: /documentation/articles/sql-database-get-started/\n[sqldatabase-get-started]: /documentation/articles/sql-database-get-started/\n\n[azure-management-portal]: https://manage.windowsazure.cn/\n[azure-create-storageaccount]: /documentation/articles/storage-create-storage-account/\n\n[apache-hadoop]: http://hadoop.apache.org/\n[apache-oozie-400]: http://oozie.apache.org/docs/4.0.0/\n[apache-oozie-332]: http://oozie.apache.org/docs/3.3.2/\n\n[powershell-download]: /downloads/\n[powershell-about-profiles]: https://technet.microsoft.com/zh-cn/library/hh847857.aspx\n[powershell-install-configure]: /documentation/articles/powershell-install-configure/\n[powershell-start]: http://technet.microsoft.com/zh-cn/library/hh847889.aspx\n[powershell-script]: https://technet.microsoft.com/library/dn425048.aspx\n\n[cindygross-hive-tables]: http://blogs.msdn.com/b/cindygross/archive/2013/02/06/hdinsight-hive-internal-and-external-tables-intro.aspx\n\n[img-workflow-diagram]: ./media/hdinsight-use-oozie-coordinator-time/HDI.UseOozie.Workflow.Diagram.png\n[img-preparation-output]: ./media/hdinsight-use-oozie-coordinator-time/HDI.UseOozie.Preparation.Output1.png\n[img-runworkflow-output]: ./media/hdinsight-use-oozie-coordinator-time/HDI.UseOozie.RunCoord.Output.png\n\n[technetwiki-hive-error]: http://social.technet.microsoft.com/wiki/contents/articles/23047.hdinsight-hive-error-unable-to-rename.aspx\n\n<!---HONumber=71-->"
}